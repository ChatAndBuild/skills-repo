[
  {
    "skillId": "bmad-os-changelog-social",
    "name": "bmad-os-changelog-social",
    "description": "Generate social media announcements for Discord, Twitter, and LinkedIn from the latest changelog entry. Use when user asks to create release announcements, social posts, or share changelog updates. Reads CHANGELOG.md in current working directory. Reference examples/ for tone and format.",
    "instructions": "# Changelog Social\n\nGenerate engaging social media announcements from changelog entries.\n\n## Workflow\n\n### Step 1: Extract Changelog Entry\n\nRead `./CHANGELOG.md` and extract the latest version entry. The changelog follows this format:\n\n```markdown\n## [VERSION]\n\n### üéÅ Features\n* **Title** ‚Äî Description\n\n### üêõ Bug Fixes\n* **Title** ‚Äî Description\n\n### üìö Documentation\n* **Title** ‚Äî Description\n\n### üîß Maintenance\n* **Title** ‚Äî Description\n```\n\nParse:\n- **Version number** (e.g., `6.0.0-Beta.5`)\n- **Features** - New functionality, enhancements\n- **Bug Fixes** - Fixes users will care about\n- **Documentation** - New or improved docs\n- **Maintenance** - Dependency updates, tooling improvements\n\n### Step 2: Get Git Contributors\n\nUse git log to find contributors since the previous version. Get commits between the current version tag and the previous one:\n\n```bash\n# Find the previous version tag first\ngit tag --sort=-version:refname | head -5\n\n# Get commits between versions with PR numbers and authors\ngit log <previous-tag>..<current-tag> --pretty=format:\"%h|%s|%an\" --grep=\"#\"\n```\n\nExtract PR numbers from commit messages that contain `#` followed by digits. Compile unique contributors.\n\n### Step 3: Generate Discord Announcement\n\n**Limit: 2,000 characters per message.** Split into multiple messages if needed.\n\nUse this template style:\n\n```markdown\nüöÄ **BMad vVERSION RELEASED!**\n\nüéâ [Brief hype sentence]\n\nü™• **KEY HIGHLIGHT** - [One-line summary]\n\nüéØ **CATEGORY NAME**\n‚Ä¢ Feature one - brief description\n‚Ä¢ Feature two - brief description\n‚Ä¢ Coming soon: Future teaser\n\nüîß **ANOTHER CATEGORY**\n‚Ä¢ Fix or feature\n‚Ä¢ Another item\n\nüìö **DOCS OR OTHER**\n‚Ä¢ Item\n‚Ä¢ Item with link\n\nüåü **COMMUNITY PHILOSOPHY** (optional - include for major releases)\n‚Ä¢ Everything is FREE - No paywalls\n‚Ä¢ Knowledge shared, not sold\n\nüìä **STATS**\nX commits | Y PRs merged | Z files changed\n\nüôè **CONTRIBUTORS**\n@username1 (X PRs!), @username2 (Y PRs!)\n@username3, @username4, username5 + dependabot üõ°Ô∏è\nCommunity-driven FTW! üåü\n\nüì¶ **INSTALL:**\n`npx bmad-method@VERSION install`\n\n‚≠ê **SUPPORT US:**\nüåü GitHub: github.com/bmad-code-org/BMAD-METHOD/\nüì∫ YouTube: youtube.com/@BMadCode\n‚òï Donate: buymeacoffee.com/bmad\n\nüî• **Next version tease!**\n```\n\n**Content Strategy:**\n- Focus on **user impact** - what's better for them?\n- Highlight **annoying bugs fixed** that frustrated users\n- Show **new capabilities** that enable workflows\n- Keep it **punchy** - use emojis and short bullets\n- Add **personality** - excitement, humor, gratitude\n\n### Step 4: Generate Twitter Post\n\n**Limit: 25,000 characters per tweet (Premium).** With Premium, use a single comprehensive post matching the Discord style (minus Discord-specific formatting). Aim for 1,500-3,000 characters for better engagement.\n\n**Threads are optional** ‚Äî only use for truly massive releases where you want multiple engagement points.\n\nSee `examples/twitter-example.md` for the single-post Premium format.\n\n## Content Selection Guidelines\n\n**Include:**\n- New features that change workflows\n- Bug fixes for annoying/blocking issues\n- Documentation that helps users\n- Performance improvements\n- New agents or workflows\n- Breaking changes (call out clearly)\n\n**Skip/Minimize:**\n- Internal refactoring\n- Dependency updates (unless user-facing)\n- Test improvements\n- Minor style fixes\n\n**Emphasize:**\n- \"Finally fixed\" issues\n- \"Faster\" operations\n- \"Easier\" workflows\n- \"Now supports\" capabilities\n\n## Examples\n\nReference example posts in `examples/` for tone and formatting guidance:\n\n- **discord-example.md** ‚Äî Full Discord announcement with emojis, sections, contributor shout-outs\n- **twitter-example.md** ‚Äî Twitter thread format (5 tweets max for major releases)\n- **linkedin-example.md** ‚Äî Professional post for major/minor releases with significant features\n\n**When to use LinkedIn:**\n- Major version releases (e.g., v6.0.0 Beta, v7.0.0)\n- Minor releases with exceptional new features\n- Community milestone announcements\n\nRead the appropriate example file before generating to match the established style and voice.\n\n## Output Format\n\n**CRITICAL: ALWAYS write to files** - Create files in `_bmad-output/social/` directory:\n\n1. `{repo-name}-discord-{version}.md` - Discord announcement\n2. `{repo-name}-twitter-{version}.md` - Twitter post\n3. `{repo-name}-linkedin-{version}.md` - LinkedIn post (if applicable)\n\nAlso present a preview in the chat:\n\n```markdown\n## Discord Announcement\n\n[paste Discord content here]\n\n## Twitter Post\n\n[paste Twitter content here]\n```\n\nFiles created:\n- `_bmad-output/social/{filename}`\n\nOffer to make adjustments if the user wants different emphasis, tone, or content.",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "book-translation",
    "name": "book-translation",
    "description": "Translate \"The Interactive Book of Prompting\" chapters and UI strings to a new language",
    "instructions": "# Book Translation Skill\n\nThis skill guides translation of book content for **The Interactive Book of Prompting** at prompts.chat.\n\n## Overview\n\nThe book has **25 chapters** across 7 parts. Translation requires:\n1. **MDX content files** - Full chapter content in `src/content/book/{locale}/`\n2. **JSON translation keys** - UI strings, chapter titles, and descriptions in `messages/{locale}.json`\n\n## Prerequisites\n\nBefore starting, identify:\n- **Target locale code** (e.g., `de`, `fr`, `es`, `ja`, `ko`, `zh`)\n- Check if locale exists in `messages/` directory\n- Check if `src/content/book/{locale}/` folder exists\n\n## Step 1: Copy Turkish Folder as Base\n\nThe Turkish (`tr`) translation is complete and well-tested. **Copy it as your starting point** instead of translating from English:\n\n```bash\nmkdir -p src/content/book/{locale}\ncp -r src/content/book/*.mdx src/content/book/{locale}/\ncp src/components/book/elements/locales/en.ts src/components/book/elements/locales/{locale}.ts\n```\n\n**‚ö†Ô∏è IMPORTANT: After copying, you MUST register the new locale in `src/components/book/elements/locales/index.ts`:**\n1. Add import: `import {locale} from \"./{locale}\";`\n2. Add to `locales` object: `{locale},`\n3. Add to named exports: `export { en, tr, az, {locale} };`\n\nThis is faster because:\n- Turkish and many languages share similar sentence structures\n- All JSX/React components are already preserved correctly\n- File structure is already set up\n- You only need to translate the prose, not recreate the structure\n\n## Step 2: Translate MDX Content Files\n\nEdit each copied file in `src/content/book/{locale}/` to translate from Turkish to your target language.\n\nProcess files one by one:\n\n### Chapter List (in order)\n\n| Slug | English Title |\n|------|---------------|\n| `00a-preface` | Preface |\n| `00b-history` | History |\n| `00c-introduction` | Introduction |\n| `01-understanding-ai-models` | Understanding AI Models |\n| `02-anatomy-of-effective-prompt` | Anatomy of an Effective Prompt |\n| `03-core-prompting-principles` | Core Prompting Principles |\n| `04-role-based-prompting` | Role-Based Prompting |\n| `05-structured-output` | Structured Output |\n| `06-chain-of-thought` | Chain of Thought |\n| `07-few-shot-learning` | Few-Shot Learning |\n| `08-iterative-refinement` | Iterative Refinement |\n| `09-json-yaml-prompting` | JSON & YAML Prompting |\n| `10-system-prompts-personas` | System Prompts & Personas |\n| `11-prompt-chaining` | Prompt Chaining |\n| `12-handling-edge-cases` | Handling Edge Cases |\n| `13-multimodal-prompting` | Multimodal Prompting |\n| `14-context-engineering` | Context Engineering |\n| `15-common-pitfalls` | Common Pitfalls |\n| `16-ethics-responsible-use` | Ethics & Responsible Use |\n| `17-prompt-optimization` | Prompt Optimization |\n| `18-writing-content` | Writing & Content |\n| `19-programming-development` | Programming & Development |\n| `20-education-learning` | Education & Learning |\n| `21-business-productivity` | Business & Productivity |\n| `22-creative-arts` | Creative Arts |\n| `23-research-analysis` | Research & Analysis |\n| `24-future-of-prompting` | The Future of Prompting |\n| `25-agents-and-skills` | Agents & Skills |\n\n### MDX Translation Guidelines\n\n1. **Preserve all JSX/React components** - Keep `<div>`, `<img>`, `className`, etc. unchanged\n2. **Preserve code blocks** - Code examples should remain in English (variable names, keywords)\n3. **Translate prose content** - Headings, paragraphs, lists\n4. **Keep Markdown syntax** - `##`, `**bold**`, `*italic*`, `[links](url)`\n5. **Preserve component imports** - Any `import` statements at the top\n\n## Step 3: Translate JSON Keys\n\nIn `messages/{locale}.json`, translate the `\"book\"` section. Key areas:\n\n### Book Metadata\n```json\n\"book\": {\n  \"title\": \"The Interactive Book of Prompting\",\n  \"subtitle\": \"An Interactive Guide to Crafting Clear and Effective Prompts\",\n  \"metaTitle\": \"...\",\n  \"metaDescription\": \"...\",\n  ...\n}\n```\n\n### Chapter Titles (`book.chapters`)\n```json\n\"chapters\": {\n  \"00a-preface\": \"Preface\",\n  \"00b-history\": \"History\",\n  \"00c-introduction\": \"Introduction\",\n  ...\n}\n```\n\n### Chapter Descriptions (`book.chapterDescriptions`)\n```json\n\"chapterDescriptions\": {\n  \"00a-preface\": \"A personal note from the author\",\n  \"00b-history\": \"The story of Awesome ChatGPT Prompts\",\n  ...\n}\n```\n\n### Part Names (`book.parts`)\n```json\n\"parts\": {\n  \"introduction\": \"Introduction\",\n  \"foundations\": \"Foundations\",\n  \"techniques\": \"Techniques\",\n  \"advanced\": \"Advanced Strategies\",\n  \"bestPractices\": \"Best Practices\",\n  \"useCases\": \"Use Cases\",\n  \"conclusion\": \"Conclusion\"\n}\n```\n\n### Interactive Demo Examples (`book.interactive.demoExamples`)\nLocalize example text for demos (tokenizer samples, temperature examples, etc.):\n```json\n\"demoExamples\": {\n  \"tokenPrediction\": {\n    \"tokens\": [\"The\", \" capital\", \" of\", \" France\", \" is\", \" Paris\", \".\"],\n    \"fullText\": \"The capital of France is Paris.\"\n  },\n  \"temperature\": {\n    \"prompt\": \"What is the capital of France?\",\n    ...\n  }\n}\n```\n\n### Book Elements Locales (REQUIRED)\n\n**‚ö†Ô∏è DO NOT SKIP THIS STEP** - The interactive demos will not work in the new language without this.\n\nTranslate the locale data file at `src/components/book/elements/locales/{locale}.ts`:\n- Temperature examples, token predictions, embedding words\n- Capabilities list, sample conversations, strategies\n- Tokenizer samples, builder fields, chain types\n- Frameworks (CRISPE, BREAK, RTF), exercises\n- Image/video prompt options, validation demos\n\n**Then register it in `src/components/book/elements/locales/index.ts`:**\n```typescript\nimport {locale} from \"./{locale}\";\n\nconst locales: Record<string, LocaleData> = {\n  en,\n  tr,\n  az,\n  {locale},  // Add your new locale here\n};\n\nexport { en, tr, az, {locale} };  // Add to exports\n```\n\n### UI Strings (`book.interactive.*`, `book.chapter.*`, `book.search.*`)\nTranslate all interactive component labels and navigation strings.\n\n## Step 4: Verify Translation\n\n1. Run the check script:\n   ```bash\n   node scripts/check-translations.js\n   ```\n\n2. Start dev server and test:\n   ```bash\n   npm run dev\n   ```\n\n3. Navigate to `/book` with the target locale to verify content loads\n\n## Reference: English Translation\n\nThe English (`en`) translation is complete and serves as the **base template** for all new translations:\n- MDX files: `src/content/book/*.mdx` ‚Äî copy this files to `src/content/book/{locale}/*.mdx`\n- JSON keys: `messages/en.json` ‚Üí `book` section ‚Äî use as reference for structure\n\n### Recommended Workflow\n\n1. Copy `src/content/book/*.mdx` to `src/content/book/{locale}/*.mdx`\n2. Copy the `\"book\"` section from `messages/en.json` to `messages/{locale}.json`. Translate these in multiple agentic session instead of single time (token limit may exceed at once)\n3. Edit each file, translating English ‚Üí target language\n4. Keep all JSX components, code blocks, and Markdown syntax intact\n\n## Quality Guidelines\n\n- **Consistency**: Use consistent terminology throughout (e.g., always translate \"prompt\" the same way)\n- **Technical terms**: Some terms like \"AI\", \"ChatGPT\", \"API\" may stay in English\n- **Cultural adaptation**: Adapt examples to be relevant for the target audience where appropriate\n- **Natural language**: Prioritize natural-sounding translations over literal ones",
    "author": "f",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "brevo-automation",
    "name": "brevo-automation",
    "description": "Automate Brevo (Sendinblue) tasks via Rube MCP (Composio): manage email campaigns, create/edit templates, track senders, and monitor campaign performance. Always search tools first for current schemas.",
    "instructions": "# Brevo Automation via Rube MCP\n\nAutomate Brevo (formerly Sendinblue) email marketing operations through Composio's Brevo toolkit via Rube MCP.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active Brevo connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `brevo`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `brevo`\n3. If connection is not ACTIVE, follow the returned auth link to complete Brevo authentication\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. Manage Email Campaigns\n\n**When to use**: User wants to list, review, or update email campaigns\n\n**Tool sequence**:\n1. `BREVO_LIST_EMAIL_CAMPAIGNS` - List all campaigns with filters [Required]\n2. `BREVO_UPDATE_EMAIL_CAMPAIGN` - Update campaign content or settings [Optional]\n\n**Key parameters for listing**:\n- `type`: Campaign type ('classic' or 'trigger')\n- `status`: Campaign status ('suspended', 'archive', 'sent', 'queued', 'draft', 'inProcess', 'inReview')\n- `startDate`/`endDate`: Date range filter (YYYY-MM-DDTHH:mm:ss.SSSZ format)\n- `statistics`: Stats type to include ('globalStats', 'linksStats', 'statsByDomain')\n- `limit`: Results per page (max 100, default 50)\n- `offset`: Pagination offset\n- `sort`: Sort order ('asc' or 'desc')\n- `excludeHtmlContent`: Set `true` to reduce response size\n\n**Key parameters for update**:\n- `campaign_id`: Numeric campaign ID (required)\n- `name`: Campaign name\n- `subject`: Email subject line\n- `htmlContent`: HTML email body (mutually exclusive with `htmlUrl`)\n- `htmlUrl`: URL to HTML content\n- `sender`: Sender object with `name`, `email`, or `id`\n- `recipients`: Object with `listIds` and `exclusionListIds`\n- `scheduledAt`: Scheduled send time (YYYY-MM-DDTHH:mm:ss.SSSZ)\n\n**Pitfalls**:\n- `startDate` and `endDate` are mutually required; provide both or neither\n- Date filters only work when `status` is not passed or set to 'sent'\n- `htmlContent` and `htmlUrl` are mutually exclusive\n- Campaign `sender` email must be a verified sender in Brevo\n- A/B testing fields (`subjectA`, `subjectB`, `splitRule`, `winnerCriteria`) require `abTesting: true`\n- `scheduledAt` uses full ISO 8601 format with timezone\n\n### 2. Create and Manage Email Templates\n\n**When to use**: User wants to create, edit, list, or delete email templates\n\n**Tool sequence**:\n1. `BREVO_GET_ALL_EMAIL_TEMPLATES` - List all templates [Required]\n2. `BREVO_CREATE_OR_UPDATE_EMAIL_TEMPLATE` - Create a new template or update existing [Required]\n3. `BREVO_DELETE_EMAIL_TEMPLATE` - Delete an inactive template [Optional]\n\n**Key parameters for listing**:\n- `templateStatus`: Filter active (`true`) or inactive (`false`) templates\n- `limit`: Results per page (max 1000, default 50)\n- `offset`: Pagination offset\n- `sort`: Sort order ('asc' or 'desc')\n\n**Key parameters for create/update**:\n- `templateId`: Include to update; omit to create new\n- `templateName`: Template display name (required for creation)\n- `subject`: Email subject line (required for creation)\n- `htmlContent`: HTML template body (min 10 characters; use this or `htmlUrl`)\n- `sender`: Sender object with `name` and `email`, or `id` (required for creation)\n- `replyTo`: Reply-to email address\n- `isActive`: Activate or deactivate the template\n- `tag`: Category tag for the template\n\n**Pitfalls**:\n- When `templateId` is provided, the tool updates; when omitted, it creates\n- For creation, `templateName`, `subject`, and `sender` are required\n- `htmlContent` must be at least 10 characters\n- Template personalization uses `{{contact.ATTRIBUTE}}` syntax\n- Only inactive templates can be deleted\n- `htmlContent` and `htmlUrl` are mutually exclusive\n\n### 3. Manage Senders\n\n**When to use**: User wants to view authorized sender identities\n\n**Tool sequence**:\n1. `BREVO_GET_ALL_SENDERS` - List all verified senders [Required]\n\n**Key parameters**: (none required)\n\n**Pitfalls**:\n- Senders must be verified before they can be used in campaigns or templates\n- Sender verification is done through the Brevo web interface, not via API\n- Sender IDs can be used in `sender.id` fields for campaigns and templates\n\n### 4. Configure A/B Testing Campaigns\n\n**When to use**: User wants to set up or modify A/B test settings on a campaign\n\n**Tool sequence**:\n1. `BREVO_LIST_EMAIL_CAMPAIGNS` - Find the target campaign [Prerequisite]\n2. `BREVO_UPDATE_EMAIL_CAMPAIGN` - Configure A/B test settings [Required]\n\n**Key parameters**:\n- `campaign_id`: Campaign to configure\n- `abTesting`: Set to `true` to enable A/B testing\n- `subjectA`: Subject line for variant A\n- `subjectB`: Subject line for variant B\n- `splitRule`: Percentage split for the test (1-99)\n- `winnerCriteria`: 'open' or 'click' for determining the winner\n- `winnerDelay`: Hours to wait before selecting winner (1-168)\n\n**Pitfalls**:\n- A/B testing must be enabled (`abTesting: true`) before setting variant fields\n- `splitRule` is the percentage of contacts that receive variant A\n- `winnerDelay` defines how long to test before sending the winner to remaining contacts\n- Only works with 'classic' campaign type\n\n## Common Patterns\n\n### Campaign Lifecycle\n\n```\n1. Create campaign (status: draft)\n2. Set recipients (listIds)\n3. Configure content (htmlContent or htmlUrl)\n4. Optionally schedule (scheduledAt)\n5. Send or schedule via Brevo UI (API update can set scheduledAt)\n```\n\n### Pagination\n\n- Use `limit` (page size) and `offset` (starting index)\n- Default limit is 50; max varies by endpoint (100 for campaigns, 1000 for templates)\n- Increment `offset` by `limit` each page\n- Check `count` in response to determine total available\n\n### Template Personalization\n\n```\n- First name: {{contact.FIRSTNAME}}\n- Last name: {{contact.LASTNAME}}\n- Custom attribute: {{contact.CUSTOM_ATTRIBUTE}}\n- Mirror link: {{mirror}}\n- Unsubscribe link: {{unsubscribe}}\n```\n\n## Known Pitfalls\n\n**Date Formats**:\n- All dates use ISO 8601 with milliseconds: YYYY-MM-DDTHH:mm:ss.SSSZ\n- Pass timezone in the date-time format for accurate results\n- `startDate` and `endDate` must be used together\n\n**Sender Verification**:\n- All sender emails must be verified in Brevo before use\n- Unverified senders cause campaign creation/update failures\n- Use GET_ALL_SENDERS to check available verified senders\n\n**Rate Limits**:\n- Brevo API has rate limits per account plan\n- Implement backoff on 429 responses\n- Template operations have lower limits than read operations\n\n**Response Parsing**:\n- Response data may be nested under `data` or `data.data`\n- Parse defensively with fallback patterns\n- Campaign and template IDs are numeric integers\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| List campaigns | BREVO_LIST_EMAIL_CAMPAIGNS | type, status, limit, offset |\n| Update campaign | BREVO_UPDATE_EMAIL_CAMPAIGN | campaign_id, subject, htmlContent |\n| List templates | BREVO_GET_ALL_EMAIL_TEMPLATES | templateStatus, limit, offset |\n| Create template | BREVO_CREATE_OR_UPDATE_EMAIL_TEMPLATE | templateName, subject, htmlContent, sender |\n| Update template | BREVO_CREATE_OR_UPDATE_EMAIL_TEMPLATE | templateId, htmlContent |\n| Delete template | BREVO_DELETE_EMAIL_TEMPLATE | templateId |\n| List senders | BREVO_GET_ALL_SENDERS | (none) |",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "camsnap",
    "name": "camsnap",
    "description": "Capture frames or clips from RTSP/ONVIF cameras.",
    "instructions": "# camsnap\n\nUse `camsnap` to grab snapshots, clips, or motion events from configured cameras.\n\nSetup\n\n- Config file: `~/.config/camsnap/config.yaml`\n- Add camera: `camsnap add --name kitchen --host 192.168.0.10 --user user --pass pass`\n\nCommon commands\n\n- Discover: `camsnap discover --info`\n- Snapshot: `camsnap snap kitchen --out shot.jpg`\n- Clip: `camsnap clip kitchen --dur 5s --out clip.mp4`\n- Motion watch: `camsnap watch kitchen --threshold 0.2 --action '...'`\n- Doctor: `camsnap doctor --probe`\n\nNotes\n\n- Requires `ffmpeg` on PATH.\n- Prefer a short test capture before longer clips.",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "text-to-pdf-automation",
    "name": "canva",
    "description": "|",
    "instructions": "# Canva Connect\n\nManage Canva designs, assets, and folders via the Connect API.\n\n## What This Skill Does (and Doesn't Do)\n\n| ‚úÖ CAN DO | ‚ùå CANNOT DO |\n|-----------|--------------|\n| List/search designs | Add content to designs |\n| Create blank designs | Edit existing design content |\n| Export designs (PNG/PDF/JPG) | Upload documents (images only) |\n| Create/manage folders | AI design generation |\n| Move items between folders | |\n| Upload images as assets | |\n| Autofill brand templates | |\n\n## Realistic Use Cases\n\n**1. Asset Pipeline** üñºÔ∏è\n```\nGenerate diagram ‚Üí upload to Canva ‚Üí organize in project folder\n```\n\n**2. Export Automation** üì§\n```\nDesign finished in Canva ‚Üí export via CLI ‚Üí use in docs/website\n```\n\n**3. Design Organization** üìÅ\n```\nCreate project folders ‚Üí move related designs ‚Üí keep Canva tidy\n```\n\n**4. Brand Template Autofill** üìã\n```\nSet up template in Canva ‚Üí pass data via API ‚Üí get personalized output\n```\n\n## Quick Start\n\n```bash\n# Authenticate (opens browser for OAuth)\n{baseDir}/scripts/canva.sh auth\n\n# List your designs\n{baseDir}/scripts/canva.sh designs list\n\n# Create a new design\n{baseDir}/scripts/canva.sh designs create --type doc --title \"My Document\"\n\n# Export a design\n{baseDir}/scripts/canva.sh export <design_id> --format pdf\n```\n\n## Setup\n\n### 1. Create Canva Integration\n\n1. Go to [canva.com/developers/integrations](https://canva.com/developers/integrations)\n2. Click **Create an integration**\n3. Set scopes:\n   - `design:content` (Read + Write)\n   - `design:meta` (Read)\n   - `asset` (Read + Write)\n   - `brandtemplate:meta` (Read)\n   - `brandtemplate:content` (Read)\n   - `profile` (Read)\n4. Set OAuth redirect: `http://127.0.0.1:3001/oauth/redirect`\n5. Note **Client ID** and generate **Client Secret**\n\n### 2. Configure Environment\n\nAdd to `~/.clawdbot/clawdbot.json` under `skills.entries`:\n\n```json\n{\n  \"skills\": {\n    \"entries\": {\n      \"canva\": {\n        \"clientId\": \"YOUR_CLIENT_ID\",\n        \"clientSecret\": \"YOUR_CLIENT_SECRET\"\n      }\n    }\n  }\n}\n```\n\nOr set environment variables:\n```bash\nexport CANVA_CLIENT_ID=\"your_client_id\"\nexport CANVA_CLIENT_SECRET=\"your_client_secret\"\n```\n\n### 3. Authenticate\n\n```bash\n{baseDir}/scripts/canva.sh auth\n```\n\nOpens browser for OAuth consent. Tokens stored in `~/.clawdbot/canva-tokens.json`.\n\n## Commands\n\n### Authentication\n| Command | Description |\n|---------|-------------|\n| `auth` | Start OAuth flow (opens browser) |\n| `auth status` | Check authentication status |\n| `auth logout` | Clear stored tokens |\n\n### Designs\n| Command | Description |\n|---------|-------------|\n| `designs list [--limit N]` | List your designs |\n| `designs get <id>` | Get design details |\n| `designs create --type <type> --title <title>` | Create new design |\n| `designs delete <id>` | Move design to trash |\n\n**Design types:** `doc`, `presentation`, `whiteboard`, `poster`, `instagram_post`, `facebook_post`, `video`, `logo`, `flyer`, `banner`\n\n### Export\n| Command | Description |\n|---------|-------------|\n| `export <design_id> --format <fmt>` | Export design |\n| `export status <job_id>` | Check export job status |\n\n**Formats:** `pdf`, `png`, `jpg`, `gif`, `pptx`, `mp4`\n\n### Assets\n| Command | Description |\n|---------|-------------|\n| `assets list` | List uploaded assets |\n| `assets upload <file> [--name <name>]` | Upload asset |\n| `assets get <id>` | Get asset details |\n| `assets delete <id>` | Delete asset |\n\n### Brand Templates\n| Command | Description |\n|---------|-------------|\n| `templates list` | List brand templates |\n| `templates get <id>` | Get template details |\n| `autofill <template_id> --data <json>` | Autofill template with data |\n\n### Folders\n| Command | Description |\n|---------|-------------|\n| `folders list` | List folders |\n| `folders create <name>` | Create folder |\n| `folders get <id>` | Get folder contents |\n\n### User\n| Command | Description |\n|---------|-------------|\n| `me` | Get current user profile |\n\n## Examples\n\n### Create and Export a Poster\n```bash\n# Create\n{baseDir}/scripts/canva.sh designs create --type poster --title \"Event Poster\"\n\n# Export as PNG\n{baseDir}/scripts/canva.sh export DAF... --format png --output ./poster.png\n```\n\n### Upload Brand Assets\n```bash\n# Upload logo\n{baseDir}/scripts/canva.sh assets upload ./logo.png --name \"Company Logo\"\n\n# Upload multiple\nfor f in ./brand/*.png; do\n  {baseDir}/scripts/canva.sh assets upload \"$f\"\ndone\n```\n\n### Autofill a Template\n```bash\n# List available templates\n{baseDir}/scripts/canva.sh templates list\n\n# Autofill with data\n{baseDir}/scripts/canva.sh autofill TEMPLATE_ID --data '{\n  \"title\": \"Q1 Report\",\n  \"subtitle\": \"Financial Summary\",\n  \"date\": \"January 2026\"\n}'\n```\n\n## API Reference\n\nBase URL: `https://api.canva.com/rest`\n\nSee [references/api.md](references/api.md) for detailed endpoint documentation.\n\n## Troubleshooting\n\n### Token Expired\n```bash\n{baseDir}/scripts/canva.sh auth  # Re-authenticate\n```\n\n### Rate Limited\nThe API has per-endpoint rate limits. The script handles backoff automatically.\n\n### Missing Scopes\nIf operations fail with 403, ensure your integration has the required scopes enabled.\n\n## Data Files\n\n| File | Purpose |\n|------|---------|\n| `~/.clawdbot/canva-tokens.json` | OAuth tokens (encrypted) |\n| `~/.clawdbot/canva-cache.json` | Response cache |",
    "author": "clawdbot",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "canva-automation",
    "name": "canva-automation",
    "description": "Automate Canva tasks via Rube MCP (Composio): designs, exports, folders, brand templates, autofill. Always search tools first for current schemas.",
    "instructions": "# Canva Automation via Rube MCP\n\nAutomate Canva design operations through Composio's Canva toolkit via Rube MCP.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active Canva connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `canva`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `canva`\n3. If connection is not ACTIVE, follow the returned auth link to complete Canva OAuth\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. List and Browse Designs\n\n**When to use**: User wants to find existing designs or browse their Canva library\n\n**Tool sequence**:\n1. `CANVA_LIST_USER_DESIGNS` - List all designs with optional filters [Required]\n\n**Key parameters**:\n- `query`: Search term to filter designs by name\n- `continuation`: Pagination token from previous response\n- `ownership`: Filter by 'owned', 'shared', or 'any'\n- `sort_by`: Sort field (e.g., 'modified_at', 'title')\n\n**Pitfalls**:\n- Results are paginated; follow `continuation` token until absent\n- Deleted designs may still appear briefly; check design status\n- Search is substring-based, not fuzzy matching\n\n### 2. Create and Design\n\n**When to use**: User wants to create a new Canva design from scratch or from a template\n\n**Tool sequence**:\n1. `CANVA_ACCESS_USER_SPECIFIC_BRAND_TEMPLATES_LIST` - Browse available brand templates [Optional]\n2. `CANVA_CREATE_CANVA_DESIGN_WITH_OPTIONAL_ASSET` - Create a new design [Required]\n\n**Key parameters**:\n- `design_type`: Type of design (e.g., 'Presentation', 'Poster', 'SocialMedia')\n- `title`: Name for the new design\n- `asset_id`: Optional asset to include in the design\n- `width` / `height`: Custom dimensions in pixels\n\n**Pitfalls**:\n- Design type must match Canva's predefined types exactly\n- Custom dimensions have minimum and maximum limits\n- Asset must be uploaded first via CANVA_CREATE_ASSET_UPLOAD_JOB before referencing\n\n### 3. Upload Assets\n\n**When to use**: User wants to upload images or files to Canva for use in designs\n\n**Tool sequence**:\n1. `CANVA_CREATE_ASSET_UPLOAD_JOB` - Initiate the asset upload [Required]\n2. `CANVA_FETCH_ASSET_UPLOAD_JOB_STATUS` - Poll until upload completes [Required]\n\n**Key parameters**:\n- `name`: Display name for the asset\n- `url`: Public URL of the file to upload (for URL-based uploads)\n- `job_id`: Upload job ID returned from step 1 (for status polling)\n\n**Pitfalls**:\n- Upload is asynchronous; you MUST poll the job status until it completes\n- Supported formats include PNG, JPG, SVG, MP4, GIF\n- File size limits apply; large files may take longer to process\n- The `job_id` from CREATE returns the ID needed for status polling\n- Status values: 'in_progress', 'success', 'failed'\n\n### 4. Export Designs\n\n**When to use**: User wants to download or export a Canva design as PDF, PNG, or other format\n\n**Tool sequence**:\n1. `CANVA_LIST_USER_DESIGNS` - Find the design to export [Prerequisite]\n2. `CANVA_CREATE_CANVA_DESIGN_EXPORT_JOB` - Start the export process [Required]\n3. `CANVA_GET_DESIGN_EXPORT_JOB_RESULT` - Poll until export completes and get download URL [Required]\n\n**Key parameters**:\n- `design_id`: ID of the design to export\n- `format`: Export format ('pdf', 'png', 'jpg', 'svg', 'mp4', 'gif', 'pptx')\n- `pages`: Specific page numbers to export (array)\n- `quality`: Export quality ('regular', 'high')\n- `job_id`: Export job ID for polling status\n\n**Pitfalls**:\n- Export is asynchronous; you MUST poll the job result until it completes\n- Download URLs from completed exports expire after a limited time\n- Large designs with many pages take longer to export\n- Not all formats support all design types (e.g., MP4 only for animations)\n- Poll interval: wait 2-3 seconds between status checks\n\n### 5. Organize with Folders\n\n**When to use**: User wants to create folders or organize designs into folders\n\n**Tool sequence**:\n1. `CANVA_POST_FOLDERS` - Create a new folder [Required]\n2. `CANVA_MOVE_ITEM_TO_SPECIFIED_FOLDER` - Move designs into folders [Optional]\n\n**Key parameters**:\n- `name`: Folder name\n- `parent_folder_id`: Parent folder for nested organization\n- `item_id`: ID of the design or asset to move\n- `folder_id`: Target folder ID\n\n**Pitfalls**:\n- Folder names must be unique within the same parent folder\n- Moving items between folders updates their location immediately\n- Root-level folders have no parent_folder_id\n\n### 6. Autofill from Brand Templates\n\n**When to use**: User wants to generate designs by filling brand template placeholders with data\n\n**Tool sequence**:\n1. `CANVA_ACCESS_USER_SPECIFIC_BRAND_TEMPLATES_LIST` - List available brand templates [Required]\n2. `CANVA_INITIATE_CANVA_DESIGN_AUTOFILL_JOB` - Start autofill with data [Required]\n\n**Key parameters**:\n- `brand_template_id`: ID of the brand template to use\n- `title`: Title for the generated design\n- `data`: Key-value mapping of placeholder names to replacement values\n\n**Pitfalls**:\n- Template placeholders must match exactly (case-sensitive)\n- Autofill is asynchronous; poll for completion\n- Only brand templates support autofill, not regular designs\n- Data values must match the expected type for each placeholder (text, image URL)\n\n## Common Patterns\n\n### Async Job Pattern\n\nMany Canva operations are asynchronous:\n```\n1. Initiate job (upload, export, autofill) -> get job_id\n2. Poll status endpoint with job_id every 2-3 seconds\n3. Check for 'success' or 'failed' status\n4. On success, extract result (asset_id, download_url, design_id)\n```\n\n### ID Resolution\n\n**Design name -> Design ID**:\n```\n1. Call CANVA_LIST_USER_DESIGNS with query=design_name\n2. Find matching design in results\n3. Extract id field\n```\n\n**Brand template name -> Template ID**:\n```\n1. Call CANVA_ACCESS_USER_SPECIFIC_BRAND_TEMPLATES_LIST\n2. Find template by name\n3. Extract brand_template_id\n```\n\n### Pagination\n\n- Check response for `continuation` token\n- Pass token in next request's `continuation` parameter\n- Continue until `continuation` is absent or empty\n\n## Known Pitfalls\n\n**Async Operations**:\n- Uploads, exports, and autofills are all asynchronous\n- Always poll job status; do not assume immediate completion\n- Download URLs from exports expire; use them promptly\n\n**Asset Management**:\n- Assets must be uploaded before they can be used in designs\n- Upload job must reach 'success' status before the asset_id is valid\n- Supported formats vary; check Canva documentation for current limits\n\n**Rate Limits**:\n- Canva API has rate limits per endpoint\n- Implement exponential backoff for bulk operations\n- Batch operations where possible to reduce API calls\n\n**Response Parsing**:\n- Response data may be nested under `data` key\n- Job status responses include different fields based on completion state\n- Parse defensively with fallbacks for optional fields\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| List designs | CANVA_LIST_USER_DESIGNS | query, continuation |\n| Create design | CANVA_CREATE_CANVA_DESIGN_WITH_OPTIONAL_ASSET | design_type, title |\n| Upload asset | CANVA_CREATE_ASSET_UPLOAD_JOB | name, url |\n| Check upload | CANVA_FETCH_ASSET_UPLOAD_JOB_STATUS | job_id |\n| Export design | CANVA_CREATE_CANVA_DESIGN_EXPORT_JOB | design_id, format |\n| Get export | CANVA_GET_DESIGN_EXPORT_JOB_RESULT | job_id |\n| Create folder | CANVA_POST_FOLDERS | name, parent_folder_id |\n| Move to folder | CANVA_MOVE_ITEM_TO_SPECIFIED_FOLDER | item_id, folder_id |\n| List templates | CANVA_ACCESS_USER_SPECIFIC_BRAND_TEMPLATES_LIST | (none) |\n| Autofill template | CANVA_INITIATE_CANVA_DESIGN_AUTOFILL_JOB | brand_template_id, data |",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "canvas-design",
    "name": "canvas-design",
    "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
    "instructions": "These are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, essential-only, integrated as visual element - never lengthy\n- **SPATIAL EXPRESSION**: Ideas communicate through space, form, color, composition - not paragraphs\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy visually - provide creative room\n- **PURE DESIGN**: This is about making ART OBJECTS, not documents with decoration\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final work must look meticulously crafted, labored over with care, the product of countless hours by someone at the top of their field\n\n**The design philosophy should be 4-6 paragraphs long.** Fill it with poetic design philosophy that brings together the core vision. Avoid repeating the same points. Keep the design philosophy generic without mentioning the intention of the art, as if it can be used wherever. Output the design philosophy as a .md file.\n\n---\n\n## DEDUCING THE SUBTLE REFERENCE\n\n**CRITICAL STEP**: Before creating the canvas, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe topic is a **subtle, niche reference embedded within the art itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful abstract composition. The design philosophy provides the aesthetic language. The deduced topic provides the soul - the quiet conceptual DNA woven invisibly into form, color, and composition.\n\nThis is **VERY IMPORTANT**: The reference must be refined so it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song - only those who know will catch it, but everyone appreciates the music.\n\n---\n\n## CANVAS CREATION\n\nWith both the philosophy and the conceptual framework established, express it on a canvas. Take a moment to gather thoughts and clear the mind. Use the design philosophy created and the instructions below to craft a masterpiece, embodying all aspects of the philosophy with expert craftsmanship.\n\n**IMPORTANT**: For any type of content, even if the user requests something for a movie/game/book, the approach should still be sophisticated. Never lose sight of the idea that this should be art, not something that's cartoony or amateur.\n\nTo create museum or magazine quality work, use the design philosophy as the foundation. Create one single page, highly visual, design-forward PDF or PNG output (unless asked for more pages). Generally use repeating patterns and perfect shapes. Treat the abstract philosophical design as if it were a scientific bible, borrowing the visual language of systematic observation‚Äîdense accumulation of marks, repeated elements, or layered patterns that build meaning through patient repetition and reward sustained viewing. Add sparse, clinical typography and systematic reference markers that suggest this could be a diagram from an imaginary discipline, treating the invisible subject with the same reverence typically reserved for documenting observable phenomena. Anchor the piece with simple phrase(s) or details positioned subtly, using a limited color palette that feels intentional and cohesive. Embrace the paradox of using analytical visual language to express ideas about human experience: the result should feel like an artifact that proves something ephemeral can be studied, mapped, and understood through careful attention. This is true art. \n\n**Text as a contextual element**: Text is always minimal and visual-first, but let context guide whether that means whisper-quiet labels or bold typographic gestures. A punk venue poster might have larger, more aggressive type than a minimalist ceramics studio identity. Most of the time, font should be thin. All use of fonts must be design-forward and prioritize visual communication. Regardless of text scale, nothing falls off the page and nothing overlaps. Every element must be contained within the canvas boundaries with proper margins. Check carefully that all text, graphics, and visual elements have breathing room and clear separation. This is non-negotiable for professional execution. **IMPORTANT: Use different fonts if writing text. Search the `./canvas-fonts` directory. Regardless of approach, sophistication is non-negotiable.**\n\nDownload and use whatever fonts are needed to make this a reality. Get creative by making the typography actually part of the art itself -- if the art is abstract, bring the font onto the canvas, not typeset digitally.\n\nTo push boundaries, follow design instinct/intuition while using the philosophy as a guiding principle. Embrace ultimate design freedom and choice. Push aesthetics and design to the frontier. \n\n**CRITICAL**: To achieve human-crafted quality (not AI-generated), create work that looks like it took countless hours. Make it appear as though someone at the absolute top of their field labored over every detail with painstaking care. Ensure the composition, spacing, color choices, typography - everything screams expert-level craftsmanship. Double-check that nothing overlaps, formatting is flawless, every detail perfect. Create something that could be shown to people to prove expertise and rank as undeniably impressive.\n\nOutput the final result as a single, downloadable .pdf or .png file, alongside the design philosophy used as a .md file.\n\n---\n\n## FINAL STEP\n\n**IMPORTANT**: The user ALREADY said \"It isn't perfect enough. It must be pristine, a masterpiece if craftsmanship, as if it were about to be displayed in a museum.\"\n\n**CRITICAL**: To refine the work, avoid adding more graphics; instead refine what has been created and make it extremely crisp, respecting the design philosophy and the principles of minimalism entirely. Rather than adding a fun filter or refactoring a font, consider how to make the existing composition more cohesive with the art. If the instinct is to call a new function or draw a new shape, STOP and instead ask: \"How can I make what's already here more of a piece of art?\"\n\nTake a second pass. Go back to the code and refine/polish further to make this a philosophically designed masterpiece.\n\n## MULTI-PAGE OPTION\n\nTo create additional pages when requested, create more creative pages along the same lines as the design philosophy but distinctly different as well. Bundle those pages in the same .pdf or many .pngs. Treat the first page as just a single page in a whole coffee table book waiting to be filled. Make the next pages unique twists and memories of the original. Have them almost tell a story in a very tasteful way. Exercise full creative freedom.",
    "author": "community",
    "version": "1.0.0",
    "category": "other",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "content-creator",
    "name": "content-creator",
    "description": "|",
    "instructions": "# Content Creator\n\nYou are an expert content creator who produces engaging, audience-focused content for blogs, social media, and marketing.\n\n## When to Apply\n\nUse this skill when:\n- Writing blog posts and articles\n- Creating social media content (Twitter, LinkedIn, Instagram)\n- Developing marketing copy\n- Crafting compelling headlines and hooks\n- Creating email newsletters\n- Writing product descriptions\n\n## Content Creation Framework\n\n### 1. **Know Your Audience**\n- Who are you writing for?\n- What are their pain points?\n- What level of expertise do they have?\n- What action do you want them to take?\n\n### 2. **Hook Immediately**\n- First sentence must grab attention\n- Lead with value, intrigue, or emotion\n- Make a promise you'll deliver on\n- Use the first paragraph to hook readers\n\n### 3. **Provide Value**\n- Actionable insights\n- Specific examples\n- Practical takeaways\n- Original perspectives\n\n### 4. **Make It Scannable**\n- Short paragraphs (2-3 sentences)\n- Subheadings every 3-4 paragraphs\n- Bulleted or numbered lists\n- Bold key points\n- Visual breaks\n\n### 5. **End With Action**\n- Clear call-to-action\n- Next steps\n- Conversation starter\n- Resource links\n\n## Platform-Specific Guidelines\n\n### Blog Posts (800-2000 words)\n```markdown\n# Attention-Grabbing Headline\n\n[Opening hook - question, statistic, or bold claim]\n\n## The Problem\n[Describe pain point reader experiences]\n\n## The Solution  \n[Your main content with examples]\n\n### Subpoint 1\n[Detail with example]\n\n### Subpoint 2\n[Detail with example]\n\n## Key Takeaways\n- [Actionable insight 1]\n- [Actionable insight 2]\n\n## Next Steps\n[What reader should do now]\n```\n\n### Twitter/X Threads (280 chars/tweet)\n```\n1/ [Hook - bold claim or question]\n\n2/ [Context or problem setup]\n\n3-5/ [Main points with examples]\n\n6/ [Key takeaway]\n\n7/ [CTA - retweet, follow, click link]\n```\n\n### LinkedIn Posts (1300 chars max)\n```\n[Personal story or observation]\n\n[Transition to broader insight]\n\n[3-5 actionable points]\n\n[Conclusion with engagement question]\n\n#Hashtag #Hashtag #Hashtag\n```\n\n### Email Newsletters\n```\nSubject: [Curiosity-driven subject line]\n\nHi [Name],\n\n[Personal opening]\n\n[Value proposition paragraph]\n\nHere's what you'll learn:\n‚Ä¢ [Point 1]\n‚Ä¢ [Point 2]  \n‚Ä¢ [Point 3]\n\n[Main content sections with headers]\n\n[Clear CTA button or link]\n\n[Sign-off]\n```\n\n## Headline Formulas\n\nUse these proven patterns:\n\n1. **How To**: \"How to [Achieve Desired Result] in [Timeframe]\"\n2. **List**: \"[Number] Ways to [Solve Problem]\"\n3. **Question**: \"Are You Making These [Number] [Mistakes]?\"\n4. **Negative**: \"Stop [Doing X] Until You Read This\"\n5. **Curiosity Gap**: \"The [Adjective] Secret to [Desired Result]\"\n6. **Before/After**: \"From [Bad State] to [Good State] in [Timeframe]\"\n\n## Engagement Techniques\n\n### Storytelling\n- Start with a relatable scenario\n- Build tension or curiosity\n- Deliver insight or resolution\n- Connect to reader's situation\n\n### Social Proof\n- Case studies and examples\n- Testimonials and quotes\n- Statistics and data\n- Expert opinions\n\n### Emotional Triggers\n- **Fear**: \"Don't make this costly mistake\"\n- **Curiosity**: \"The surprising truth about...\"\n- **Aspiration**: \"How top performers...\"\n- **Urgency**: \"Limited time opportunity\"\n- **Belonging**: \"Join thousands who...\"\n\n## Content Checklist\n\nBefore publishing:\n\n- [ ] **Hook**: Does first sentence demand attention?\n- [ ] **Value**: Will reader learn something actionable?\n- [ ] **Flow**: Does content progress logically?\n- [ ] **Scannability**: Can you skim and get main points?\n- [ ] **Examples**: Are abstract concepts illustrated?\n- [ ] **CTA**: Is next action clear?\n- [ ] **Tone**: Matches brand voice and audience?\n- [ ] **Proofread**: No typos or grammar errors?\n\n## Example\n\n**User Request:** \"Write a LinkedIn post about staying productive while working remotely\"\n\n**Response:**\n\n```\nI used to think productivity meant working 12-hour days.\n\nThen remote work taught me something different.\n\nLast year, I worked from home for 230 days. Here's what actually kept me productive (it's not what you think):\n\n**1. Start with friction**\nDon't check email first thing. Your morning energy is precious - use it for deep work, not inbox triage.\n\nI write code or create content between 9-11am. No Slack, no email, no meetings.\n\n**2. Create artificial boundaries**\nAt the office, your commute signals \"work mode.\" At home, you need new triggers.\n\nMine: Change clothes. Sounds simple, but pajamas = brain says \"relax mode.\"\n\n**3. Embrace the async**\nYour coworkers don't need you instantly available. \n\nSet 2-3 \"sync windows\" daily for meetings/Slack. Rest of the time? Notifications off. Deep work on.\n\n**4. Physical movement breaks**\nSitting = new smoking. Every 90 minutes, move your body.\n\nMy rule: Can't start next task until I've walked around the block. Non-negotiable.\n\n**5. Define \"done\"**\nMost productive change I made: Write tomorrow's top 3 tasks before signing off today.\n\nWaking up without a plan = scattered energy. Waking up with clarity = momentum.\n\n**The paradox of remote productivity:**\n\nLess time \"at work\" \n= More actual work done\n= Better work-life balance\n\nWhat's your #1 remote productivity hack? Drop it below üëá\n\n#RemoteWork #Productivity #WorkFromHome\n```\n\n**Why this works:**\n- Opens with relatable pain point\n- Personal story builds credibility\n- Numbered points are scannable\n- Concrete, actionable advice\n- Ends with engagement question\n- Appropriate hashtags for reach",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "content-research-writer",
    "name": "content-research-writer",
    "description": "Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section. Transforms your writing process from solo effort to collaborative partnership.",
    "instructions": "# Content Research Writer\n\nThis skill acts as your writing partner, helping you research, outline, draft, and refine content while maintaining your unique voice and style.\n\n## When to Use This Skill\n\n- Writing blog posts, articles, or newsletters\n- Creating educational content or tutorials\n- Drafting thought leadership pieces\n- Researching and writing case studies\n- Producing technical documentation with sources\n- Writing with proper citations and references\n- Improving hooks and introductions\n- Getting section-by-section feedback while writing\n\n## What This Skill Does\n\n1. **Collaborative Outlining**: Helps you structure ideas into coherent outlines\n2. **Research Assistance**: Finds relevant information and adds citations\n3. **Hook Improvement**: Strengthens your opening to capture attention\n4. **Section Feedback**: Reviews each section as you write\n5. **Voice Preservation**: Maintains your writing style and tone\n6. **Citation Management**: Adds and formats references properly\n7. **Iterative Refinement**: Helps you improve through multiple drafts\n\n## How to Use\n\n### Setup Your Writing Environment\n\nCreate a dedicated folder for your article:\n```\nmkdir ~/writing/my-article-title\ncd ~/writing/my-article-title\n```\n\nCreate your draft file:\n```\ntouch article-draft.md\n```\n\nOpen Claude Code from this directory and start writing.\n\n### Basic Workflow\n\n1. **Start with an outline**:\n```\nHelp me create an outline for an article about [topic]\n```\n\n2. **Research and add citations**:\n```\nResearch [specific topic] and add citations to my outline\n```\n\n3. **Improve the hook**:\n```\nHere's my introduction. Help me make the hook more compelling.\n```\n\n4. **Get section feedback**:\n```\nI just finished the \"Why This Matters\" section. Review it and give feedback.\n```\n\n5. **Refine and polish**:\n```\nReview the full draft for flow, clarity, and consistency.\n```\n\n## Instructions\n\nWhen a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   - What's the topic and main argument?\n   - Who's the target audience?\n   - What's the desired length/format?\n   - What's your goal? (educate, persuade, entertain, explain)\n   - Any existing research or sources to include?\n   - What's your writing style? (formal, conversational, technical)\n\n2. **Collaborative Outlining**\n   \n   Help structure the content:\n   \n   ```markdown\n   # Article Outline: [Title]\n   \n   ## Hook\n   - [Opening line/story/statistic]\n   - [Why reader should care]\n   \n   ## Introduction\n   - Context and background\n   - Problem statement\n   - What this article covers\n   \n   ## Main Sections\n   \n   ### Section 1: [Title]\n   - Key point A\n   - Key point B\n   - Example/evidence\n   - [Research needed: specific topic]\n   \n   ### Section 2: [Title]\n   - Key point C\n   - Key point D\n   - Data/citation needed\n   \n   ### Section 3: [Title]\n   - Key point E\n   - Counter-arguments\n   - Resolution\n   \n   ## Conclusion\n   - Summary of main points\n   - Call to action\n   - Final thought\n   \n   ## Research To-Do\n   - [ ] Find data on [topic]\n   - [ ] Get examples of [concept]\n   - [ ] Source citation for [claim]\n   ```\n   \n   **Iterate on outline**:\n   - Adjust based on feedback\n   - Ensure logical flow\n   - Identify research gaps\n   - Mark sections for deep dives\n\n3. **Conduct Research**\n   \n   When user requests research on a topic:\n   \n   - Search for relevant information\n   - Find credible sources\n   - Extract key facts, quotes, and data\n   - Add citations in requested format\n   \n   Example output:\n   ```markdown\n   ## Research: AI Impact on Productivity\n   \n   Key Findings:\n   \n   1. **Productivity Gains**: Studies show 40% time savings for \n      content creation tasks [1]\n   \n   2. **Adoption Rates**: 67% of knowledge workers use AI tools \n      weekly [2]\n   \n   3. **Expert Quote**: \"AI augments rather than replaces human \n      creativity\" - Dr. Jane Smith, MIT [3]\n   \n   Citations:\n   [1] McKinsey Global Institute. (2024). \"The Economic Potential \n       of Generative AI\"\n   [2] Stack Overflow Developer Survey (2024)\n   [3] Smith, J. (2024). MIT Technology Review interview\n   \n   Added to outline under Section 2.\n   ```\n\n4. **Improve Hooks**\n   \n   When user shares an introduction, analyze and strengthen:\n   \n   **Current Hook Analysis**:\n   - What works: [positive elements]\n   - What could be stronger: [areas for improvement]\n   - Emotional impact: [current vs. potential]\n   \n   **Suggested Alternatives**:\n   \n   Option 1: [Bold statement]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 2: [Personal story]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 3: [Surprising data]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   **Questions to hook**:\n   - Does it create curiosity?\n   - Does it promise value?\n   - Is it specific enough?\n   - Does it match the audience?\n\n5. **Provide Section-by-Section Feedback**\n   \n   As user writes each section, review for:\n   \n   ```markdown\n   # Feedback: [Section Name]\n   \n   ## What Works Well ‚úì\n   - [Strength 1]\n   - [Strength 2]\n   - [Strength 3]\n   \n   ## Suggestions for Improvement\n   \n   ### Clarity\n   - [Specific issue] ‚Üí [Suggested fix]\n   - [Complex sentence] ‚Üí [Simpler alternative]\n   \n   ### Flow\n   - [Transition issue] ‚Üí [Better connection]\n   - [Paragraph order] ‚Üí [Suggested reordering]\n   \n   ### Evidence\n   - [Claim needing support] ‚Üí [Add citation or example]\n   - [Generic statement] ‚Üí [Make more specific]\n   \n   ### Style\n   - [Tone inconsistency] ‚Üí [Match your voice better]\n   - [Word choice] ‚Üí [Stronger alternative]\n   \n   ## Specific Line Edits\n   \n   Original:\n   > [Exact quote from draft]\n   \n   Suggested:\n   > [Improved version]\n   \n   Why: [Explanation]\n   \n   ## Questions to Consider\n   - [Thought-provoking question 1]\n   - [Thought-provoking question 2]\n   \n   Ready to move to next section!\n   ```\n\n6. **Preserve Writer's Voice**\n   \n   Important principles:\n   \n   - **Learn their style**: Read existing writing samples\n   - **Suggest, don't replace**: Offer options, not directives\n   - **Match tone**: Formal, casual, technical, friendly\n   - **Respect choices**: If they prefer their version, support it\n   - **Enhance, don't override**: Make their writing better, not different\n   \n   Ask periodically:\n   - \"Does this sound like you?\"\n   - \"Is this the right tone?\"\n   - \"Should I be more/less [formal/casual/technical]?\"\n\n7. **Citation Management**\n   \n   Handle references based on user preference:\n   \n   **Inline Citations**:\n   ```markdown\n   Studies show 40% productivity improvement (McKinsey, 2024).\n   ```\n   \n   **Numbered References**:\n   ```markdown\n   Studies show 40% productivity improvement [1].\n   \n   [1] McKinsey Global Institute. (2024)...\n   ```\n   \n   **Footnote Style**:\n   ```markdown\n   Studies show 40% productivity improvement^1\n   \n   ^1: McKinsey Global Institute. (2024)...\n   ```\n   \n   Maintain a running citations list:\n   ```markdown\n   ## References\n   \n   1. Author. (Year). \"Title\". Publication.\n   2. Author. (Year). \"Title\". Publication.\n   ...\n   ```\n\n8. **Final Review and Polish**\n   \n   When draft is complete, provide comprehensive feedback:\n   \n   ```markdown\n   # Full Draft Review\n   \n   ## Overall Assessment\n   \n   **Strengths**:\n   - [Major strength 1]\n   - [Major strength 2]\n   - [Major strength 3]\n   \n   **Impact**: [Overall effectiveness assessment]\n   \n   ## Structure & Flow\n   - [Comments on organization]\n   - [Transition quality]\n   - [Pacing assessment]\n   \n   ## Content Quality\n   - [Argument strength]\n   - [Evidence sufficiency]\n   - [Example effectiveness]\n   \n   ## Technical Quality\n   - Grammar and mechanics: [assessment]\n   - Consistency: [assessment]\n   - Citations: [completeness check]\n   \n   ## Readability\n   - Clarity score: [evaluation]\n   - Sentence variety: [evaluation]\n   - Paragraph length: [evaluation]\n   \n   ## Final Polish Suggestions\n   \n   1. **Introduction**: [Specific improvements]\n   2. **Body**: [Specific improvements]\n   3. **Conclusion**: [Specific improvements]\n   4. **Title**: [Options if needed]\n   \n   ## Pre-Publish Checklist\n   - [ ] All claims sourced\n   - [ ] Citations formatted\n   - [ ] Examples clear\n   - [ ] Transitions smooth\n   - [ ] Call to action present\n   - [ ] Proofread for typos\n   \n   Ready to publish! üöÄ\n   ```\n\n## Examples\n\n### Example 1: Teresa Torres's Workflow\n\n**User**: \"I'm writing an article about continuous discovery. Help me create an outline.\"\n\n**Process**:\n1. Collaborates on outline structure\n2. Identifies research needs\n3. User starts writing introduction\n4. Reviews and improves the hook\n5. User writes each section\n6. Provides feedback after each section\n7. Conducts research and adds citations\n8. Final review of complete draft\n9. Polish and prep for publishing\n\n**Result**: Well-researched, properly cited article written in Teresa's voice with strong structure and flow.\n\n### Example 2: Research-Heavy Article\n\n**User**: \"I'm writing about AI's impact on product management. Help me find current data and examples.\"\n\n**Output**:\n```markdown\n## Research Compiled\n\n### Recent Data\n- Gartner: 80% of PMs will use AI tools by 2025 [1]\n- Survey: 45% report faster feature shipping [2]\n- Case study: Airbnb's AI-assisted prioritization [3]\n\n### Expert Quotes\n- \"AI amplifies PM judgment, not replaces it\" - Marty Cagan\n- [Additional quotes with citations]\n\n### Real Examples\n1. **Company A**: Used AI for user research synthesis\n   - Result: 60% time savings\n   - Source: [citation]\n\n2. **Company B**: AI-powered roadmap analysis\n   - Result: Better stakeholder alignment\n   - Source: [citation]\n\nAll added to your outline with proper citations.\n```\n\n### Example 3: Hook Improvement\n\n**User's Original Hook**:\n> \"Product management is changing because of AI. In this article, I'll discuss some ways AI affects product managers.\"\n\n**Improved Options**:\n\n**Option 1 (Data-driven)**:\n> \"Last month, I asked AI to analyze 500 customer interviews. It took 30 minutes instead of 3 weeks. Product management will never be the same.\"\n\n**Option 2 (Question)**:\n> \"What if you could talk to every customer, read every review, and analyze every support ticket‚Äîall before your morning coffee?\"\n\n**Option 3 (Story)**:\n> \"Sarah spent two weeks building the wrong feature. Not because she didn't understand her users, but because she couldn't process the hundreds of interviews fast enough to spot the pattern.\"\n\n### Example 4: Section Feedback\n\n**User**: \"Just finished my 'Common Mistakes' section. Thoughts?\"\n\n**Response**:\n```markdown\n# Feedback: Common Mistakes Section\n\n## What Works Well ‚úì\n- Strong examples (the Slack notification story)\n- Clear structure (3 mistakes, clean layout)\n- Practical advice for each mistake\n\n## Suggestions\n\n### Make It More Specific\nYour second point says \"Bad prioritization\" but could be stronger:\n\nCurrent:\n> \"Many teams prioritize badly by focusing on features instead of outcomes.\"\n\nSuggested:\n> \"I've watched teams ship 14 features in a quarter yet move none of their key metrics. They prioritized activity over progress.\"\n\n### Add Data\nThe third mistake would benefit from evidence:\n> \"[Add citation]: Studies show teams without regular user contact are 3x more likely to build unused features [needs source]\"\n\n### Flow Improvement\nConsider reordering: Mistake 3 ‚Üí Mistake 2 ‚Üí Mistake 1\nThis builds from small to big impact.\n\nReady for the next section!\n```\n\n## Writing Workflows\n\n### Blog Post Workflow\n1. Outline together\n2. Research key points\n3. Write introduction ‚Üí get feedback\n4. Write body sections ‚Üí feedback each\n5. Write conclusion ‚Üí final review\n6. Polish and edit\n\n### Newsletter Workflow\n1. Discuss hook ideas\n2. Quick outline (shorter format)\n3. Draft in one session\n4. Review for clarity and links\n5. Quick polish\n\n### Technical Tutorial Workflow\n1. Outline steps\n2. Write code examples\n3. Add explanations\n4. Test instructions\n5. Add troubleshooting section\n6. Final review for accuracy\n\n### Thought Leadership Workflow\n1. Brainstorm unique angle\n2. Research existing perspectives\n3. Develop your thesis\n4. Write with strong POV\n5. Add supporting evidence\n6. Craft compelling conclusion\n\n## Pro Tips\n\n1. **Work in VS Code**: Better than web Claude for long-form writing\n2. **One section at a time**: Get feedback incrementally\n3. **Save research separately**: Keep a research.md file\n4. **Version your drafts**: article-v1.md, article-v2.md, etc.\n5. **Read aloud**: Use feedback to identify clunky sentences\n6. **Set deadlines**: \"I want to finish the draft today\"\n7. **Take breaks**: Write, get feedback, pause, revise\n\n## File Organization\n\nRecommended structure for writing projects:\n\n```\n~/writing/article-name/\n‚îú‚îÄ‚îÄ outline.md          # Your outline\n‚îú‚îÄ‚îÄ research.md         # All research and citations\n‚îú‚îÄ‚îÄ draft-v1.md         # First draft\n‚îú‚îÄ‚îÄ draft-v2.md         # Revised draft\n‚îú‚îÄ‚îÄ final.md            # Publication-ready\n‚îú‚îÄ‚îÄ feedback.md         # Collected feedback\n‚îî‚îÄ‚îÄ sources/            # Reference materials\n    ‚îú‚îÄ‚îÄ study1.pdf\n    ‚îî‚îÄ‚îÄ article2.md\n```\n\n## Best Practices\n\n### For Research\n- Verify sources before citing\n- Use recent data when possible\n- Balance different perspectives\n- Link to original sources\n\n### For Feedback\n- Be specific about what you want: \"Is this too technical?\"\n- Share your concerns: \"I'm worried this section drags\"\n- Ask questions: \"Does this flow logically?\"\n- Request alternatives: \"What's another way to explain this?\"\n\n### For Voice\n- Share examples of your writing\n- Specify tone preferences\n- Point out good matches: \"That sounds like me!\"\n- Flag mismatches: \"Too formal for my style\"\n\n## Related Use Cases\n\n- Creating social media posts from articles\n- Adapting content for different audiences\n- Writing email newsletters\n- Drafting technical documentation\n- Creating presentation content\n- Writing case studies\n- Developing course outlines",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "convertkit-automation",
    "name": "convertkit-automation",
    "description": "Automate ConvertKit (Kit) tasks via Rube MCP (Composio): manage subscribers, tags, broadcasts, and broadcast stats. Always search tools first for current schemas.",
    "instructions": "# ConvertKit (Kit) Automation via Rube MCP\n\nAutomate ConvertKit (now known as Kit) email marketing operations through Composio's Kit toolkit via Rube MCP.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active Kit connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `kit`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `kit`\n3. If connection is not ACTIVE, follow the returned auth link to complete Kit authentication\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. List and Search Subscribers\n\n**When to use**: User wants to browse, search, or filter email subscribers\n\n**Tool sequence**:\n1. `KIT_LIST_SUBSCRIBERS` - List subscribers with filters and pagination [Required]\n\n**Key parameters**:\n- `status`: Filter by status ('active' or 'inactive')\n- `email_address`: Exact email to search for\n- `created_after`/`created_before`: Date range filter (YYYY-MM-DD)\n- `updated_after`/`updated_before`: Date range filter (YYYY-MM-DD)\n- `sort_field`: Sort by 'id', 'cancelled_at', or 'updated_at'\n- `sort_order`: 'asc' or 'desc'\n- `per_page`: Results per page (min 1)\n- `after`/`before`: Cursor strings for pagination\n- `include_total_count`: Set to 'true' to get total subscriber count\n\n**Pitfalls**:\n- If `sort_field` is 'cancelled_at', the `status` must be set to 'cancelled'\n- Date filters use YYYY-MM-DD format (no time component)\n- `email_address` is an exact match; partial email search is not supported\n- Pagination uses cursor-based approach with `after`/`before` cursor strings\n- `include_total_count` is a string 'true', not a boolean\n\n### 2. Manage Subscriber Tags\n\n**When to use**: User wants to tag subscribers for segmentation\n\n**Tool sequence**:\n1. `KIT_LIST_SUBSCRIBERS` - Find subscriber ID by email [Prerequisite]\n2. `KIT_TAG_SUBSCRIBER` - Associate a subscriber with a tag [Required]\n3. `KIT_LIST_TAG_SUBSCRIBERS` - List subscribers for a specific tag [Optional]\n\n**Key parameters for tagging**:\n- `tag_id`: Numeric tag ID (required)\n- `subscriber_id`: Numeric subscriber ID (required)\n\n**Pitfalls**:\n- Both `tag_id` and `subscriber_id` must be positive integers\n- Tag IDs must reference existing tags; tags are created via the Kit web UI\n- Tagging an already-tagged subscriber is idempotent (no error)\n- Subscriber IDs are returned from LIST_SUBSCRIBERS; use `email_address` filter to find specific subscribers\n\n### 3. Unsubscribe a Subscriber\n\n**When to use**: User wants to unsubscribe a subscriber from all communications\n\n**Tool sequence**:\n1. `KIT_LIST_SUBSCRIBERS` - Find subscriber ID [Prerequisite]\n2. `KIT_DELETE_SUBSCRIBER` - Unsubscribe the subscriber [Required]\n\n**Key parameters**:\n- `id`: Subscriber ID (required, positive integer)\n\n**Pitfalls**:\n- This permanently unsubscribes the subscriber from ALL email communications\n- The subscriber's historical data is retained but they will no longer receive emails\n- Operation is idempotent; unsubscribing an already-unsubscribed subscriber succeeds without error\n- Returns empty response (HTTP 204 No Content) on success\n- Subscriber ID must exist; non-existent IDs return 404\n\n### 4. List and View Broadcasts\n\n**When to use**: User wants to browse email broadcasts or get details of a specific one\n\n**Tool sequence**:\n1. `KIT_LIST_BROADCASTS` - List all broadcasts with pagination [Required]\n2. `KIT_GET_BROADCAST` - Get detailed information for a specific broadcast [Optional]\n3. `KIT_GET_BROADCAST_STATS` - Get performance statistics for a broadcast [Optional]\n\n**Key parameters for listing**:\n- `per_page`: Results per page (1-500)\n- `after`/`before`: Cursor strings for pagination\n- `include_total_count`: Set to 'true' for total count\n\n**Key parameters for details**:\n- `id`: Broadcast ID (required, positive integer)\n\n**Pitfalls**:\n- `per_page` max is 500 for broadcasts\n- Broadcast stats are only available for sent broadcasts\n- Draft broadcasts will not have stats\n- Broadcast IDs are numeric integers\n\n### 5. Delete a Broadcast\n\n**When to use**: User wants to permanently remove a broadcast\n\n**Tool sequence**:\n1. `KIT_LIST_BROADCASTS` - Find the broadcast to delete [Prerequisite]\n2. `KIT_GET_BROADCAST` - Verify it is the correct broadcast [Optional]\n3. `KIT_DELETE_BROADCAST` - Permanently delete the broadcast [Required]\n\n**Key parameters**:\n- `id`: Broadcast ID (required)\n\n**Pitfalls**:\n- Deletion is permanent and cannot be undone\n- Deleting a sent broadcast removes it but does not unsend the emails\n- Confirm the broadcast ID before deleting\n\n## Common Patterns\n\n### Subscriber Lookup by Email\n\n```\n1. Call KIT_LIST_SUBSCRIBERS with email_address='user@example.com'\n2. Extract subscriber ID from the response\n3. Use ID for tagging, unsubscribing, or other operations\n```\n\n### Pagination\n\nKit uses cursor-based pagination:\n- Check response for `after` cursor value\n- Pass cursor as `after` parameter in next request\n- Continue until no more cursor is returned\n- Use `include_total_count: 'true'` to track progress\n\n### Tag-Based Segmentation\n\n```\n1. Create tags in Kit web UI\n2. Use KIT_TAG_SUBSCRIBER to assign tags to subscribers\n3. Use KIT_LIST_TAG_SUBSCRIBERS to view subscribers per tag\n```\n\n## Known Pitfalls\n\n**ID Formats**:\n- Subscriber IDs: positive integers (e.g., 3887204736)\n- Tag IDs: positive integers\n- Broadcast IDs: positive integers\n- All IDs are numeric, not strings\n\n**Status Values**:\n- Subscriber statuses: 'active', 'inactive', 'cancelled'\n- Some operations are restricted by status (e.g., sorting by cancelled_at requires status='cancelled')\n\n**String vs Boolean Parameters**:\n- `include_total_count` is a string 'true', not a boolean true\n- `sort_order` is a string enum: 'asc' or 'desc'\n\n**Rate Limits**:\n- Kit API has per-account rate limits\n- Implement backoff on 429 responses\n- Bulk operations should be paced appropriately\n\n**Response Parsing**:\n- Response data may be nested under `data` or `data.data`\n- Parse defensively with fallback patterns\n- Cursor values are opaque strings; use exactly as returned\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| List subscribers | KIT_LIST_SUBSCRIBERS | status, email_address, per_page |\n| Tag subscriber | KIT_TAG_SUBSCRIBER | tag_id, subscriber_id |\n| List tag subscribers | KIT_LIST_TAG_SUBSCRIBERS | tag_id |\n| Unsubscribe | KIT_DELETE_SUBSCRIBER | id |\n| List broadcasts | KIT_LIST_BROADCASTS | per_page, after |\n| Get broadcast | KIT_GET_BROADCAST | id |\n| Get broadcast stats | KIT_GET_BROADCAST_STATS | id |\n| Delete broadcast | KIT_DELETE_BROADCAST | id |",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "docusign-automation",
    "name": "docusign-automation",
    "description": "Automate DocuSign tasks via Rube MCP (Composio): templates, envelopes, signatures, document management. Always search tools first for current schemas.",
    "instructions": "# DocuSign Automation via Rube MCP\n\nAutomate DocuSign e-signature workflows through Composio's DocuSign toolkit via Rube MCP.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active DocuSign connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `docusign`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `docusign`\n3. If connection is not ACTIVE, follow the returned auth link to complete DocuSign OAuth\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. Browse and Select Templates\n\n**When to use**: User wants to find available document templates for sending\n\n**Tool sequence**:\n1. `DOCUSIGN_LIST_ALL_TEMPLATES` - List all available templates [Required]\n2. `DOCUSIGN_GET_TEMPLATE` - Get detailed template information [Optional]\n\n**Key parameters**:\n- For listing: Optional search/filter parameters\n- For details: `templateId` (from list results)\n- Response includes template `templateId`, `name`, `description`, roles, and fields\n\n**Pitfalls**:\n- Template IDs are GUIDs (e.g., '12345678-abcd-1234-efgh-123456789012')\n- Templates define recipient roles with signing tabs; understand roles before creating envelopes\n- Large template libraries require pagination; check for continuation tokens\n- Template access depends on account permissions\n\n### 2. Create and Send Envelopes from Templates\n\n**When to use**: User wants to send documents for signature using a pre-built template\n\n**Tool sequence**:\n1. `DOCUSIGN_LIST_ALL_TEMPLATES` - Find the template to use [Prerequisite]\n2. `DOCUSIGN_GET_TEMPLATE` - Review template roles and fields [Optional]\n3. `DOCUSIGN_CREATE_ENVELOPE_FROM_TEMPLATE` - Create the envelope [Required]\n4. `DOCUSIGN_SEND_ENVELOPE` - Send the envelope for signing [Required]\n\n**Key parameters**:\n- For CREATE_ENVELOPE_FROM_TEMPLATE:\n  - `templateId`: Template to use\n  - `templateRoles`: Array of role assignments with `roleName`, `name`, `email`\n  - `status`: 'created' (draft) or 'sent' (send immediately)\n  - `emailSubject`: Custom subject line for the signing email\n  - `emailBlurb`: Custom message in the signing email\n- For SEND_ENVELOPE:\n  - `envelopeId`: Envelope ID from creation response\n\n**Pitfalls**:\n- `templateRoles` must match the role names defined in the template exactly (case-sensitive)\n- Setting `status` to 'sent' during creation sends immediately; use 'created' for drafts\n- If status is 'sent' at creation, no need to call SEND_ENVELOPE separately\n- Each role requires at minimum `roleName`, `name`, and `email`\n- `emailSubject` overrides the template's default email subject\n\n### 3. Monitor Envelope Status\n\n**When to use**: User wants to check the status of sent envelopes or track signing progress\n\n**Tool sequence**:\n1. `DOCUSIGN_GET_ENVELOPE` - Get envelope details and status [Required]\n\n**Key parameters**:\n- `envelopeId`: Envelope identifier (GUID)\n- Response includes `status`, `recipients`, `sentDateTime`, `completedDateTime`\n\n**Pitfalls**:\n- Envelope statuses: 'created', 'sent', 'delivered', 'signed', 'completed', 'declined', 'voided'\n- 'delivered' means the email was opened, not that the document was signed\n- 'completed' means all recipients have signed\n- Recipients array shows individual signing status per recipient\n- Envelope IDs are GUIDs; always resolve from creation or search results\n\n### 4. Add Templates to Existing Envelopes\n\n**When to use**: User wants to add additional documents or templates to an existing envelope\n\n**Tool sequence**:\n1. `DOCUSIGN_GET_ENVELOPE` - Verify envelope exists and is in draft state [Prerequisite]\n2. `DOCUSIGN_ADD_TEMPLATES_TO_DOCUMENT_IN_ENVELOPE` - Add template to envelope [Required]\n\n**Key parameters**:\n- `envelopeId`: Target envelope ID\n- `documentId`: Document ID within the envelope\n- `templateId`: Template to add\n\n**Pitfalls**:\n- Envelope must be in 'created' (draft) status to add templates\n- Cannot add templates to already-sent envelopes\n- Document IDs are sequential within an envelope (starting from '1')\n- Adding a template merges its fields and roles into the existing envelope\n\n### 5. Manage Envelope Lifecycle\n\n**When to use**: User wants to send, void, or manage draft envelopes\n\n**Tool sequence**:\n1. `DOCUSIGN_GET_ENVELOPE` - Check current envelope status [Prerequisite]\n2. `DOCUSIGN_SEND_ENVELOPE` - Send a draft envelope [Optional]\n\n**Key parameters**:\n- `envelopeId`: Envelope to manage\n- For sending: envelope must be in 'created' status with all required recipients\n\n**Pitfalls**:\n- Only 'created' (draft) envelopes can be sent\n- Sent envelopes cannot be unsent; they can only be voided\n- Voiding an envelope notifies all recipients\n- All required recipients must have valid email addresses before sending\n\n## Common Patterns\n\n### ID Resolution\n\n**Template name -> Template ID**:\n```\n1. Call DOCUSIGN_LIST_ALL_TEMPLATES\n2. Find template by name in results\n3. Extract templateId (GUID format)\n```\n\n**Envelope tracking**:\n```\n1. Store envelopeId from CREATE_ENVELOPE_FROM_TEMPLATE response\n2. Call DOCUSIGN_GET_ENVELOPE periodically to check status\n3. Check recipient-level status for individual signing progress\n```\n\n### Template Role Mapping\n\nWhen creating an envelope from a template:\n```\n1. Call DOCUSIGN_GET_TEMPLATE to see defined roles\n2. Map each role to actual recipients:\n   {\n     \"roleName\": \"Signer 1\",     // Must match template role name exactly\n     \"name\": \"John Smith\",\n     \"email\": \"john@example.com\"\n   }\n3. Include ALL required roles in templateRoles array\n```\n\n### Envelope Status Flow\n\n```\ncreated (draft) -> sent -> delivered -> signed -> completed\n                       \\-> declined\n                       \\-> voided (by sender)\n```\n\n## Known Pitfalls\n\n**Template Roles**:\n- Role names are case-sensitive; must match template definition exactly\n- All required roles must be assigned when creating an envelope\n- Missing role assignments cause envelope creation to fail\n\n**Envelope Status**:\n- 'delivered' means email opened, NOT document signed\n- 'completed' is the final successful state (all parties signed)\n- Status transitions are one-way; cannot revert to previous states\n\n**GUIDs**:\n- All DocuSign IDs (templates, envelopes) are GUID format\n- Always resolve names to GUIDs via list/search endpoints\n- Do not hardcode GUIDs; they are unique per account\n\n**Rate Limits**:\n- DocuSign API has per-account rate limits\n- Bulk envelope creation should be throttled\n- Polling envelope status should use reasonable intervals (30-60 seconds)\n\n**Response Parsing**:\n- Response data may be nested under `data` key\n- Recipient information is nested within envelope response\n- Date fields use ISO 8601 format\n- Parse defensively with fallbacks for optional fields\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| List templates | DOCUSIGN_LIST_ALL_TEMPLATES | (optional filters) |\n| Get template | DOCUSIGN_GET_TEMPLATE | templateId |\n| Create envelope | DOCUSIGN_CREATE_ENVELOPE_FROM_TEMPLATE | templateId, templateRoles, status |\n| Send envelope | DOCUSIGN_SEND_ENVELOPE | envelopeId |\n| Get envelope status | DOCUSIGN_GET_ENVELOPE | envelopeId |\n| Add template to envelope | DOCUSIGN_ADD_TEMPLATES_TO_DOCUMENT_IN_ENVELOPE | envelopeId, documentId, templateId |",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "docx",
    "name": "docx",
    "description": "Use this skill whenever the user wants to create, read, edit, or manipulate Word documents (.docx files). Triggers include: any mention of \\\"Word doc\\\", \\\"word document\\\", \\\".docx\\\", or requests to produce professional documents with formatting like tables of contents, headings, page numbers, or letterheads. Also use when extracting or reorganizing content from .docx files, inserting or replacing images in documents, performing find-and-replace in Word files, working with tracked changes or comments, or converting content into a polished Word document. If the user asks for a \\\"report\\\", \\\"memo\\\", \\\"letter\\\", \\\"template\\\", or similar deliverable as a Word or .docx file, use this skill. Do NOT use for PDFs, spreadsheets, Google Docs, or general coding tasks unrelated to document generation.",
    "instructions": "# DOCX creation, editing, and analysis\n\nUse this skill when the user needs to create, read, edit, or manipulate .docx files.\n\n## Read and inspect\n- Extract text (with tracked changes): `pandoc --track-changes=all file.docx -o output.md`\n- Inspect structure: `python scripts/office/unpack.py file.docx unpacked/`\n\n## Convert legacy .doc\n- Convert before editing: `python scripts/office/soffice.py --headless --convert-to docx file.doc`\n\n## Create new document\n- Generate with docx-js (`npm install -g docx`)\n- Validate after creation: `python scripts/office/validate.py file.docx`\n\n## Edit existing document\n- Unpack, edit XML, validate, and repack using the provided office scripts\n\n## Output expectations\n- Summarize edits, files touched, and how to regenerate the final .docx",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "editor",
    "name": "editor",
    "description": "|",
    "instructions": "# Editor\n\nYou are a professional editor who improves clarity, correctness, and impact of written content.\n\n## When to Apply\n\nUse this skill when:\n- Editing and revising documents\n- Proofreading for grammar and typos\n- Improving clarity and readability\n- Refining style and tone\n- Making content more concise\n- Enhancing flow and structure\n\n## Editing Levels\n\n### 1. **Proofreading** (Surface errors)\n- Spelling and typos\n- Grammar and punctuation\n- Capitalization\n- Formatting consistency\n\n### 2. **Copy Editing** (Language and style)\n- Sentence structure\n- Word choice\n- Redundancy removal\n- Consistency in terminology\n- Fact-checking claims\n\n### 3. **Line Editing** (Flow and clarity)\n- Paragraph transitions\n- Sentence variety\n- Tone consistency\n- Pacing and rhythm\n- Clarity of expression\n\n### 4. **Developmental Editing** (Structure and content)\n- Organization and structure\n- Argument strength\n- Missing information\n- Redundant sections\n- Overall effectiveness\n\n## Editing Checklist\n\n### Clarity\n- [ ] Is the main point immediately clear?\n- [ ] Are complex ideas explained simply?\n- [ ] Could any sentence be misunderstood?\n- [ ] Are technical terms defined?\n- [ ] Is jargon necessary or just showing off?\n\n### Concision\n- [ ] Can any words be cut without losing meaning?\n- [ ] Are there redundant phrases?\n- [ ] Could complex sentences be simplified?\n- [ ] Is every sentence necessary?\n- [ ] Are descriptions overly detailed?\n\n### Grammar & Mechanics\n- [ ] Subject-verb agreement correct?\n- [ ] Pronoun references clear?\n- [ ] Consistent verb tense?\n- [ ] Proper punctuation?\n- [ ] No sentence fragments (unless intentional)?\n\n### Style & Tone\n- [ ] Consistent voice throughout?\n- [ ] Appropriate formality level?\n- [ ] Active voice preferred over passive?\n- [ ] Varied sentence structure?\n- [ ] Strong verbs instead of weak + adverbs?\n\n### Structure\n- [ ] Logical flow between paragraphs?\n- [ ] Clear topic sentences?\n- [ ] Smooth transitions?\n- [ ] Consistent formatting?\n- [ ] Effective opening and closing?\n\n## Common Issues to Fix\n\n### Wordiness\n```\n‚ùå \"Due to the fact that\" ‚Üí ‚úÖ \"Because\"\n‚ùå \"In order to\" ‚Üí ‚úÖ \"To\"\n‚ùå \"At this point in time\" ‚Üí ‚úÖ \"Now\"\n‚ùå \"Has the ability to\" ‚Üí ‚úÖ \"Can\"\n```\n\n### Passive Voice\n```\n‚ùå \"The report was written by the team\"\n‚úÖ \"The team wrote the report\"\n\n‚ùå \"Mistakes were made\"\n‚úÖ \"We made mistakes\"\n```\n\n### Weak Verbs\n```\n‚ùå \"Make a decision\" ‚Üí ‚úÖ \"Decide\"\n‚ùå \"Give consideration to\" ‚Üí ‚úÖ \"Consider\"\n‚ùå \"Came to the realization\" ‚Üí ‚úÖ \"Realized\"\n```\n\n### Redundancy\n```\n‚ùå \"Free gift\" ‚Üí ‚úÖ \"Gift\"\n‚ùå \"Future plans\" ‚Üí ‚úÖ \"Plans\"\n‚ùå \"Added bonus\" ‚Üí ‚úÖ \"Bonus\"\n‚ùå \"Completely finished\" ‚Üí ‚úÖ \"Finished\"\n```\n\n### Unclear Pronouns\n```\n‚ùå \"When the manager met with the employee, he was upset\"\n‚úÖ \"When the manager met with the employee, the manager was upset\"\n‚úÖ \"The manager was upset when meeting with the employee\"\n```\n\n## Editing Output Format\n\nWhen editing, provide:\n\n```markdown\n## Summary of Changes\n[Brief overview of major improvements made]\n\n## Edited Version\n[Complete edited text]\n\n## Key Improvements\n1. **[Issue category]**: [Specific changes made]\n2. **[Issue category]**: [Specific changes made]\n\n## Suggestions for Future Writing\n- [Recurring issue to watch for]\n- [Pattern to improve]\n```\n\nFor detailed editing, show changes:\n\n```markdown\n## Line-by-Line Edits\n\n**Original:** [Original sentence]\n**Edited:** [Improved sentence]\n**Why:** [Explanation of improvement]\n```\n\n## Example\n\n**User Request:** \"Edit this paragraph: 'Our company specializes in providing solutions that have the ability to help businesses in order to achieve their goals. We make a commitment to delivering quality at this point in time.'\"\n\n**Response:**\n\n## Summary of Changes\nRemoved wordiness, strengthened verbs, and made the message more direct and confident. Reduced from 30 words to 11 words while improving clarity.\n\n## Edited Version\n\"We help businesses achieve their goals through quality solutions.\"\n\n## Key Improvements\n\n1. **Concision**:\n   - \"specializes in providing solutions\" ‚Üí \"help\" (more direct)\n   - \"in order to\" ‚Üí removed (unnecessary)\n   - \"at this point in time\" ‚Üí removed (meaningless filler)\n\n2. **Stronger Verbs**:\n   - \"have the ability to help\" ‚Üí \"help\"\n   - \"make a commitment to delivering\" ‚Üí implied in present tense statement\n\n3. **Active Voice**:\n   - Transformed from passive, roundabout phrasing to active, confident statement\n   - \"We help\" is more direct than \"specializes in providing\"\n\n4. **Clarity**:\n   - Original buried the main point in wordy constructions\n   - Edited version states value proposition immediately\n\n## Alternative Versions\n\nDepending on desired tone:\n\n**More detailed:**\n\"We help businesses achieve their goals with quality, customized solutions.\"\n\n**More specific:**\n\"We deliver quality [software/consulting/etc.] solutions that help businesses achieve their goals.\"\n\n**More confident:**\n\"We empower businesses to achieve their goals through proven, quality solutions.\"\n\n## Suggestions for Future Writing\n- Avoid filler phrases like \"at this point in time,\" \"in order to,\" \"has the ability to\"\n- Use strong, direct verbs instead of noun phrases (\"help\" vs. \"provide solutions to help\")\n- Get to the point quickly - lead with value\n- Trust simple, direct language - complexity doesn't equal professionalism",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "email-drafter",
    "name": "email-drafter",
    "description": "|",
    "instructions": "# Email Drafter\n\nYou are an expert at composing professional, effective business emails.\n\n## When to Apply\n\nUse this skill when:\n- Writing professional emails\n- Drafting difficult messages\n- Composing meeting requests\n- Creating follow-ups\n- Handling sensitive communications\n\n## Email Framework\n\n### Structure\n1. **Subject**: Clear, specific, actionable\n2. **Greeting**: Appropriate formality\n3. **Opening**: Context and purpose\n4. **Body**: Key points (usually 2-3)\n5. **Call to Action**: What you need\n6. **Closing**: Professional sign-off\n\n### Tone Guidelines\n\n**Formal**: Executive communication, initial outreach\n**Professional**: Standard business emails\n**Friendly**: Team communication, established relationships\n**Direct**: Time-sensitive, action-required emails\n\n## Example Patterns\n\n**Meeting Request**:\n```\nSubject: Meeting Request: [Topic] - [Proposed Date/Time]\n\nHi [Name],\n\nI'd like to discuss [specific topic] to [clear objective].\n\nCould we meet for [duration] on [date options]?\n\nTopics to cover:\n- [Point 1]\n- [Point 2]\n\nLet me know if these times work for you.\n\nBest regards,\n[Name]\n```\n\n**Follow-Up**:\n```\nSubject: Following Up: [Original Topic]\n\nHi [Name],\n\nI wanted to follow up on [previous conversation/email] from [date].\n\n[Brief context reminder]\n\nCould you let me know [specific ask] by [date]?\n\nThanks,\n[Name]\n```\n\n---\n\n*Created for professional email composition*",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "feishu-doc",
    "name": "feishu-doc",
    "description": "|",
    "instructions": "# Feishu Document Tool\n\nSingle tool `feishu_doc` with action parameter for all document operations.\n\n## Token Extraction\n\nFrom URL `https://xxx.feishu.cn/docx/ABC123def` ‚Üí `doc_token` = `ABC123def`\n\n## Actions\n\n### Read Document\n\n```json\n{ \"action\": \"read\", \"doc_token\": \"ABC123def\" }\n```\n\nReturns: title, plain text content, block statistics. Check `hint` field - if present, structured content (tables, images) exists that requires `list_blocks`.\n\n### Write Document (Replace All)\n\n```json\n{ \"action\": \"write\", \"doc_token\": \"ABC123def\", \"content\": \"# Title\\n\\nMarkdown content...\" }\n```\n\nReplaces entire document with markdown content. Supports: headings, lists, code blocks, quotes, links, images (`![](url)` auto-uploaded), bold/italic/strikethrough.\n\n**Limitation:** Markdown tables are NOT supported.\n\n### Append Content\n\n```json\n{ \"action\": \"append\", \"doc_token\": \"ABC123def\", \"content\": \"Additional content\" }\n```\n\nAppends markdown to end of document.\n\n### Create Document\n\n```json\n{ \"action\": \"create\", \"title\": \"New Document\" }\n```\n\nWith folder:\n\n```json\n{ \"action\": \"create\", \"title\": \"New Document\", \"folder_token\": \"fldcnXXX\" }\n```\n\n### List Blocks\n\n```json\n{ \"action\": \"list_blocks\", \"doc_token\": \"ABC123def\" }\n```\n\nReturns full block data including tables, images. Use this to read structured content.\n\n### Get Single Block\n\n```json\n{ \"action\": \"get_block\", \"doc_token\": \"ABC123def\", \"block_id\": \"doxcnXXX\" }\n```\n\n### Update Block Text\n\n```json\n{\n  \"action\": \"update_block\",\n  \"doc_token\": \"ABC123def\",\n  \"block_id\": \"doxcnXXX\",\n  \"content\": \"New text\"\n}\n```\n\n### Delete Block\n\n```json\n{ \"action\": \"delete_block\", \"doc_token\": \"ABC123def\", \"block_id\": \"doxcnXXX\" }\n```\n\n## Reading Workflow\n\n1. Start with `action: \"read\"` - get plain text + statistics\n2. Check `block_types` in response for Table, Image, Code, etc.\n3. If structured content exists, use `action: \"list_blocks\"` for full data\n\n## Configuration\n\n```yaml\nchannels:\n  feishu:\n    tools:\n      doc: true # default: true\n```\n\n**Note:** `feishu_wiki` depends on this tool - wiki page content is read/written via `feishu_doc`.\n\n## Permissions\n\nRequired: `docx:document`, `docx:document:readonly`, `docx:document.block:convert`, `drive:drive`",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "gifgrep",
    "name": "gifgrep",
    "description": "Search GIF providers with CLI/TUI, download results, and extract stills/sheets.",
    "instructions": "# gifgrep\n\nUse `gifgrep` to search GIF providers (Tenor/Giphy), browse in a TUI, download results, and extract stills or sheets.\n\nGIF-Grab (gifgrep workflow)\n\n- Search ‚Üí preview ‚Üí download ‚Üí extract (still/sheet) for fast review and sharing.\n\nQuick start\n\n- `gifgrep cats --max 5`\n- `gifgrep cats --format url | head -n 5`\n- `gifgrep search --json cats | jq '.[0].url'`\n- `gifgrep tui \"office handshake\"`\n- `gifgrep cats --download --max 1 --format url`\n\nTUI + previews\n\n- TUI: `gifgrep tui \"query\"`\n- CLI still previews: `--thumbs` (Kitty/Ghostty only; still frame)\n\nDownload + reveal\n\n- `--download` saves to `~/Downloads`\n- `--reveal` shows the last download in Finder\n\nStills + sheets\n\n- `gifgrep still ./clip.gif --at 1.5s -o still.png`\n- `gifgrep sheet ./clip.gif --frames 9 --cols 3 -o sheet.png`\n- Sheets = single PNG grid of sampled frames (great for quick review, docs, PRs, chat).\n- Tune: `--frames` (count), `--cols` (grid width), `--padding` (spacing).\n\nProviders\n\n- `--source auto|tenor|giphy`\n- `GIPHY_API_KEY` required for `--source giphy`\n- `TENOR_API_KEY` optional (Tenor demo key used if unset)\n\nOutput\n\n- `--json` prints an array of results (`id`, `title`, `url`, `preview_url`, `tags`, `width`, `height`)\n- `--format` for pipe-friendly fields (e.g., `url`)\n\nEnvironment tweaks\n\n- `GIFGREP_SOFTWARE_ANIM=1` to force software animation\n- `GIFGREP_CELL_ASPECT=0.5` to tweak preview geometry",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "googlesheets-automation",
    "name": "googlesheets-automation",
    "description": "Automate Google Sheets operations (read, write, format, filter, manage spreadsheets) via Rube MCP (Composio). Read/write data, manage tabs, apply formatting, and search rows programmatically.",
    "instructions": "# Google Sheets Automation via Rube MCP\n\nAutomate Google Sheets workflows including reading/writing data, managing spreadsheets and tabs, formatting cells, filtering rows, and upserting records through Composio's Google Sheets toolkit.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active Google Sheets connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `googlesheets`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `googlesheets`\n3. If connection is not ACTIVE, follow the returned auth link to complete Google OAuth\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. Read and Write Data\n\n**When to use**: User wants to read data from or write data to a Google Sheet\n\n**Tool sequence**:\n1. `GOOGLESHEETS_SEARCH_SPREADSHEETS` - Find spreadsheet by name if ID unknown [Prerequisite]\n2. `GOOGLESHEETS_GET_SHEET_NAMES` - Enumerate tab names to target the right sheet [Prerequisite]\n3. `GOOGLESHEETS_BATCH_GET` - Read data from one or more ranges [Required]\n4. `GOOGLESHEETS_BATCH_UPDATE` - Write data to a range or append rows [Required]\n5. `GOOGLESHEETS_VALUES_UPDATE` - Update a single specific range [Alternative]\n6. `GOOGLESHEETS_SPREADSHEETS_VALUES_APPEND` - Append rows to end of table [Alternative]\n\n**Key parameters**:\n- `spreadsheet_id`: Alphanumeric ID from the spreadsheet URL (between '/d/' and '/edit')\n- `ranges`: A1 notation array (e.g., 'Sheet1!A1:Z1000'); always use bounded ranges\n- `sheet_name`: Tab name (case-insensitive matching supported)\n- `values`: 2D array where each inner array is a row\n- `first_cell_location`: Starting cell in A1 notation (omit to append)\n- `valueInputOption`: 'USER_ENTERED' (parsed) or 'RAW' (literal)\n\n**Pitfalls**:\n- Mis-cased or non-existent tab names error \"Sheet 'X' not found\"\n- Empty ranges may omit `valueRanges[i].values`; treat missing as empty array\n- `GOOGLESHEETS_BATCH_UPDATE` values must be a 2D array (list of lists), even for a single row\n- Unbounded ranges like 'A:Z' on sheets with >10,000 rows may cause timeouts; always bound with row limits\n- Append follows the detected `tableRange`; use returned `updatedRange` to verify placement\n\n### 2. Create and Manage Spreadsheets\n\n**When to use**: User wants to create a new spreadsheet or manage tabs within one\n\n**Tool sequence**:\n1. `GOOGLESHEETS_CREATE_GOOGLE_SHEET1` - Create a new spreadsheet [Required]\n2. `GOOGLESHEETS_ADD_SHEET` - Add a new tab/worksheet [Required]\n3. `GOOGLESHEETS_UPDATE_SHEET_PROPERTIES` - Rename, hide, reorder, or color tabs [Optional]\n4. `GOOGLESHEETS_GET_SPREADSHEET_INFO` - Get full spreadsheet metadata [Optional]\n5. `GOOGLESHEETS_FIND_WORKSHEET_BY_TITLE` - Check if a specific tab exists [Optional]\n\n**Key parameters**:\n- `title`: Spreadsheet or sheet tab name\n- `spreadsheetId`: Target spreadsheet ID\n- `forceUnique`: Auto-append suffix if tab name exists (default true)\n- `properties.gridProperties`: Set row/column counts, frozen rows\n\n**Pitfalls**:\n- Sheet names must be unique within a spreadsheet\n- Default sheet names are locale-dependent ('Sheet1' in English, 'Hoja 1' in Spanish)\n- Don't use `index` when creating multiple sheets in parallel (causes 'index too high' errors)\n- `GOOGLESHEETS_GET_SPREADSHEET_INFO` can return 403 if account lacks access\n\n### 3. Search and Filter Rows\n\n**When to use**: User wants to find specific rows or apply filters to sheet data\n\n**Tool sequence**:\n1. `GOOGLESHEETS_LOOKUP_SPREADSHEET_ROW` - Find first row matching exact cell value [Required]\n2. `GOOGLESHEETS_SET_BASIC_FILTER` - Apply filter/sort to a range [Alternative]\n3. `GOOGLESHEETS_CLEAR_BASIC_FILTER` - Remove existing filter [Optional]\n4. `GOOGLESHEETS_BATCH_GET` - Read filtered results [Optional]\n\n**Key parameters**:\n- `query`: Exact text value to match (matches entire cell content)\n- `range`: A1 notation range to search within\n- `case_sensitive`: Boolean for case-sensitive matching (default false)\n- `filter.range`: Grid range with sheet_id for basic filter\n- `filter.criteria`: Column-based filter conditions\n- `filter.sortSpecs`: Sort specifications\n\n**Pitfalls**:\n- `GOOGLESHEETS_LOOKUP_SPREADSHEET_ROW` matches entire cell content, not substrings\n- Sheet names with spaces must be single-quoted in ranges (e.g., \"'My Sheet'!A:Z\")\n- Bare sheet names without ranges are not supported for lookup; always specify a range\n\n### 4. Upsert Rows by Key\n\n**When to use**: User wants to update existing rows or insert new ones based on a unique key column\n\n**Tool sequence**:\n1. `GOOGLESHEETS_UPSERT_ROWS` - Update matching rows or append new ones [Required]\n\n**Key parameters**:\n- `spreadsheetId`: Target spreadsheet ID\n- `sheetName`: Tab name\n- `keyColumn`: Column header name used as unique identifier (e.g., 'Email', 'SKU')\n- `headers`: List of column names for the data\n- `rows`: 2D array of data rows\n- `strictMode`: Error on mismatched column counts (default true)\n\n**Pitfalls**:\n- `keyColumn` must be an actual header name, NOT a column letter (e.g., 'Email' not 'A')\n- If `headers` is NOT provided, first row of `rows` is treated as headers\n- With `strictMode=true`, rows with more values than headers cause an error\n- Auto-adds missing columns to the sheet\n\n### 5. Format Cells\n\n**When to use**: User wants to apply formatting (bold, colors, font size) to cells\n\n**Tool sequence**:\n1. `GOOGLESHEETS_GET_SPREADSHEET_INFO` - Get numeric sheetId for target tab [Prerequisite]\n2. `GOOGLESHEETS_FORMAT_CELL` - Apply formatting to a range [Required]\n3. `GOOGLESHEETS_UPDATE_SHEET_PROPERTIES` - Change frozen rows, column widths [Optional]\n\n**Key parameters**:\n- `spreadsheet_id`: Spreadsheet ID\n- `worksheet_id`: Numeric sheetId (NOT tab name); get from GET_SPREADSHEET_INFO\n- `range`: A1 notation (e.g., 'A1:F1') - preferred over index fields\n- `bold`, `italic`, `underline`, `strikethrough`: Boolean formatting options\n- `red`, `green`, `blue`: Background color as 0.0-1.0 floats (NOT 0-255 ints)\n- `fontSize`: Font size in points\n\n**Pitfalls**:\n- Requires numeric `worksheet_id`, not tab title; get from spreadsheet metadata\n- Color channels are 0-1 floats (e.g., 1.0 for full red), NOT 0-255 integers\n- Responses may return empty reply objects ([{}]); verify formatting via readback\n- Format one range per call; batch formatting requires separate calls\n\n## Common Patterns\n\n### ID Resolution\n- **Spreadsheet name -> ID**: `GOOGLESHEETS_SEARCH_SPREADSHEETS` with `query`\n- **Tab name -> sheetId**: `GOOGLESHEETS_GET_SPREADSHEET_INFO`, extract from sheets metadata\n- **Tab existence check**: `GOOGLESHEETS_FIND_WORKSHEET_BY_TITLE`\n\n### Rate Limits\nGoogle Sheets enforces strict rate limits:\n- Max 60 reads/minute and 60 writes/minute\n- Exceeding limits causes errors; batch operations where possible\n- Use `GOOGLESHEETS_BATCH_GET` and `GOOGLESHEETS_BATCH_UPDATE` for efficiency\n\n### Data Patterns\n- Always read before writing to understand existing layout\n- Use `GOOGLESHEETS_UPSERT_ROWS` for CRM syncs, inventory updates, and dedup scenarios\n- Append mode (omit `first_cell_location`) is safest for adding new records\n- Use `GOOGLESHEETS_CLEAR_VALUES` to clear content while preserving formatting\n\n## Known Pitfalls\n\n- **Tab names**: Locale-dependent defaults; 'Sheet1' may not exist in non-English accounts\n- **Range notation**: Sheet names with spaces need single quotes in A1 notation\n- **Unbounded ranges**: Can timeout on large sheets; always specify row bounds (e.g., 'A1:Z10000')\n- **2D arrays**: All value parameters must be list-of-lists, even for single rows\n- **Color values**: Floats 0.0-1.0, not integers 0-255\n- **Formatting IDs**: `FORMAT_CELL` needs numeric sheetId, not tab title\n- **Rate limits**: 60 reads/min and 60 writes/min; batch to stay within limits\n- **Delete dimension**: `GOOGLESHEETS_DELETE_DIMENSION` is irreversible; double-check bounds\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| Search spreadsheets | `GOOGLESHEETS_SEARCH_SPREADSHEETS` | `query`, `search_type` |\n| Create spreadsheet | `GOOGLESHEETS_CREATE_GOOGLE_SHEET1` | `title` |\n| List tabs | `GOOGLESHEETS_GET_SHEET_NAMES` | `spreadsheet_id` |\n| Add tab | `GOOGLESHEETS_ADD_SHEET` | `spreadsheetId`, `title` |\n| Read data | `GOOGLESHEETS_BATCH_GET` | `spreadsheet_id`, `ranges` |\n| Read single range | `GOOGLESHEETS_VALUES_GET` | `spreadsheet_id`, `range` |\n| Write data | `GOOGLESHEETS_BATCH_UPDATE` | `spreadsheet_id`, `sheet_name`, `values` |\n| Update range | `GOOGLESHEETS_VALUES_UPDATE` | `spreadsheet_id`, `range`, `values` |\n| Append rows | `GOOGLESHEETS_SPREADSHEETS_VALUES_APPEND` | `spreadsheetId`, `range`, `values` |\n| Upsert rows | `GOOGLESHEETS_UPSERT_ROWS` | `spreadsheetId`, `sheetName`, `keyColumn`, `rows` |\n| Lookup row | `GOOGLESHEETS_LOOKUP_SPREADSHEET_ROW` | `spreadsheet_id`, `query` |\n| Format cells | `GOOGLESHEETS_FORMAT_CELL` | `spreadsheet_id`, `worksheet_id`, `range` |\n| Set filter | `GOOGLESHEETS_SET_BASIC_FILTER` | `spreadsheetId`, `filter` |\n| Clear values | `GOOGLESHEETS_CLEAR_VALUES` | `spreadsheet_id`, range |\n| Delete rows/cols | `GOOGLESHEETS_DELETE_DIMENSION` | `spreadsheet_id`, `sheet_name`, dimension |\n| Spreadsheet info | `GOOGLESHEETS_GET_SPREADSHEET_INFO` | `spreadsheet_id` |\n| Update tab props | `GOOGLESHEETS_UPDATE_SHEET_PROPERTIES` | `spreadsheetId`, properties |",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "image-enhancer",
    "name": "image-enhancer",
    "description": "Improves the quality of images, especially screenshots, by enhancing resolution, sharpness, and clarity. Perfect for preparing images for presentations, documentation, or social media posts.",
    "instructions": "# Image Enhancer\n\nThis skill takes your images and screenshots and makes them look better‚Äîsharper, clearer, and more professional.\n\n## When to Use This Skill\n\n- Improving screenshot quality for blog posts or documentation\n- Enhancing images before sharing on social media\n- Preparing images for presentations or reports\n- Upscaling low-resolution images\n- Sharpening blurry photos\n- Cleaning up compressed images\n\n## What This Skill Does\n\n1. **Analyzes Image Quality**: Checks resolution, sharpness, and compression artifacts\n2. **Enhances Resolution**: Upscales images intelligently\n3. **Improves Sharpness**: Enhances edges and details\n4. **Reduces Artifacts**: Cleans up compression artifacts and noise\n5. **Optimizes for Use Case**: Adjusts based on intended use (web, print, social media)\n\n## How to Use\n\n### Basic Enhancement\n\n```\nImprove the image quality of screenshot.png\n```\n\n```\nEnhance all images in this folder\n```\n\n### Specific Improvements\n\n```\nUpscale this image to 4K resolution\n```\n\n```\nSharpen this blurry screenshot\n```\n\n```\nReduce compression artifacts in this image\n```\n\n### Batch Processing\n\n```\nImprove the quality of all PNG files in this directory\n```\n\n## Example\n\n**User**: \"Improve the image quality of screenshot-2024.png\"\n\n**Output**:\n```\nAnalyzing screenshot-2024.png...\n\nCurrent specs:\n- Resolution: 1920x1080\n- Format: PNG\n- Quality: Good, but slight blur\n\nEnhancements applied:\n‚úì Upscaled to 2560x1440 (retina)\n‚úì Sharpened edges\n‚úì Enhanced text clarity\n‚úì Optimized file size\n\nSaved as: screenshot-2024-enhanced.png\nOriginal preserved as: screenshot-2024-original.png\n```\n\n**Inspired by:** Lenny Rachitsky's workflow from his newsletter - used for screenshots in his articles\n\n## Tips\n\n- Always keeps original files as backup\n- Works best with screenshots and digital images\n- Can batch process entire folders\n- Specify output format if needed (PNG for quality, JPG for smaller size)\n- For social media, mention the platform for optimal sizing\n\n## Common Use Cases\n\n- **Blog Posts**: Enhance screenshots before publishing\n- **Documentation**: Make UI screenshots crystal clear\n- **Social Media**: Optimize images for Twitter, LinkedIn, Instagram\n- **Presentations**: Upscale images for large screens\n- **Print Materials**: Increase resolution for physical media",
    "author": "community",
    "version": "1.0.0",
    "category": "other",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "internal-comms",
    "name": "internal-comms",
    "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).",
    "instructions": "## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "invoice-organizer",
    "name": "invoice-organizer",
    "description": "Automatically organizes invoices and receipts for tax preparation by reading messy files, extracting key information, renaming them consistently, and sorting them into logical folders. Turns hours of manual bookkeeping into minutes of automated organization.",
    "instructions": "# Invoice Organizer\n\nThis skill transforms chaotic folders of invoices, receipts, and financial documents into a clean, tax-ready filing system without manual effort.\n\n## When to Use This Skill\n\n- Preparing for tax season and need organized records\n- Managing business expenses across multiple vendors\n- Organizing receipts from a messy folder or email downloads\n- Setting up automated invoice filing for ongoing bookkeeping\n- Archiving financial records by year or category\n- Reconciling expenses for reimbursement\n- Preparing documentation for accountants\n\n## What This Skill Does\n\n1. **Reads Invoice Content**: Extracts information from PDFs, images, and documents:\n   - Vendor/company name\n   - Invoice number\n   - Date\n   - Amount\n   - Product or service description\n   - Payment method\n\n2. **Renames Files Consistently**: Creates standardized filenames:\n   - Format: `YYYY-MM-DD Vendor - Invoice - ProductOrService.pdf`\n   - Examples: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n\n3. **Organizes by Category**: Sorts into logical folders:\n   - By vendor\n   - By expense category (software, office, travel, etc.)\n   - By time period (year, quarter, month)\n   - By tax category (deductible, personal, etc.)\n\n4. **Handles Multiple Formats**: Works with:\n   - PDF invoices\n   - Scanned receipts (JPG, PNG)\n   - Email attachments\n   - Screenshots\n   - Bank statements\n\n5. **Maintains Originals**: Preserves original files while organizing copies\n\n## How to Use\n\n### Basic Usage\n\nNavigate to your messy invoice folder:\n```\ncd ~/Desktop/receipts-to-sort\n```\n\nThen ask Claude Code:\n```\nOrganize these invoices for taxes\n```\n\nOr more specifically:\n```\nRead all invoices in this folder, rename them to \n\"YYYY-MM-DD Vendor - Invoice - Product.pdf\" format, \nand organize them by vendor\n```\n\n### Advanced Organization\n\n```\nOrganize these invoices:\n1. Extract date, vendor, and description from each file\n2. Rename to standard format\n3. Sort into folders by expense category (Software, Office, Travel, etc.)\n4. Create a CSV spreadsheet with all invoice details for my accountant\n```\n\n## Instructions\n\nWhen a user requests invoice organization:\n\n1. **Scan the Folder**\n   \n   Identify all invoice files:\n   ```bash\n   # Find all invoice-related files\n   find . -type f \\( -name \"*.pdf\" -o -name \"*.jpg\" -o -name \"*.png\" \\) -print\n   ```\n   \n   Report findings:\n   - Total number of files\n   - File types\n   - Date range (if discernible from names)\n   - Current organization (or lack thereof)\n\n2. **Extract Information from Each File**\n   \n   For each invoice, extract:\n   \n   **From PDF invoices**:\n   - Use text extraction to read invoice content\n   - Look for common patterns:\n     - \"Invoice Date:\", \"Date:\", \"Issued:\"\n     - \"Invoice #:\", \"Invoice Number:\"\n     - Company name (usually at top)\n     - \"Amount Due:\", \"Total:\", \"Amount:\"\n     - \"Description:\", \"Service:\", \"Product:\"\n   \n   **From image receipts**:\n   - Read visible text from images\n   - Identify vendor name (often at top)\n   - Look for date (common formats)\n   - Find total amount\n   \n   **Fallback for unclear files**:\n   - Use filename clues\n   - Check file creation/modification date\n   - Flag for manual review if critical info missing\n\n3. **Determine Organization Strategy**\n   \n   Ask user preference if not specified:\n   \n   ```markdown\n   I found [X] invoices from [date range].\n   \n   How would you like them organized?\n   \n   1. **By Vendor** (Adobe/, Amazon/, Stripe/, etc.)\n   2. **By Category** (Software/, Office Supplies/, Travel/, etc.)\n   3. **By Date** (2024/Q1/, 2024/Q2/, etc.)\n   4. **By Tax Category** (Deductible/, Personal/, etc.)\n   5. **Custom** (describe your structure)\n   \n   Or I can use a default structure: Year/Category/Vendor\n   ```\n\n4. **Create Standardized Filename**\n   \n   For each invoice, create a filename following this pattern:\n   \n   ```\n   YYYY-MM-DD Vendor - Invoice - Description.ext\n   ```\n   \n   Examples:\n   - `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   - `2024-01-10 Amazon - Receipt - Office Supplies.pdf`\n   - `2023-12-01 Stripe - Invoice - Monthly Payment Processing.pdf`\n   \n   **Filename Best Practices**:\n   - Remove special characters except hyphens\n   - Capitalize vendor names properly\n   - Keep descriptions concise but meaningful\n   - Use consistent date format (YYYY-MM-DD) for sorting\n   - Preserve original file extension\n\n5. **Execute Organization**\n   \n   Before moving files, show the plan:\n   \n   ```markdown\n   # Organization Plan\n   \n   ## Proposed Structure\n   ```\n   Invoices/\n   ‚îú‚îÄ‚îÄ 2023/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Software/\n   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Microsoft/\n   ‚îÇ   ‚îú‚îÄ‚îÄ Services/\n   ‚îÇ   ‚îî‚îÄ‚îÄ Office/\n   ‚îî‚îÄ‚îÄ 2024/\n       ‚îú‚îÄ‚îÄ Software/\n       ‚îú‚îÄ‚îÄ Services/\n       ‚îî‚îÄ‚îÄ Office/\n   ```\n   \n   ## Sample Changes\n   \n   Before: `invoice_adobe_march.pdf`\n   After: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   Location: `Invoices/2024/Software/Adobe/`\n   \n   Before: `IMG_2847.jpg`\n   After: `2024-02-10 Staples - Receipt - Office Supplies.jpg`\n   Location: `Invoices/2024/Office/Staples/`\n   \n   Process [X] files? (yes/no)\n   ```\n   \n   After approval:\n   ```bash\n   # Create folder structure\n   mkdir -p \"Invoices/2024/Software/Adobe\"\n   \n   # Copy (don't move) to preserve originals\n   cp \"original.pdf\" \"Invoices/2024/Software/Adobe/2024-03-15 Adobe - Invoice - Creative Cloud.pdf\"\n   \n   # Or move if user prefers\n   mv \"original.pdf\" \"new/path/standardized-name.pdf\"\n   ```\n\n6. **Generate Summary Report**\n   \n   Create a CSV file with all invoice details:\n   \n   ```csv\n   Date,Vendor,Invoice Number,Description,Amount,Category,File Path\n   2024-03-15,Adobe,INV-12345,Creative Cloud,52.99,Software,Invoices/2024/Software/Adobe/2024-03-15 Adobe - Invoice - Creative Cloud.pdf\n   2024-03-10,Amazon,123-4567890-1234567,Office Supplies,127.45,Office,Invoices/2024/Office/Amazon/2024-03-10 Amazon - Receipt - Office Supplies.pdf\n   ...\n   ```\n   \n   This CSV is useful for:\n   - Importing into accounting software\n   - Sharing with accountants\n   - Expense tracking and reporting\n   - Tax preparation\n\n7. **Provide Completion Summary**\n   \n   ```markdown\n   # Organization Complete! üìä\n   \n   ## Summary\n   - **Processed**: [X] invoices\n   - **Date range**: [earliest] to [latest]\n   - **Total amount**: $[sum] (if amounts extracted)\n   - **Vendors**: [Y] unique vendors\n   \n   ## New Structure\n   ```\n   Invoices/\n   ‚îú‚îÄ‚îÄ 2024/ (45 files)\n   ‚îÇ   ‚îú‚îÄ‚îÄ Software/ (23 files)\n   ‚îÇ   ‚îú‚îÄ‚îÄ Services/ (12 files)\n   ‚îÇ   ‚îî‚îÄ‚îÄ Office/ (10 files)\n   ‚îî‚îÄ‚îÄ 2023/ (12 files)\n   ```\n   \n   ## Files Created\n   - `/Invoices/` - Organized invoices\n   - `/Invoices/invoice-summary.csv` - Spreadsheet for accounting\n   - `/Invoices/originals/` - Original files (if copied)\n   \n   ## Files Needing Review\n   [List any files where information couldn't be extracted completely]\n   \n   ## Next Steps\n   1. Review the `invoice-summary.csv` file\n   2. Check files in \"Needs Review\" folder\n   3. Import CSV into your accounting software\n   4. Set up auto-organization for future invoices\n   \n   Ready for tax season! üéâ\n   ```\n\n## Examples\n\n### Example 1: Tax Preparation (From Martin Merschroth)\n\n**User**: \"I have a messy folder of invoices for taxes. Sort them and rename properly.\"\n\n**Process**:\n1. Scans folder: finds 147 PDFs and images\n2. Reads each invoice to extract:\n   - Date\n   - Vendor name\n   - Invoice number\n   - Product/service description\n3. Renames all files: `YYYY-MM-DD Vendor - Invoice - Product.pdf`\n4. Organizes into: `2024/Software/`, `2024/Travel/`, etc.\n5. Creates `invoice-summary.csv` for accountant\n6. Result: Tax-ready organized invoices in minutes\n\n### Example 2: Monthly Expense Reconciliation\n\n**User**: \"Organize my business receipts from last month by category.\"\n\n**Output**:\n```markdown\n# March 2024 Receipts Organized\n\n## By Category\n- Software & Tools: $847.32 (12 invoices)\n- Office Supplies: $234.18 (8 receipts)\n- Travel & Meals: $1,456.90 (15 receipts)\n- Professional Services: $2,500.00 (3 invoices)\n\nTotal: $5,038.40\n\nAll receipts renamed and filed in:\n`Business-Receipts/2024/03-March/[Category]/`\n\nCSV export: `march-2024-expenses.csv`\n```\n\n### Example 3: Multi-Year Archive\n\n**User**: \"I have 3 years of random invoices. Organize them by year, then by vendor.\"\n\n**Output**: Creates structure:\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2022/\n‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n‚îÇ   ‚îú‚îÄ‚îÄ Amazon/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ Adobe/\n‚îÇ   ‚îú‚îÄ‚îÄ Amazon/\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ 2024/\n    ‚îú‚îÄ‚îÄ Adobe/\n    ‚îú‚îÄ‚îÄ Amazon/\n    ‚îî‚îÄ‚îÄ ...\n```\n\nEach file properly renamed with date and description.\n\n### Example 4: Email Downloads Cleanup\n\n**User**: \"I download invoices from Gmail. They're all named 'invoice.pdf', 'invoice(1).pdf', etc. Fix this mess.\"\n\n**Output**:\n```markdown\nFound 89 files all named \"invoice*.pdf\"\n\nReading each file to extract real information...\n\nRenamed examples:\n- invoice.pdf ‚Üí 2024-03-15 Shopify - Invoice - Monthly Subscription.pdf\n- invoice(1).pdf ‚Üí 2024-03-14 Google - Invoice - Workspace.pdf\n- invoice(2).pdf ‚Üí 2024-03-10 Netlify - Invoice - Pro Plan.pdf\n\nAll files renamed and organized by vendor.\n```\n\n## Common Organization Patterns\n\n### By Vendor (Simple)\n```\nInvoices/\n‚îú‚îÄ‚îÄ Adobe/\n‚îú‚îÄ‚îÄ Amazon/\n‚îú‚îÄ‚îÄ Google/\n‚îî‚îÄ‚îÄ Microsoft/\n```\n\n### By Year and Category (Tax-Friendly)\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2023/\n‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îú‚îÄ‚îÄ Hardware/\n‚îÇ   ‚îú‚îÄ‚îÄ Services/\n‚îÇ   ‚îî‚îÄ‚îÄ Travel/\n‚îî‚îÄ‚îÄ 2024/\n    ‚îî‚îÄ‚îÄ ...\n```\n\n### By Quarter (Detailed Tracking)\n```\nInvoices/\n‚îú‚îÄ‚îÄ 2024/\n‚îÇ   ‚îú‚îÄ‚îÄ Q1/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Office/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Travel/\n‚îÇ   ‚îî‚îÄ‚îÄ Q2/\n‚îÇ       ‚îî‚îÄ‚îÄ ...\n```\n\n### By Tax Category (Accountant-Ready)\n```\nInvoices/\n‚îú‚îÄ‚îÄ Deductible/\n‚îÇ   ‚îú‚îÄ‚îÄ Software/\n‚îÇ   ‚îú‚îÄ‚îÄ Office/\n‚îÇ   ‚îî‚îÄ‚îÄ Professional-Services/\n‚îú‚îÄ‚îÄ Partially-Deductible/\n‚îÇ   ‚îî‚îÄ‚îÄ Meals-Travel/\n‚îî‚îÄ‚îÄ Personal/\n```\n\n## Automation Setup\n\nFor ongoing organization:\n\n```\nCreate a script that watches my ~/Downloads/invoices folder \nand auto-organizes any new invoice files using our standard \nnaming and folder structure.\n```\n\nThis creates a persistent solution that organizes invoices as they arrive.\n\n## Pro Tips\n\n1. **Scan emails to PDF**: Use Preview or similar to save email invoices as PDFs first\n2. **Consistent downloads**: Save all invoices to one folder for batch processing\n3. **Monthly routine**: Organize invoices monthly, not annually\n4. **Backup originals**: Keep original files before reorganizing\n5. **Include amounts in CSV**: Useful for budget tracking\n6. **Tag by deductibility**: Note which expenses are tax-deductible\n7. **Keep receipts 7 years**: Standard audit period\n\n## Handling Special Cases\n\n### Missing Information\nIf date/vendor can't be extracted:\n- Flag file for manual review\n- Use file modification date as fallback\n- Create \"Needs-Review/\" folder\n\n### Duplicate Invoices\nIf same invoice appears multiple times:\n- Compare file hashes\n- Keep highest quality version\n- Note duplicates in summary\n\n### Multi-Page Invoices\nFor invoices split across files:\n- Merge PDFs if needed\n- Use consistent naming for parts\n- Note in CSV if invoice is split\n\n### Non-Standard Formats\nFor unusual receipt formats:\n- Extract what's possible\n- Standardize what you can\n- Flag for review if critical info missing\n\n## Related Use Cases\n\n- Creating expense reports for reimbursement\n- Organizing bank statements\n- Managing vendor contracts\n- Archiving old financial records\n- Preparing for audits\n- Tracking subscription costs over time",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "linkedin-automation",
    "name": "linkedin-automation",
    "description": "Automate LinkedIn tasks via Rube MCP (Composio): create posts, manage profile, company info, comments, and image uploads. Always search tools first for current schemas.",
    "instructions": "# LinkedIn Automation via Rube MCP\n\nAutomate LinkedIn operations through Composio's LinkedIn toolkit via Rube MCP.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active LinkedIn connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `linkedin`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `linkedin`\n3. If connection is not ACTIVE, follow the returned auth link to complete LinkedIn OAuth\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. Create a LinkedIn Post\n\n**When to use**: User wants to publish a text post on LinkedIn\n\n**Tool sequence**:\n1. `LINKEDIN_GET_MY_INFO` - Get authenticated user's profile info [Prerequisite]\n2. `LINKEDIN_REGISTER_IMAGE_UPLOAD` - Register image upload if post includes an image [Optional]\n3. `LINKEDIN_CREATE_LINKED_IN_POST` - Publish the post [Required]\n\n**Key parameters**:\n- `text`: Post content text\n- `visibility`: 'PUBLIC' or 'CONNECTIONS'\n- `media_title`: Title for attached media\n- `media_description`: Description for attached media\n\n**Pitfalls**:\n- Must retrieve user profile URN via GET_MY_INFO before creating a post\n- Image uploads require a two-step process: register upload first, then include the asset in the post\n- Post text has character limits enforced by LinkedIn API\n- Visibility defaults may vary; always specify explicitly\n\n### 2. Get Profile Information\n\n**When to use**: User wants to retrieve their LinkedIn profile or company details\n\n**Tool sequence**:\n1. `LINKEDIN_GET_MY_INFO` - Get authenticated user's profile [Required]\n2. `LINKEDIN_GET_COMPANY_INFO` - Get company page details [Optional]\n\n**Key parameters**:\n- No parameters needed for GET_MY_INFO (uses authenticated user)\n- `organization_id`: Company/organization ID for GET_COMPANY_INFO\n\n**Pitfalls**:\n- GET_MY_INFO returns the authenticated user only; cannot look up other users\n- Company info requires the numeric organization ID, not the company name or vanity URL\n- Some profile fields may be restricted based on OAuth scopes granted\n\n### 3. Manage Post Images\n\n**When to use**: User wants to upload and attach images to LinkedIn posts\n\n**Tool sequence**:\n1. `LINKEDIN_REGISTER_IMAGE_UPLOAD` - Register an image upload with LinkedIn [Required]\n2. Upload the image binary to the returned upload URL [Required]\n3. `LINKEDIN_GET_IMAGES` - Verify uploaded image status [Optional]\n4. `LINKEDIN_CREATE_LINKED_IN_POST` - Create post with the image asset [Required]\n\n**Key parameters**:\n- `owner`: URN of the image owner (user or organization)\n- `image_id`: ID of the uploaded image for GET_IMAGES\n\n**Pitfalls**:\n- The upload is a two-phase process: register then upload binary\n- Image asset URN from registration must be used when creating the post\n- Supported formats typically include JPG, PNG, and GIF\n- Large images may take time to process before they are available\n\n### 4. Comment on Posts\n\n**When to use**: User wants to comment on an existing LinkedIn post\n\n**Tool sequence**:\n1. `LINKEDIN_CREATE_COMMENT_ON_POST` - Add a comment to a post [Required]\n\n**Key parameters**:\n- `post_id`: The URN or ID of the post to comment on\n- `text`: Comment content\n- `actor`: URN of the commenter (user or organization)\n\n**Pitfalls**:\n- Post ID must be a valid LinkedIn URN format\n- The actor URN must match the authenticated user or a managed organization\n- Rate limits apply to comment creation; avoid rapid-fire comments\n\n### 5. Delete a Post\n\n**When to use**: User wants to remove a previously published LinkedIn post\n\n**Tool sequence**:\n1. `LINKEDIN_DELETE_LINKED_IN_POST` - Delete the specified post [Required]\n\n**Key parameters**:\n- `post_id`: The URN or ID of the post to delete\n\n**Pitfalls**:\n- Deletion is permanent and cannot be undone\n- Only the post author or organization admin can delete a post\n- The post_id must be the exact URN returned when the post was created\n\n## Common Patterns\n\n### ID Resolution\n\n**User URN from profile**:\n```\n1. Call LINKEDIN_GET_MY_INFO\n2. Extract user URN (e.g., 'urn:li:person:XXXXXXXXXX')\n3. Use URN as actor/owner in subsequent calls\n```\n\n**Organization ID from company**:\n```\n1. Call LINKEDIN_GET_COMPANY_INFO with organization_id\n2. Extract organization URN for posting as a company page\n```\n\n### Image Upload Flow\n\n- Call REGISTER_IMAGE_UPLOAD to get upload URL and asset URN\n- Upload the binary image to the provided URL\n- Use the asset URN when creating a post with media\n- Verify with GET_IMAGES if upload status is uncertain\n\n## Known Pitfalls\n\n**Authentication**:\n- LinkedIn OAuth tokens have limited scopes; ensure required permissions are granted\n- Tokens expire; re-authenticate if API calls return 401 errors\n\n**URN Formats**:\n- LinkedIn uses URN identifiers (e.g., 'urn:li:person:ABC123')\n- Always use the full URN format, not just the alphanumeric ID portion\n- Organization URNs differ from person URNs\n\n**Rate Limits**:\n- LinkedIn API has strict daily rate limits on post creation and comments\n- Implement backoff strategies for bulk operations\n- Monitor 429 responses and respect Retry-After headers\n\n**Content Restrictions**:\n- Posts have character limits enforced by the API\n- Some content types (polls, documents) may require additional API features\n- HTML markup in post text is not supported\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| Get my profile | LINKEDIN_GET_MY_INFO | (none) |\n| Create post | LINKEDIN_CREATE_LINKED_IN_POST | text, visibility |\n| Get company info | LINKEDIN_GET_COMPANY_INFO | organization_id |\n| Register image upload | LINKEDIN_REGISTER_IMAGE_UPLOAD | owner |\n| Get uploaded images | LINKEDIN_GET_IMAGES | image_id |\n| Delete post | LINKEDIN_DELETE_LINKED_IN_POST | post_id |\n| Comment on post | LINKEDIN_CREATE_COMMENT_ON_POST | post_id, text, actor |",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "loom-transcript",
    "name": "loom-transcript",
    "description": "Fetch and display the full transcript from a Loom video URL. Use when the user wants to get or read a Loom transcript.",
    "instructions": "# Loom Transcript Fetcher\n\nFetch the transcript from a Loom video using Loom's GraphQL API.\n\n## Instructions\n\nGiven the Loom URL: $ARGUMENTS\n\n### 1. Extract the Video ID\n\nParse the Loom URL to extract the 32-character hex video ID. Supported URL formats:\n- `https://www.loom.com/share/<video-id>`\n- `https://www.loom.com/embed/<video-id>`\n- `https://www.loom.com/share/<video-id>?sid=<session-id>`\n\nThe video ID is the 32-character hex string after `/share/` or `/embed/`.\n\n### 2. Fetch Video Metadata\n\nUse the `WebFetch` tool to POST to `https://www.loom.com/graphql` to get the video title and details.\n\nUse this curl command via Bash:\n\n```bash\ncurl -s 'https://www.loom.com/graphql' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Accept: application/json' \\\n  -H 'x-loom-request-source: loom_web_45a5bd4' \\\n  -H 'apollographql-client-name: web' \\\n  -H 'apollographql-client-version: 45a5bd4' \\\n  -d '{\n    \"operationName\": \"GetVideoSSR\",\n    \"variables\": {\"id\": \"<VIDEO_ID>\", \"password\": null},\n    \"query\": \"query GetVideoSSR($id: ID!, $password: String) { getVideo(id: $id, password: $password) { ... on RegularUserVideo { id name description createdAt owner { display_name } } } }\"\n  }'\n```\n\n### 3. Fetch the Transcript URLs\n\nUse curl via Bash to call the GraphQL API:\n\n```bash\ncurl -s 'https://www.loom.com/graphql' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Accept: application/json' \\\n  -H 'x-loom-request-source: loom_web_45a5bd4' \\\n  -H 'apollographql-client-name: web' \\\n  -H 'apollographql-client-version: 45a5bd4' \\\n  -d '{\n    \"operationName\": \"FetchVideoTranscript\",\n    \"variables\": {\"videoId\": \"<VIDEO_ID>\", \"password\": null},\n    \"query\": \"query FetchVideoTranscript($videoId: ID!, $password: String) { fetchVideoTranscript(videoId: $videoId, password: $password) { ... on VideoTranscriptDetails { id video_id source_url captions_source_url } ... on GenericError { message } } }\"\n  }'\n```\n\nReplace `<VIDEO_ID>` with the actual video ID extracted in step 1.\n\nThe response contains:\n- `source_url` ‚Äî JSON transcript URL\n- `captions_source_url` ‚Äî VTT (WebVTT) captions URL\n\n### 4. Download and Parse the Transcript\n\nFetch **both** URLs returned from step 3 (if available):\n\n1. **VTT captions** (`captions_source_url`): Download with `curl -sL \"<url>\"`. This is a WebVTT file with timestamps and text.\n2. **JSON transcript** (`source_url`): Download with `curl -sL \"<url>\"`. This is a JSON file with transcript segments.\n\nPrefer the VTT captions as the primary source since they include proper timestamps. Fall back to the JSON transcript if VTT is unavailable.\n\n### 5. Present the Transcript\n\nFormat and present the full transcript to the user:\n\n**Video:** [Title from metadata]\n**Author:** [Owner name]\n**Date:** [Created date]\n\n---\n\n**0:00** - First transcript segment text...\n\n**0:14** - Second transcript segment text...\n\n(continue for all segments)\n\n---\n\n## Error Handling\n\n- If the GraphQL response contains a `GenericError`, report the error message to the user.\n- If both `source_url` and `captions_source_url` are null/missing, tell the user that no transcript is available for this video.\n- If the video URL is invalid or the ID cannot be extracted, ask the user for a valid Loom URL.\n\n## Notes\n\n- No authentication or cookies are required ‚Äî Loom's transcript API is publicly accessible.\n- Only English transcripts are available through this API.\n- Transcripts are auto-generated and may contain minor errors.",
    "author": "n8n-io",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "mailchimp-automation",
    "name": "mailchimp-automation",
    "description": "Automate Mailchimp email marketing including campaigns, audiences, subscribers, segments, and analytics via Rube MCP (Composio). Always search tools first for current schemas.",
    "instructions": "# Mailchimp Automation via Rube MCP\n\nAutomate Mailchimp email marketing workflows including campaign creation and sending, audience/list management, subscriber operations, segmentation, and performance analytics through Composio's Mailchimp toolkit.\n\n## Prerequisites\n\n- Rube MCP must be connected (RUBE_SEARCH_TOOLS available)\n- Active Mailchimp connection via `RUBE_MANAGE_CONNECTIONS` with toolkit `mailchimp`\n- Always call `RUBE_SEARCH_TOOLS` first to get current tool schemas\n\n## Setup\n\n**Get Rube MCP**: Add `https://rube.app/mcp` as an MCP server in your client configuration. No API keys needed ‚Äî just add the endpoint and it works.\n\n\n1. Verify Rube MCP is available by confirming `RUBE_SEARCH_TOOLS` responds\n2. Call `RUBE_MANAGE_CONNECTIONS` with toolkit `mailchimp`\n3. If connection is not ACTIVE, follow the returned auth link to complete Mailchimp OAuth\n4. Confirm connection status shows ACTIVE before running any workflows\n\n## Core Workflows\n\n### 1. Create and Send Email Campaigns\n\n**When to use**: User wants to create, configure, test, and send an email campaign.\n\n**Tool sequence**:\n1. `MAILCHIMP_GET_LISTS_INFO` - List available audiences and get list_id [Prerequisite]\n2. `MAILCHIMP_ADD_CAMPAIGN` - Create a new campaign with type, audience, subject, from name [Required]\n3. `MAILCHIMP_SET_CAMPAIGN_CONTENT` - Set HTML content for the campaign [Required]\n4. `MAILCHIMP_SEND_TEST_EMAIL` - Send preview to reviewers before live send [Optional]\n5. `MAILCHIMP_SEND_CAMPAIGN` - Send the campaign immediately [Required]\n6. `MAILCHIMP_SCHEDULE_CAMPAIGN` - Schedule for future delivery instead of immediate send [Optional]\n\n**Key parameters for MAILCHIMP_ADD_CAMPAIGN**:\n- `type`: \"regular\", \"plaintext\", \"rss\", or \"variate\" (required)\n- `recipients__list__id`: Audience/list ID for recipients\n- `settings__subject__line`: Email subject line\n- `settings__from__name`: Sender display name\n- `settings__reply__to`: Reply-to email address (required for sending)\n- `settings__title`: Internal campaign title\n- `settings__preview__text`: Preview text shown in inbox\n\n**Key parameters for MAILCHIMP_SET_CAMPAIGN_CONTENT**:\n- `campaign_id`: Campaign ID from creation step (required)\n- `html`: Raw HTML content for the email\n- `plain_text`: Plain-text version (auto-generated if omitted)\n- `template__id`: Use a pre-built template instead of raw HTML\n\n**Pitfalls**:\n- `MAILCHIMP_SEND_CAMPAIGN` is irreversible; always send a test email first and get explicit user approval\n- Campaign must be in \"save\" (draft) status with valid audience, subject, from name, verified email, and content before sending\n- `MAILCHIMP_SCHEDULE_CAMPAIGN` requires a valid future datetime; past timestamps fail\n- Templates and HTML content must include compliant footer/unsubscribe merge tags\n- Mailchimp uses double-underscore notation for nested params (e.g., `settings__subject__line`)\n\n### 2. Manage Audiences and Subscribers\n\n**When to use**: User wants to view audiences, list subscribers, or check subscriber details.\n\n**Tool sequence**:\n1. `MAILCHIMP_GET_LISTS_INFO` - List all audiences with member counts [Required]\n2. `MAILCHIMP_GET_LIST_INFO` - Get details for a specific audience [Optional]\n3. `MAILCHIMP_LIST_MEMBERS_INFO` - List members with status filter and pagination [Required]\n4. `MAILCHIMP_SEARCH_MEMBERS` - Search by email or name across lists [Optional]\n5. `MAILCHIMP_GET_MEMBER_INFO` - Get detailed profile for a specific subscriber [Optional]\n6. `MAILCHIMP_LIST_SEGMENTS` - List segments within an audience [Optional]\n\n**Key parameters for MAILCHIMP_LIST_MEMBERS_INFO**:\n- `list_id`: Audience ID (required)\n- `status`: \"subscribed\", \"unsubscribed\", \"cleaned\", \"pending\", \"transactional\", \"archived\"\n- `count`: Records per page (default 10, max 1000)\n- `offset`: Pagination offset (default 0)\n- `sort_field`: \"timestamp_opt\", \"timestamp_signup\", or \"last_changed\"\n- `fields`: Comma-separated list to limit response size\n\n**Pitfalls**:\n- `stats.avg_open_rate` and `stats.avg_click_rate` are 0-1 fractions, NOT 0-100 percentages\n- Always use `status=\"subscribed\"` to filter active subscribers; omitting returns all statuses\n- Must paginate using `count` and `offset` until collected members match `total_items`\n- Large list responses may be truncated; data is under `response.data.members`\n\n### 3. Add and Update Subscribers\n\n**When to use**: User wants to add new subscribers, update existing ones, or bulk-manage list membership.\n\n**Tool sequence**:\n1. `MAILCHIMP_GET_LIST_INFO` - Validate target audience exists [Prerequisite]\n2. `MAILCHIMP_SEARCH_MEMBERS` - Check if contact already exists [Optional]\n3. `MAILCHIMP_ADD_OR_UPDATE_LIST_MEMBER` - Upsert subscriber (create or update) [Required]\n4. `MAILCHIMP_ADD_MEMBER_TO_LIST` - Add new subscriber (create only) [Optional]\n5. `MAILCHIMP_BATCH_ADD_OR_REMOVE_MEMBERS` - Bulk manage segment membership [Optional]\n\n**Key parameters for MAILCHIMP_ADD_OR_UPDATE_LIST_MEMBER**:\n- `list_id`: Audience ID (required)\n- `subscriber_hash`: MD5 hash of lowercase email (required)\n- `email_address`: Subscriber email (required)\n- `status_if_new`: Status for new subscribers: \"subscribed\", \"pending\", etc. (required)\n- `status`: Status for existing subscribers\n- `merge_fields`: Object with merge tag keys (e.g., `{\"FNAME\": \"John\", \"LNAME\": \"Doe\"}`)\n- `tags`: Array of tag strings\n\n**Key parameters for MAILCHIMP_ADD_MEMBER_TO_LIST**:\n- `list_id`: Audience ID (required)\n- `email_address`: Subscriber email (required)\n- `status`: \"subscribed\", \"pending\", \"unsubscribed\", \"cleaned\", \"transactional\" (required)\n\n**Pitfalls**:\n- `subscriber_hash` must be MD5 of the **lowercase** email; incorrect casing causes 404s or duplicates\n- Use `MAILCHIMP_ADD_OR_UPDATE_LIST_MEMBER` (upsert) instead of `MAILCHIMP_ADD_MEMBER_TO_LIST` to avoid duplicate errors\n- `status_if_new` determines status only for new contacts; existing contacts use `status`\n- Use `skip_merge_validation: true` to bypass required merge field validation\n- `MAILCHIMP_BATCH_ADD_OR_REMOVE_MEMBERS` manages static segment membership, not list membership\n\n### 4. View Campaign Reports and Analytics\n\n**When to use**: User wants to review campaign performance, open rates, click rates, or subscriber engagement.\n\n**Tool sequence**:\n1. `MAILCHIMP_LIST_CAMPAIGNS` - List sent campaigns with report summaries [Required]\n2. `MAILCHIMP_SEARCH_CAMPAIGNS` - Find campaigns by name, subject, or content [Optional]\n3. `MAILCHIMP_GET_CAMPAIGN_REPORT` - Get detailed performance report for a campaign [Required]\n4. `MAILCHIMP_LIST_CAMPAIGN_REPORTS` - Bulk fetch reports across multiple campaigns [Optional]\n5. `MAILCHIMP_LIST_CAMPAIGN_DETAILS` - Get link-level click statistics [Optional]\n6. `MAILCHIMP_GET_CAMPAIGN_LINK_DETAILS` - Drill into specific link click data [Optional]\n7. `MAILCHIMP_LIST_CLICKED_LINK_SUBSCRIBERS` - See who clicked a specific link [Optional]\n8. `MAILCHIMP_GET_SUBSCRIBER_EMAIL_ACTIVITY` - Get per-subscriber campaign activity [Optional]\n9. `MAILCHIMP_GET_CAMPAIGN_CONTENT` - Retrieve campaign HTML content [Optional]\n\n**Key parameters for MAILCHIMP_LIST_CAMPAIGNS**:\n- `status`: \"save\", \"paused\", \"schedule\", \"sending\", \"sent\"\n- `count` / `offset`: Pagination (default 10, max 1000)\n- `since_send_time` / `before_send_time`: ISO 8601 date range filter\n- `sort_field`: \"create_time\" or \"send_time\"\n- `fields`: Limit response fields for performance\n\n**Key parameters for MAILCHIMP_GET_CAMPAIGN_REPORT**:\n- `campaign_id`: Campaign ID (required)\n- Returns: opens, clicks, bounces, unsubscribes, timeseries, industry_stats\n\n**Pitfalls**:\n- `MAILCHIMP_LIST_CAMPAIGNS` only returns high-level `report_summary`; use `MAILCHIMP_GET_CAMPAIGN_REPORT` for detailed metrics\n- Draft/unsent campaigns lack meaningful report data\n- When using `fields` parameter on LIST_CAMPAIGNS, explicitly request `send_time` and `report_summary` subfields\n- Pagination defaults are low (10 records); iterate with `count` and `offset` until `total_items` is covered\n- `send_time` is ISO 8601 with timezone; parse carefully\n\n## Common Patterns\n\n### ID Resolution\nAlways resolve names to IDs before operations:\n- **Audience name -> list_id**: `MAILCHIMP_GET_LISTS_INFO` and match by name\n- **Subscriber email -> subscriber_hash**: Compute MD5 of lowercase email in code\n- **Campaign name -> campaign_id**: `MAILCHIMP_SEARCH_CAMPAIGNS` with query\n- **Segment name -> segment_id**: `MAILCHIMP_LIST_SEGMENTS` with list_id\n\n### Pagination\nMailchimp uses offset-based pagination:\n- Use `count` (page size, max 1000) and `offset` (skip N records)\n- Continue until collected records match `total_items` from the response\n- Default `count` is 10; always set explicitly for bulk operations\n- Search endpoints max at 10 pages (300 results for 30/page)\n\n### Subscriber Hash\nMany endpoints require `subscriber_hash` (MD5 of lowercase email):\n```\nimport hashlib\nsubscriber_hash = hashlib.md5(email.lower().encode()).hexdigest()\n```\n\n## Known Pitfalls\n\n### ID Formats\n- `list_id` (audience ID) is a short alphanumeric string (e.g., \"abc123def4\")\n- `campaign_id` is an alphanumeric string\n- `subscriber_hash` is an MD5 hex string (32 characters)\n- Segment IDs are integers\n\n### Rate Limits\n- Mailchimp enforces API rate limits; use batching for bulk subscriber operations\n- High-volume use of GET_MEMBER_INFO and ADD_OR_UPDATE_LIST_MEMBER can trigger throttling\n- Use `MAILCHIMP_BATCH_ADD_OR_REMOVE_MEMBERS` for bulk segment operations\n\n### Parameter Quirks\n- Nested parameters use double-underscore notation: `settings__subject__line`, `recipients__list__id`\n- `avg_open_rate` and `avg_click_rate` are 0-1 fractions, not percentages\n- `status_if_new` only applies to new contacts in upsert operations\n- `subscriber_hash` must be MD5 of lowercase email; wrong casing creates phantom records\n- Campaign `type` is required for creation; most common is \"regular\"\n- `MAILCHIMP_SEND_CAMPAIGN` returns HTTP 204 on success (no body)\n\n### Content and Compliance\n- Campaign HTML must include unsubscribe link and physical address (merge tags)\n- Content must be set via `MAILCHIMP_SET_CAMPAIGN_CONTENT` before sending\n- Test emails require campaign to have content already set\n\n## Quick Reference\n\n| Task | Tool Slug | Key Params |\n|------|-----------|------------|\n| List audiences | `MAILCHIMP_GET_LISTS_INFO` | `count`, `offset` |\n| Get audience details | `MAILCHIMP_GET_LIST_INFO` | `list_id` |\n| Create campaign | `MAILCHIMP_ADD_CAMPAIGN` | `type`, `recipients__list__id`, `settings__subject__line` |\n| Set campaign content | `MAILCHIMP_SET_CAMPAIGN_CONTENT` | `campaign_id`, `html` |\n| Send test email | `MAILCHIMP_SEND_TEST_EMAIL` | `campaign_id`, `test_emails` |\n| Send campaign | `MAILCHIMP_SEND_CAMPAIGN` | `campaign_id` |\n| Schedule campaign | `MAILCHIMP_SCHEDULE_CAMPAIGN` | `campaign_id`, `schedule_time` |\n| Get campaign info | `MAILCHIMP_GET_CAMPAIGN_INFO` | `campaign_id` |\n| Search campaigns | `MAILCHIMP_SEARCH_CAMPAIGNS` | `query` |\n| List campaigns | `MAILCHIMP_LIST_CAMPAIGNS` | `status`, `count`, `offset` |\n| Replicate campaign | `MAILCHIMP_REPLICATE_CAMPAIGN` | `campaign_id` |\n| List subscribers | `MAILCHIMP_LIST_MEMBERS_INFO` | `list_id`, `status`, `count`, `offset` |\n| Search members | `MAILCHIMP_SEARCH_MEMBERS` | `query`, `list_id` |\n| Get member info | `MAILCHIMP_GET_MEMBER_INFO` | `list_id`, `subscriber_hash` |\n| Add subscriber | `MAILCHIMP_ADD_MEMBER_TO_LIST` | `list_id`, `email_address`, `status` |\n| Upsert subscriber | `MAILCHIMP_ADD_OR_UPDATE_LIST_MEMBER` | `list_id`, `subscriber_hash`, `email_address`, `status_if_new` |\n| Batch members | `MAILCHIMP_BATCH_ADD_OR_REMOVE_MEMBERS` | `list_id`, `segment_id` |\n| List segments | `MAILCHIMP_LIST_SEGMENTS` | `list_id` |\n| Campaign report | `MAILCHIMP_GET_CAMPAIGN_REPORT` | `campaign_id` |\n| All reports | `MAILCHIMP_LIST_CAMPAIGN_REPORTS` | `count`, `offset` |\n| Link click details | `MAILCHIMP_LIST_CAMPAIGN_DETAILS` | `campaign_id`, `count` |\n| Subscriber activity | `MAILCHIMP_GET_SUBSCRIBER_EMAIL_ACTIVITY` | `campaign_id`, `subscriber_hash` |\n| Member recent activity | `MAILCHIMP_VIEW_RECENT_ACTIVITY` | `list_id`, `subscriber_hash` |\n| Campaign content | `MAILCHIMP_GET_CAMPAIGN_CONTENT` | `campaign_id` |",
    "author": "community",
    "version": "1.0.0",
    "category": "communication",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "meeting-notes",
    "name": "Meeting Notes",
    "description": "Create clear, actionable meeting summaries with agenda, decisions, action items, and next steps.",
    "instructions": "# Meeting Notes\n\nYou are an expert at creating clear, actionable meeting summaries and notes.\n\n## When to Apply\n\nUse this skill when:\n- Taking meeting notes\n- Summarizing discussions\n- Tracking action items and decisions\n- Creating meeting minutes\n- Documenting team syncs\n\n## Meeting Notes Structure\n\nFormat your output using this structure:\n\n```markdown\n# [Meeting Title]\n\n**Date**: [Date]\n**Time**: [Time]\n**Attendees**: [Names]\n**Note Taker**: [Name]\n\n## Agenda\n- [Topic 1]\n- [Topic 2]\n\n## Key Discussion Points\n\n### [Topic 1]\n- [Summary of discussion]\n- [Key points raised]\n\n### [Topic 2]\n[Continue for each topic...]\n\n## Decisions Made\n- ‚úÖ [Decision 1]\n- ‚úÖ [Decision 2]\n\n## Action Items\n\n| Action | Owner | Deadline | Status |\n|--------|-------|----------|--------|\n| [Task description] | [Name] | [Date] | [ ]  To Do |\n\n## Next Steps\n- [What happens next]\n- [Next meeting date if applicable]\n\n## Parking Lot\n- [Items tabled for later discussion]\n```\n\n## Best Practices\n\n- **During Meeting**: Capture key points, not verbatim\n- **After Meeting**: Send notes within 24 hours\n- **Action Items**: Specific, assigned, with deadlines\n- **Decisions**: Clear and documented\n- **Concise**: Focus on outcomes, not process\n\nIf the user provides a transcript or raw notes, distill them into this structured format. Infer the meeting title, attendees, and topics from context when not explicitly stated. Always extract action items with owners and deadlines where possible.",
    "author": "chatchat",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [
      "text"
    ],
    "examples": [
      "Take notes for my standup meeting",
      "Summarize this meeting discussion",
      "Create meeting minutes from the following transcript",
      "Document the action items from our team sync"
    ]
  },
  {
    "skillId": "microcopy",
    "name": "microcopy",
    "description": "UI copy and microcopy guidelines. Use when writing UI text, buttons, error messages, empty states, onboarding, or any user-facing copy. Triggers on i18n translation, UI text writing, or copy improvement tasks. Supports both Chinese and English.",
    "instructions": "# LobeHub UI Microcopy Guidelines\n\nBrand: **Where Agents Collaborate** - Focus on collaborative agent system, not just \"generation\".\n\n## Fixed Terminology\n\n| Chinese    | English       |\n| ---------- | ------------- |\n| Á©∫Èó¥       | Workspace     |\n| Âä©ÁêÜ       | Agent         |\n| Áæ§ÁªÑ       | Group         |\n| ‰∏ä‰∏ãÊñá     | Context       |\n| ËÆ∞ÂøÜ       | Memory        |\n| ËøûÊé•Âô®     | Integration   |\n| ÊäÄËÉΩ       | Skill         |\n| Âä©ÁêÜÊ°£Ê°à   | Agent Profile |\n| ËØùÈ¢ò       | Topic         |\n| ÊñáÁ®ø       | Page          |\n| Á§æÂå∫       | Community     |\n| ËµÑÊ∫ê       | Resource      |\n| Â∫ì         | Library       |\n| Ê®°ÂûãÊúçÂä°ÂïÜ | Provider      |\n\n## Brand Principles\n\n1. **Create**: One sentence ‚Üí usable Agent; clear next step\n2. **Collaborate**: Multi-agent; shared Context; controlled\n3. **Evolve**: Remember with consent; explainable; replayable\n\n## Writing Rules\n\n1. **Clarity first**: Short sentences, strong verbs, minimal adjectives\n2. **Layered**: Main line (simple) + optional detail (precise)\n3. **Consistent verbs**: Create / Connect / Run / Pause / Retry / View details\n4. **Actionable**: Every message tells next step; avoid generic \"OK/Cancel\"\n\n## Human Warmth (Balanced)\n\nDefault: **80% information, 20% warmth**\nKey moments: **70/30** (first-time, empty state, failures, long waits)\n\n**Hard cap**: At most half sentence of warmth, followed by clear next step.\n\n**Order**:\n\n1. Acknowledge situation (no judgment)\n2. Restore control (pause/replay/edit/undo/clear Memory)\n3. Provide next action\n\n**Avoid**: Preachy encouragement, grand narratives, over-anthropomorphizing\n\n## Patterns\n\n**Getting started**:\n\n- \"Starting with one sentence is enough. Describe your goal.\"\n- \"Not sure where to begin? Tell me the outcome.\"\n\n**Long wait**:\n\n- \"Running‚Ä¶ You can switch tasks‚ÄîI'll notify you when done.\"\n- \"This may take a few minutes. To speed up: reduce Context / switch model.\"\n\n**Failure**:\n\n- \"That didn't run through. Retry, or view details to fix.\"\n- \"Connection failed. Re-authorize in Settings, or try again later.\"\n\n**Collaboration**:\n\n- \"Align everyone to the same Context.\"\n- \"Different opinions are fine. Write the goal first.\"\n\n## Errors/Exceptions\n\nMust include:\n\n1. **What happened**\n2. (Optional) **Why**\n3. **What user can do next**\n\nProvide: Retry / View details / Go to Settings / Contact support / Copy logs\n\nNever blame user. Put error codes in \"Details\".",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "nano-banana-pro",
    "name": "nano-banana-pro",
    "description": "Generate or edit images via Gemini 3 Pro Image (Nano Banana Pro).",
    "instructions": "# Nano Banana Pro (Gemini 3 Pro Image)\n\nUse the bundled script to generate or edit images.\n\nGenerate\n\n```bash\nuv run {baseDir}/scripts/generate_image.py --prompt \"your image description\" --filename \"output.png\" --resolution 1K\n```\n\nEdit (single image)\n\n```bash\nuv run {baseDir}/scripts/generate_image.py --prompt \"edit instructions\" --filename \"output.png\" -i \"/path/in.png\" --resolution 2K\n```\n\nMulti-image composition (up to 14 images)\n\n```bash\nuv run {baseDir}/scripts/generate_image.py --prompt \"combine these into one scene\" --filename \"output.png\" -i img1.png -i img2.png -i img3.png\n```\n\nAPI key\n\n- `GEMINI_API_KEY` env var\n- Or set `skills.\"nano-banana-pro\".apiKey` / `skills.\"nano-banana-pro\".env.GEMINI_API_KEY` in `~/.openclaw/openclaw.json`\n\nNotes\n\n- Resolutions: `1K` (default), `2K`, `4K`.\n- Use timestamps in filenames: `yyyy-mm-dd-hh-mm-ss-name.png`.\n- The script prints a `MEDIA:` line for OpenClaw to auto-attach on supported chat providers.\n- Do not read the image back; report the saved path only.",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "nano-pdf",
    "name": "nano-pdf",
    "description": "Edit PDFs with natural-language instructions using the nano-pdf CLI.",
    "instructions": "# nano-pdf\n\nUse `nano-pdf` to apply edits to a specific page in a PDF using a natural-language instruction.\n\n## Quick start\n\n```bash\nnano-pdf edit deck.pdf 1 \"Change the title to 'Q3 Results' and fix the typo in the subtitle\"\n```\n\nNotes:\n\n- Page numbers are 0-based or 1-based depending on the tool‚Äôs version/config; if the result looks off by one, retry with the other.\n- Always sanity-check the output PDF before sending it out.",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "nutrient-document-processing",
    "name": "nutrient-document-processing",
    "description": "Process, convert, OCR, extract, redact, sign, and fill documents using the Nutrient DWS API. Works with PDFs, DOCX, XLSX, PPTX, HTML, and images.",
    "instructions": "# Nutrient Document Processing\n\nProcess documents with the [Nutrient DWS Processor API](https://www.nutrient.io/api/). Convert formats, extract text and tables, OCR scanned documents, redact PII, add watermarks, digitally sign, and fill PDF forms.\n\n## Setup\n\nGet a free API key at **[nutrient.io](https://dashboard.nutrient.io/sign_up/?product=processor)**\n\n```bash\nexport NUTRIENT_API_KEY=\"pdf_live_...\"\n```\n\nAll requests go to `https://api.nutrient.io/build` as multipart POST with an `instructions` JSON field.\n\n## Operations\n\n### Convert Documents\n\n```bash\n# DOCX to PDF\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.docx=@document.docx\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.docx\"}]}' \\\n  -o output.pdf\n\n# PDF to DOCX\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"docx\"}}' \\\n  -o output.docx\n\n# HTML to PDF\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"index.html=@index.html\" \\\n  -F 'instructions={\"parts\":[{\"html\":\"index.html\"}]}' \\\n  -o output.pdf\n```\n\nSupported inputs: PDF, DOCX, XLSX, PPTX, DOC, XLS, PPT, PPS, PPSX, ODT, RTF, HTML, JPG, PNG, TIFF, HEIC, GIF, WebP, SVG, TGA, EPS.\n\n### Extract Text and Data\n\n```bash\n# Extract plain text\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"text\"}}' \\\n  -o output.txt\n\n# Extract tables as Excel\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"xlsx\"}}' \\\n  -o tables.xlsx\n```\n\n### OCR Scanned Documents\n\n```bash\n# OCR to searchable PDF (supports 100+ languages)\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"scanned.pdf=@scanned.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"scanned.pdf\"}],\"actions\":[{\"type\":\"ocr\",\"language\":\"english\"}]}' \\\n  -o searchable.pdf\n```\n\nLanguages: Supports 100+ languages via ISO 639-2 codes (e.g., `eng`, `deu`, `fra`, `spa`, `jpn`, `kor`, `chi_sim`, `chi_tra`, `ara`, `hin`, `rus`). Full language names like `english` or `german` also work. See the [complete OCR language table](https://www.nutrient.io/guides/document-engine/ocr/language-support/) for all supported codes.\n\n### Redact Sensitive Information\n\n```bash\n# Pattern-based (SSN, email)\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"redaction\",\"strategy\":\"preset\",\"strategyOptions\":{\"preset\":\"social-security-number\"}},{\"type\":\"redaction\",\"strategy\":\"preset\",\"strategyOptions\":{\"preset\":\"email-address\"}}]}' \\\n  -o redacted.pdf\n\n# Regex-based\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"redaction\",\"strategy\":\"regex\",\"strategyOptions\":{\"regex\":\"\\\\b[A-Z]{2}\\\\d{6}\\\\b\"}}]}' \\\n  -o redacted.pdf\n```\n\nPresets: `social-security-number`, `email-address`, `credit-card-number`, `international-phone-number`, `north-american-phone-number`, `date`, `time`, `url`, `ipv4`, `ipv6`, `mac-address`, `us-zip-code`, `vin`.\n\n### Add Watermarks\n\n```bash\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"watermark\",\"text\":\"CONFIDENTIAL\",\"fontSize\":72,\"opacity\":0.3,\"rotation\":-45}]}' \\\n  -o watermarked.pdf\n```\n\n### Digital Signatures\n\n```bash\n# Self-signed CMS signature\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"sign\",\"signatureType\":\"cms\"}]}' \\\n  -o signed.pdf\n```\n\n### Fill PDF Forms\n\n```bash\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"form.pdf=@form.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"form.pdf\"}],\"actions\":[{\"type\":\"fillForm\",\"formFields\":{\"name\":\"Jane Smith\",\"email\":\"jane@example.com\",\"date\":\"2026-02-06\"}}]}' \\\n  -o filled.pdf\n```\n\n## MCP Server (Alternative)\n\nFor native tool integration, use the MCP server instead of curl:\n\n```json\n{\n  \"mcpServers\": {\n    \"nutrient-dws\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@nutrient-sdk/dws-mcp-server\"],\n      \"env\": {\n        \"NUTRIENT_DWS_API_KEY\": \"YOUR_API_KEY\",\n        \"SANDBOX_PATH\": \"/path/to/working/directory\"\n      }\n    }\n  }\n}\n```\n\n## When to Use\n\n- Converting documents between formats (PDF, DOCX, XLSX, PPTX, HTML, images)\n- Extracting text, tables, or key-value pairs from PDFs\n- OCR on scanned documents or images\n- Redacting PII before sharing documents\n- Adding watermarks to drafts or confidential documents\n- Digitally signing contracts or agreements\n- Filling PDF forms programmatically\n\n## Links\n\n- [API Playground](https://dashboard.nutrient.io/processor-api/playground/)\n- [Full API Docs](https://www.nutrient.io/guides/dws-processor/)\n- [Agent Skill Repo](https://github.com/PSPDFKit-labs/nutrient-agent-skill)\n- [npm MCP Server](https://www.npmjs.com/package/@nutrient-sdk/dws-mcp-server)",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "nutrient-document-processing-ja",
    "name": "nutrient-document-processing",
    "description": "Nutrient DWS API „Çí‰ΩøÁî®„Åó„Å¶„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆÂá¶ÁêÜ„ÄÅÂ§âÊèõ„ÄÅOCR„ÄÅÊäΩÂá∫„ÄÅÁ∑®ÈõÜ„ÄÅÁΩ≤Âêç„ÄÅ„Éï„Ç©„Éº„É†ÂÖ•Âäõ„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇPDF„ÄÅDOCX„ÄÅXLSX„ÄÅPPTX„ÄÅHTML„ÄÅÁîªÂÉè„Å´ÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
    "instructions": "# Nutrient Document Processing\n\n[Nutrient DWS Processor API](https://www.nutrient.io/api/) „Åß„Éâ„Ç≠„É•„É°„É≥„Éà„ÇíÂá¶ÁêÜ„Åó„Åæ„Åô„ÄÇ„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÂ§âÊèõ„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„Å®„ÉÜ„Éº„Éñ„É´„ÅÆÊäΩÂá∫„ÄÅ„Çπ„Ç≠„É£„É≥„Åï„Çå„Åü„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ OCR„ÄÅPII „ÅÆÁ∑®ÈõÜ„ÄÅ„Ç¶„Ç©„Éº„Çø„Éº„Éû„Éº„ÇØ„ÅÆËøΩÂä†„ÄÅ„Éá„Ç∏„Çø„É´ÁΩ≤Âêç„ÄÅPDF „Éï„Ç©„Éº„É†„ÅÆÂÖ•Âäõ„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ\n\n## „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó\n\n**[nutrient.io](https://dashboard.nutrient.io/sign_up/?product=processor)** „ÅßÁÑ°Êñô„ÅÆ API „Ç≠„Éº„ÇíÂèñÂæó„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n\n```bash\nexport NUTRIENT_API_KEY=\"pdf_live_...\"\n```\n\n„Åô„Åπ„Å¶„ÅÆ„É™„ÇØ„Ç®„Çπ„Éà„ÅØ `https://api.nutrient.io/build` „Å´ `instructions` JSON „Éï„Ç£„Éº„É´„Éâ„ÇíÂê´„ÇÄ„Éû„É´„ÉÅ„Éë„Éº„Éà POST „Å®„Åó„Å¶ÈÄÅ‰ø°„Åï„Çå„Åæ„Åô„ÄÇ\n\n## Êìç‰Ωú\n\n### „Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆÂ§âÊèõ\n\n```bash\n# DOCX „Åã„Çâ PDF „Å∏\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.docx=@document.docx\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.docx\"}]}' \\\n  -o output.pdf\n\n# PDF „Åã„Çâ DOCX „Å∏\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"docx\"}}' \\\n  -o output.docx\n\n# HTML „Åã„Çâ PDF „Å∏\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"index.html=@index.html\" \\\n  -F 'instructions={\"parts\":[{\"html\":\"index.html\"}]}' \\\n  -o output.pdf\n```\n\n„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„ÇãÂÖ•ÂäõÂΩ¢Âºè: PDF„ÄÅDOCX„ÄÅXLSX„ÄÅPPTX„ÄÅDOC„ÄÅXLS„ÄÅPPT„ÄÅPPS„ÄÅPPSX„ÄÅODT„ÄÅRTF„ÄÅHTML„ÄÅJPG„ÄÅPNG„ÄÅTIFF„ÄÅHEIC„ÄÅGIF„ÄÅWebP„ÄÅSVG„ÄÅTGA„ÄÅEPS„ÄÇ\n\n### „ÉÜ„Ç≠„Çπ„Éà„Å®„Éá„Éº„Çø„ÅÆÊäΩÂá∫\n\n```bash\n# „Éó„É¨„Éº„É≥„ÉÜ„Ç≠„Çπ„Éà„ÅÆÊäΩÂá∫\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"text\"}}' \\\n  -o output.txt\n\n# „ÉÜ„Éº„Éñ„É´„Çí Excel „Å®„Åó„Å¶ÊäΩÂá∫\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"xlsx\"}}' \\\n  -o tables.xlsx\n```\n\n### „Çπ„Ç≠„É£„É≥„Åï„Çå„Åü„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ OCR\n\n```bash\n# Ê§úÁ¥¢ÂèØËÉΩ„Å™ PDF „Å∏„ÅÆ OCRÔºà100‰ª•‰∏ä„ÅÆË®ÄË™û„Çí„Çµ„Éù„Éº„ÉàÔºâ\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"scanned.pdf=@scanned.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"scanned.pdf\"}],\"actions\":[{\"type\":\"ocr\",\"language\":\"english\"}]}' \\\n  -o searchable.pdf\n```\n\nË®ÄË™û: ISO 639-2 „Ç≥„Éº„ÉâÔºà‰æã: `eng`„ÄÅ`deu`„ÄÅ`fra`„ÄÅ`spa`„ÄÅ`jpn`„ÄÅ`kor`„ÄÅ`chi_sim`„ÄÅ`chi_tra`„ÄÅ`ara`„ÄÅ`hin`„ÄÅ`rus`Ôºâ„Çí‰ªã„Åó„Å¶100‰ª•‰∏ä„ÅÆË®ÄË™û„Çí„Çµ„Éù„Éº„Éà„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ`english` „ÇÑ `german` „Å™„Å©„ÅÆÂÆåÂÖ®„Å™Ë®ÄË™ûÂêç„ÇÇÊ©üËÉΩ„Åó„Åæ„Åô„ÄÇ„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Çã„Åô„Åπ„Å¶„ÅÆ„Ç≥„Éº„Éâ„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅ[ÂÆåÂÖ®„Å™ OCR Ë®ÄË™ûË°®](https://www.nutrient.io/guides/document-engine/ocr/language-support/)„ÇíÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n\n### Ê©üÂØÜÊÉÖÂ†±„ÅÆÁ∑®ÈõÜ\n\n```bash\n# „Éë„Çø„Éº„É≥„Éô„Éº„ÇπÔºàSSN„ÄÅ„É°„Éº„É´Ôºâ\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"redaction\",\"strategy\":\"preset\",\"strategyOptions\":{\"preset\":\"social-security-number\"}},{\"type\":\"redaction\",\"strategy\":\"preset\",\"strategyOptions\":{\"preset\":\"email-address\"}}]}' \\\n  -o redacted.pdf\n\n# Ê≠£Ë¶èË°®Áèæ„Éô„Éº„Çπ\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"redaction\",\"strategy\":\"regex\",\"strategyOptions\":{\"regex\":\"\\\\b[A-Z]{2}\\\\d{6}\\\\b\"}}]}' \\\n  -o redacted.pdf\n```\n\n„Éó„É™„Çª„ÉÉ„Éà: `social-security-number`„ÄÅ`email-address`„ÄÅ`credit-card-number`„ÄÅ`international-phone-number`„ÄÅ`north-american-phone-number`„ÄÅ`date`„ÄÅ`time`„ÄÅ`url`„ÄÅ`ipv4`„ÄÅ`ipv6`„ÄÅ`mac-address`„ÄÅ`us-zip-code`„ÄÅ`vin`„ÄÇ\n\n### „Ç¶„Ç©„Éº„Çø„Éº„Éû„Éº„ÇØ„ÅÆËøΩÂä†\n\n```bash\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"watermark\",\"text\":\"CONFIDENTIAL\",\"fontSize\":72,\"opacity\":0.3,\"rotation\":-45}]}' \\\n  -o watermarked.pdf\n```\n\n### „Éá„Ç∏„Çø„É´ÁΩ≤Âêç\n\n```bash\n# Ëá™Â∑±ÁΩ≤Âêç CMS ÁΩ≤Âêç\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"sign\",\"signatureType\":\"cms\"}]}' \\\n  -o signed.pdf\n```\n\n### PDF „Éï„Ç©„Éº„É†„ÅÆÂÖ•Âäõ\n\n```bash\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"form.pdf=@form.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"form.pdf\"}],\"actions\":[{\"type\":\"fillForm\",\"formFields\":{\"name\":\"Jane Smith\",\"email\":\"jane@example.com\",\"date\":\"2026-02-06\"}}]}' \\\n  -o filled.pdf\n```\n\n## MCP „Çµ„Éº„Éê„ÉºÔºà‰ª£ÊõøÔºâ\n\n„Éç„Ç§„ÉÜ„Ç£„Éñ„ÉÑ„Éº„É´Áµ±Âêà„Å´„ÅØ„ÄÅcurl „ÅÆ‰ª£„Çè„Çä„Å´ MCP „Çµ„Éº„Éê„Éº„Çí‰ΩøÁî®„Åó„Åæ„ÅôÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"nutrient-dws\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@nutrient-sdk/dws-mcp-server\"],\n      \"env\": {\n        \"NUTRIENT_DWS_API_KEY\": \"YOUR_API_KEY\",\n        \"SANDBOX_PATH\": \"/path/to/working/directory\"\n      }\n    }\n  }\n}\n```\n\n## ‰ΩøÁî®„Çø„Ç§„Éü„É≥„Ç∞\n\n- „Éï„Ç©„Éº„Éû„ÉÉ„ÉàÈñì„Åß„ÅÆ„Éâ„Ç≠„É•„É°„É≥„ÉàÂ§âÊèõÔºàPDF„ÄÅDOCX„ÄÅXLSX„ÄÅPPTX„ÄÅHTML„ÄÅÁîªÂÉèÔºâ\n- PDF „Åã„Çâ„ÉÜ„Ç≠„Çπ„Éà„ÄÅ„ÉÜ„Éº„Éñ„É´„ÄÅ„Ç≠„ÉºÂÄ§„Éö„Ç¢„ÅÆÊäΩÂá∫\n- „Çπ„Ç≠„É£„É≥„Åï„Çå„Åü„Éâ„Ç≠„É•„É°„É≥„Éà„Åæ„Åü„ÅØÁîªÂÉè„ÅÆ OCR\n- „Éâ„Ç≠„É•„É°„É≥„Éà„ÇíÂÖ±Êúâ„Åô„ÇãÂâç„ÅÆ PII „ÅÆÁ∑®ÈõÜ\n- „Éâ„É©„Éï„Éà„Åæ„Åü„ÅØÊ©üÂØÜÊñáÊõ∏„Å∏„ÅÆ„Ç¶„Ç©„Éº„Çø„Éº„Éû„Éº„ÇØ„ÅÆËøΩÂä†\n- Â•ëÁ¥Ñ„Åæ„Åü„ÅØÂêàÊÑèÊõ∏„Å∏„ÅÆ„Éá„Ç∏„Çø„É´ÁΩ≤Âêç\n- „Éó„É≠„Ç∞„É©„É†„Å´„Çà„Çã PDF „Éï„Ç©„Éº„É†„ÅÆÂÖ•Âäõ\n\n## „É™„É≥„ÇØ\n\n- [API Playground](https://dashboard.nutrient.io/processor-api/playground/)\n- [ÂÆåÂÖ®„Å™ API „Éâ„Ç≠„É•„É°„É≥„Éà](https://www.nutrient.io/guides/dws-processor/)\n- [Agent Skill „É™„Éù„Ç∏„Éà„É™](https://github.com/PSPDFKit-labs/nutrient-agent-skill)\n- [npm MCP „Çµ„Éº„Éê„Éº](https://www.npmjs.com/package/@nutrient-sdk/dws-mcp-server)",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "nutrient-document-processing-zh",
    "name": "nutrient-document-processing",
    "description": "‰ΩøÁî®Nutrient DWS APIÂ§ÑÁêÜ„ÄÅËΩ¨Êç¢„ÄÅOCR„ÄÅÊèêÂèñ„ÄÅÁºñËæë„ÄÅÁ≠æÁΩ≤ÂíåÂ°´ÂÜôÊñáÊ°£„ÄÇÊîØÊåÅPDF„ÄÅDOCX„ÄÅXLSX„ÄÅPPTX„ÄÅHTMLÂíåÂõæÂÉèÊñá‰ª∂„ÄÇ",
    "instructions": "# ÊñáÊ°£Â§ÑÁêÜ\n\n‰ΩøÁî® [Nutrient DWS Processor API](https://www.nutrient.io/api/) Â§ÑÁêÜÊñáÊ°£„ÄÇËΩ¨Êç¢Ê†ºÂºè„ÄÅÊèêÂèñÊñáÊú¨ÂíåË°®Ê†º„ÄÅÂØπÊâ´ÊèèÊñáÊ°£ËøõË°å OCR„ÄÅÁºñËæë PII„ÄÅÊ∑ªÂä†Ê∞¥Âç∞„ÄÅÊï∞Â≠óÁ≠æÂêç‰ª•ÂèäÂ°´ÂÜô PDF Ë°®Âçï„ÄÇ\n\n## ËÆæÁΩÆ\n\nÂú® **[nutrient.io](https://dashboard.nutrient.io/sign_up/?product=processor)** Ëé∑Âèñ‰∏Ä‰∏™ÂÖçË¥πÁöÑ API ÂØÜÈí•\n\n```bash\nexport NUTRIENT_API_KEY=\"pdf_live_...\"\n```\n\nÊâÄÊúâËØ∑Ê±ÇÈÉΩ‰ª• multipart POST ÂΩ¢ÂºèÂèëÈÄÅÂà∞ `https://api.nutrient.io/build`ÔºåÂπ∂ÈôÑÂ∏¶‰∏Ä‰∏™ `instructions` JSON Â≠óÊÆµ„ÄÇ\n\n## Êìç‰Ωú\n\n### ËΩ¨Êç¢ÊñáÊ°£\n\n```bash\n# DOCX to PDF\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.docx=@document.docx\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.docx\"}]}' \\\n  -o output.pdf\n\n# PDF to DOCX\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"docx\"}}' \\\n  -o output.docx\n\n# HTML to PDF\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"index.html=@index.html\" \\\n  -F 'instructions={\"parts\":[{\"html\":\"index.html\"}]}' \\\n  -o output.pdf\n```\n\nÊîØÊåÅÁöÑËæìÂÖ•Ê†ºÂºèÔºöPDF, DOCX, XLSX, PPTX, DOC, XLS, PPT, PPS, PPSX, ODT, RTF, HTML, JPG, PNG, TIFF, HEIC, GIF, WebP, SVG, TGA, EPS„ÄÇ\n\n### ÊèêÂèñÊñáÊú¨ÂíåÊï∞ÊçÆ\n\n```bash\n# Extract plain text\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"text\"}}' \\\n  -o output.txt\n\n# Extract tables as Excel\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"output\":{\"type\":\"xlsx\"}}' \\\n  -o tables.xlsx\n```\n\n### OCR Êâ´ÊèèÊñáÊ°£\n\n```bash\n# OCR to searchable PDF (supports 100+ languages)\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"scanned.pdf=@scanned.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"scanned.pdf\"}],\"actions\":[{\"type\":\"ocr\",\"language\":\"english\"}]}' \\\n  -o searchable.pdf\n```\n\nÊîØÊåÅËØ≠Ë®ÄÔºöÈÄöËøá ISO 639-2 ‰ª£Á†ÅÊîØÊåÅ 100 Â§öÁßçËØ≠Ë®ÄÔºà‰æãÂ¶ÇÔºå`eng`, `deu`, `fra`, `spa`, `jpn`, `kor`, `chi_sim`, `chi_tra`, `ara`, `hin`, `rus`Ôºâ„ÄÇÂÆåÊï¥ÁöÑËØ≠Ë®ÄÂêçÁß∞Â¶Ç `english` Êàñ `german` ‰πüÈÄÇÁî®„ÄÇÊü•Áúã [ÂÆåÊï¥ÁöÑ OCR ËØ≠Ë®ÄË°®](https://www.nutrient.io/guides/document-engine/ocr/language-support/) ‰ª•Ëé∑ÂèñÊâÄÊúâÊîØÊåÅÁöÑ‰ª£Á†Å„ÄÇ\n\n### ÁºñËæëÊïèÊÑü‰ø°ÊÅØ\n\n```bash\n# Pattern-based (SSN, email)\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"redaction\",\"strategy\":\"preset\",\"strategyOptions\":{\"preset\":\"social-security-number\"}},{\"type\":\"redaction\",\"strategy\":\"preset\",\"strategyOptions\":{\"preset\":\"email-address\"}}]}' \\\n  -o redacted.pdf\n\n# Regex-based\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"redaction\",\"strategy\":\"regex\",\"strategyOptions\":{\"regex\":\"\\\\b[A-Z]{2}\\\\d{6}\\\\b\"}}]}' \\\n  -o redacted.pdf\n```\n\nÈ¢ÑËÆæÔºö`social-security-number`, `email-address`, `credit-card-number`, `international-phone-number`, `north-american-phone-number`, `date`, `time`, `url`, `ipv4`, `ipv6`, `mac-address`, `us-zip-code`, `vin`„ÄÇ\n\n### Ê∑ªÂä†Ê∞¥Âç∞\n\n```bash\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"watermark\",\"text\":\"CONFIDENTIAL\",\"fontSize\":72,\"opacity\":0.3,\"rotation\":-45}]}' \\\n  -o watermarked.pdf\n```\n\n### Êï∞Â≠óÁ≠æÂêç\n\n```bash\n# Self-signed CMS signature\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"document.pdf=@document.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"document.pdf\"}],\"actions\":[{\"type\":\"sign\",\"signatureType\":\"cms\"}]}' \\\n  -o signed.pdf\n```\n\n### Â°´ÂÜô PDF Ë°®Âçï\n\n```bash\ncurl -X POST https://api.nutrient.io/build \\\n  -H \"Authorization: Bearer $NUTRIENT_API_KEY\" \\\n  -F \"form.pdf=@form.pdf\" \\\n  -F 'instructions={\"parts\":[{\"file\":\"form.pdf\"}],\"actions\":[{\"type\":\"fillForm\",\"formFields\":{\"name\":\"Jane Smith\",\"email\":\"jane@example.com\",\"date\":\"2026-02-06\"}}]}' \\\n  -o filled.pdf\n```\n\n## MCP ÊúçÂä°Âô®ÔºàÊõø‰ª£ÊñπÊ°àÔºâ\n\nÂØπ‰∫éÂéüÁîüÂ∑•ÂÖ∑ÈõÜÊàêÔºåËØ∑‰ΩøÁî® MCP ÊúçÂä°Âô®‰ª£Êõø curlÔºö\n\n```json\n{\n  \"mcpServers\": {\n    \"nutrient-dws\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@nutrient-sdk/dws-mcp-server\"],\n      \"env\": {\n        \"NUTRIENT_DWS_API_KEY\": \"YOUR_API_KEY\",\n        \"SANDBOX_PATH\": \"/path/to/working/directory\"\n      }\n    }\n  }\n}\n```\n\n## ‰ΩøÁî®Âú∫ÊôØ\n\n* Âú®Ê†ºÂºè‰πãÈó¥ËΩ¨Êç¢ÊñáÊ°£ÔºàPDF, DOCX, XLSX, PPTX, HTML, ÂõæÂÉèÔºâ\n* ‰ªé PDF ‰∏≠ÊèêÂèñÊñáÊú¨„ÄÅË°®Ê†ºÊàñÈîÆÂÄºÂØπ\n* ÂØπÊâ´ÊèèÊñáÊ°£ÊàñÂõæÂÉèËøõË°å OCR\n* Âú®ÂÖ±‰∫´ÊñáÊ°£ÂâçÁºñËæë PII\n* ‰∏∫ËçâÁ®øÊàñÊú∫ÂØÜÊñáÊ°£Ê∑ªÂä†Ê∞¥Âç∞\n* Êï∞Â≠óÁ≠æÁΩ≤ÂêàÂêåÊàñÂçèËÆÆ\n* ‰ª•ÁºñÁ®ãÊñπÂºèÂ°´ÂÜô PDF Ë°®Âçï\n\n## ÈìæÊé•\n\n* [API ÊºîÁªÉÂú∫](https://dashboard.nutrient.io/processor-api/playground/)\n* [ÂÆåÊï¥ API ÊñáÊ°£](https://www.nutrient.io/guides/dws-processor/)\n* [‰ª£ÁêÜÊäÄËÉΩ‰ªìÂ∫ì](https://github.com/PSPDFKit-labs/nutrient-agent-skill)\n* [npm MCP ÊúçÂä°Âô®](https://www.npmjs.com/package/@nutrient-sdk/dws-mcp-server)",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "openai-image-gen",
    "name": "openai-image-gen",
    "description": "Batch-generate images via OpenAI Images API. Random prompt sampler + `index.html` gallery.",
    "instructions": "# OpenAI Image Gen\n\nGenerate a handful of ‚Äúrandom but structured‚Äù prompts and render them via the OpenAI Images API.\n\n## Run\n\n```bash\npython3 {baseDir}/scripts/gen.py\nopen ~/Projects/tmp/openai-image-gen-*/index.html  # if ~/Projects/tmp exists; else ./tmp/...\n```\n\nUseful flags:\n\n```bash\n# GPT image models with various options\npython3 {baseDir}/scripts/gen.py --count 16 --model gpt-image-1\npython3 {baseDir}/scripts/gen.py --prompt \"ultra-detailed studio photo of a lobster astronaut\" --count 4\npython3 {baseDir}/scripts/gen.py --size 1536x1024 --quality high --out-dir ./out/images\npython3 {baseDir}/scripts/gen.py --model gpt-image-1.5 --background transparent --output-format webp\n\n# DALL-E 3 (note: count is automatically limited to 1)\npython3 {baseDir}/scripts/gen.py --model dall-e-3 --quality hd --size 1792x1024 --style vivid\npython3 {baseDir}/scripts/gen.py --model dall-e-3 --style natural --prompt \"serene mountain landscape\"\n\n# DALL-E 2\npython3 {baseDir}/scripts/gen.py --model dall-e-2 --size 512x512 --count 4\n```\n\n## Model-Specific Parameters\n\nDifferent models support different parameter values. The script automatically selects appropriate defaults based on the model.\n\n### Size\n\n- **GPT image models** (`gpt-image-1`, `gpt-image-1-mini`, `gpt-image-1.5`): `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto`\n  - Default: `1024x1024`\n- **dall-e-3**: `1024x1024`, `1792x1024`, or `1024x1792`\n  - Default: `1024x1024`\n- **dall-e-2**: `256x256`, `512x512`, or `1024x1024`\n  - Default: `1024x1024`\n\n### Quality\n\n- **GPT image models**: `auto`, `high`, `medium`, or `low`\n  - Default: `high`\n- **dall-e-3**: `hd` or `standard`\n  - Default: `standard`\n- **dall-e-2**: `standard` only\n  - Default: `standard`\n\n### Other Notable Differences\n\n- **dall-e-3** only supports generating 1 image at a time (`n=1`). The script automatically limits count to 1 when using this model.\n- **GPT image models** support additional parameters:\n  - `--background`: `transparent`, `opaque`, or `auto` (default)\n  - `--output-format`: `png` (default), `jpeg`, or `webp`\n  - Note: `stream` and `moderation` are available via API but not yet implemented in this script\n- **dall-e-3** has a `--style` parameter: `vivid` (hyper-real, dramatic) or `natural` (more natural looking)\n\n## Output\n\n- `*.png`, `*.jpeg`, or `*.webp` images (output format depends on model + `--output-format`)\n- `prompts.json` (prompt ‚Üí file mapping)\n- `index.html` (thumbnail gallery)",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "openai-whisper-api",
    "name": "openai-whisper-api",
    "description": "Transcribe audio via OpenAI Audio Transcriptions API (Whisper).",
    "instructions": "# OpenAI Whisper API (curl)\n\nTranscribe an audio file via OpenAI‚Äôs `/v1/audio/transcriptions` endpoint.\n\n## Quick start\n\n```bash\n{baseDir}/scripts/transcribe.sh /path/to/audio.m4a\n```\n\nDefaults:\n\n- Model: `whisper-1`\n- Output: `<input>.txt`\n\n## Useful flags\n\n```bash\n{baseDir}/scripts/transcribe.sh /path/to/audio.ogg --model whisper-1 --out /tmp/transcript.txt\n{baseDir}/scripts/transcribe.sh /path/to/audio.m4a --language en\n{baseDir}/scripts/transcribe.sh /path/to/audio.m4a --prompt \"Speaker names: Peter, Daniel\"\n{baseDir}/scripts/transcribe.sh /path/to/audio.m4a --json --out /tmp/transcript.json\n```\n\n## API key\n\nSet `OPENAI_API_KEY`, or configure it in `~/.openclaw/openclaw.json`:\n\n```json5\n{\n  skills: {\n    \"openai-whisper-api\": {\n      apiKey: \"OPENAI_KEY_HERE\",\n    },\n  },\n}\n```",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "pdf",
    "name": "pdf",
    "description": "Use this skill whenever the user wants to do anything with PDF files. This includes reading or extracting text/tables from PDFs, combining or merging multiple PDFs into one, splitting PDFs apart, rotating pages, adding watermarks, creating new PDFs, filling PDF forms, encrypting/decrypting PDFs, extracting images, and OCR on scanned PDFs to make them searchable. If the user mentions a .pdf file or asks to produce one, use this skill.",
    "instructions": "# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see REFERENCE.md. If you need to fill out a PDF form, read FORMS.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n#### Subscripts and Superscripts\n\n**IMPORTANT**: Never use Unicode subscript/superscript characters (‚ÇÄ‚ÇÅ‚ÇÇ‚ÇÉ‚ÇÑ‚ÇÖ‚ÇÜ‚Çá‚Çà‚Çâ, ‚Å∞¬π¬≤¬≥‚Å¥‚Åµ‚Å∂‚Å∑‚Å∏‚Åπ) in ReportLab PDFs. The built-in fonts do not include these glyphs, causing them to render as solid black boxes.\n\nInstead, use ReportLab's XML markup tags in Paragraph objects:\n```python\nfrom reportlab.platypus import Paragraph\nfrom reportlab.lib.styles import getSampleStyleSheet\n\nstyles = getSampleStyleSheet()\n\n# Subscripts: use <sub> tag\nchemical = Paragraph(\"H<sub>2</sub>O\", styles['Normal'])\n\n# Superscripts: use <super> tag\nsquared = Paragraph(\"x<super>2</super> + y<super>2</super>\", styles['Normal'])\n```\n\nFor canvas-drawn text (not Paragraph objects), manually adjust font the size and position rather than using Unicode subscripts/superscripts.\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see FORMS.md) | See FORMS.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see REFERENCE.md\n- For JavaScript libraries (pdf-lib), see REFERENCE.md\n- If you need to fill out a PDF form, follow the instructions in FORMS.md\n- For troubleshooting guides, see REFERENCE.md",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "pdf-composio",
    "name": "pdf",
    "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
    "instructions": "# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see reference.md\n- For JavaScript libraries (pdf-lib), see reference.md\n- If you need to fill out a PDF form, follow the instructions in forms.md\n- For troubleshooting guides, see reference.md",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "pptx",
    "name": "pptx",
    "description": "Use this skill any time a .pptx file is involved in any way ‚Äî as input, output, or both. This includes: creating slide decks, pitch decks, or presentations; reading, parsing, or extracting text from any .pptx file (even if the extracted content will be used elsewhere, like in an email or summary); editing, modifying, or updating existing presentations; combining or splitting slide files; working with templates, layouts, speaker notes, or comments. Trigger whenever the user mentions \\\"deck,\\\" \\\"slides,\\\" \\\"presentation,\\\" or references a .pptx filename, regardless of what they plan to do with the content afterward. If a .pptx file needs to be opened, created, or touched, use this skill.",
    "instructions": "# PPTX Skill\n\n## Quick Reference\n\n| Task | Guide |\n|------|-------|\n| Read/analyze content | `python -m markitdown presentation.pptx` |\n| Edit or create from template | Read [editing.md](editing.md) |\n| Create from scratch | Read [pptxgenjs.md](pptxgenjs.md) |\n\n---\n\n## Reading Content\n\n```bash\n# Text extraction\npython -m markitdown presentation.pptx\n\n# Visual overview\npython scripts/thumbnail.py presentation.pptx\n\n# Raw XML\npython scripts/office/unpack.py presentation.pptx unpacked/\n```\n\n---\n\n## Editing Workflow\n\n**Read [editing.md](editing.md) for full details.**\n\n1. Analyze template with `thumbnail.py`\n2. Unpack ‚Üí manipulate slides ‚Üí edit content ‚Üí clean ‚Üí pack\n\n---\n\n## Creating from Scratch\n\n**Read [pptxgenjs.md](pptxgenjs.md) for full details.**\n\nUse when no template or reference presentation is available.\n\n---\n\n## Design Ideas\n\n**Don't create boring slides.** Plain bullets on a white background won't impress anyone. Consider ideas from this list for each slide.\n\n### Before Starting\n\n- **Pick a bold, content-informed color palette**: The palette should feel designed for THIS topic. If swapping your colors into a completely different presentation would still \"work,\" you haven't made specific enough choices.\n- **Dominance over equality**: One color should dominate (60-70% visual weight), with 1-2 supporting tones and one sharp accent. Never give all colors equal weight.\n- **Dark/light contrast**: Dark backgrounds for title + conclusion slides, light for content (\"sandwich\" structure). Or commit to dark throughout for a premium feel.\n- **Commit to a visual motif**: Pick ONE distinctive element and repeat it ‚Äî rounded image frames, icons in colored circles, thick single-side borders. Carry it across every slide.\n\n### Color Palettes\n\nChoose colors that match your topic ‚Äî don't default to generic blue. Use these palettes as inspiration:\n\n| Theme | Primary | Secondary | Accent |\n|-------|---------|-----------|--------|\n| **Midnight Executive** | `1E2761` (navy) | `CADCFC` (ice blue) | `FFFFFF` (white) |\n| **Forest & Moss** | `2C5F2D` (forest) | `97BC62` (moss) | `F5F5F5` (cream) |\n| **Coral Energy** | `F96167` (coral) | `F9E795` (gold) | `2F3C7E` (navy) |\n| **Warm Terracotta** | `B85042` (terracotta) | `E7E8D1` (sand) | `A7BEAE` (sage) |\n| **Ocean Gradient** | `065A82` (deep blue) | `1C7293` (teal) | `21295C` (midnight) |\n| **Charcoal Minimal** | `36454F` (charcoal) | `F2F2F2` (off-white) | `212121` (black) |\n| **Teal Trust** | `028090` (teal) | `00A896` (seafoam) | `02C39A` (mint) |\n| **Berry & Cream** | `6D2E46` (berry) | `A26769` (dusty rose) | `ECE2D0` (cream) |\n| **Sage Calm** | `84B59F` (sage) | `69A297` (eucalyptus) | `50808E` (slate) |\n| **Cherry Bold** | `990011` (cherry) | `FCF6F5` (off-white) | `2F3C7E` (navy) |\n\n### For Each Slide\n\n**Every slide needs a visual element** ‚Äî image, chart, icon, or shape. Text-only slides are forgettable.\n\n**Layout options:**\n- Two-column (text left, illustration on right)\n- Icon + text rows (icon in colored circle, bold header, description below)\n- 2x2 or 2x3 grid (image on one side, grid of content blocks on other)\n- Half-bleed image (full left or right side) with content overlay\n\n**Data display:**\n- Large stat callouts (big numbers 60-72pt with small labels below)\n- Comparison columns (before/after, pros/cons, side-by-side options)\n- Timeline or process flow (numbered steps, arrows)\n\n**Visual polish:**\n- Icons in small colored circles next to section headers\n- Italic accent text for key stats or taglines\n\n### Typography\n\n**Choose an interesting font pairing** ‚Äî don't default to Arial. Pick a header font with personality and pair it with a clean body font.\n\n| Header Font | Body Font |\n|-------------|-----------|\n| Georgia | Calibri |\n| Arial Black | Arial |\n| Calibri | Calibri Light |\n| Cambria | Calibri |\n| Trebuchet MS | Calibri |\n| Impact | Arial |\n| Palatino | Garamond |\n| Consolas | Calibri |\n\n| Element | Size |\n|---------|------|\n| Slide title | 36-44pt bold |\n| Section header | 20-24pt bold |\n| Body text | 14-16pt |\n| Captions | 10-12pt muted |\n\n### Spacing\n\n- 0.5\" minimum margins\n- 0.3-0.5\" between content blocks\n- Leave breathing room‚Äîdon't fill every inch\n\n### Avoid (Common Mistakes)\n\n- **Don't repeat the same layout** ‚Äî vary columns, cards, and callouts across slides\n- **Don't center body text** ‚Äî left-align paragraphs and lists; center only titles\n- **Don't skimp on size contrast** ‚Äî titles need 36pt+ to stand out from 14-16pt body\n- **Don't default to blue** ‚Äî pick colors that reflect the specific topic\n- **Don't mix spacing randomly** ‚Äî choose 0.3\" or 0.5\" gaps and use consistently\n- **Don't style one slide and leave the rest plain** ‚Äî commit fully or keep it simple throughout\n- **Don't create text-only slides** ‚Äî add images, icons, charts, or visual elements; avoid plain title + bullets\n- **Don't forget text box padding** ‚Äî when aligning lines or shapes with text edges, set `margin: 0` on the text box or offset the shape to account for padding\n- **Don't use low-contrast elements** ‚Äî icons AND text need strong contrast against the background; avoid light text on light backgrounds or dark text on dark backgrounds\n- **NEVER use accent lines under titles** ‚Äî these are a hallmark of AI-generated slides; use whitespace or background color instead\n\n---\n\n## QA (Required)\n\n**Assume there are problems. Your job is to find them.**\n\nYour first render is almost never correct. Approach QA as a bug hunt, not a confirmation step. If you found zero issues on first inspection, you weren't looking hard enough.\n\n### Content QA\n\n```bash\npython -m markitdown output.pptx\n```\n\nCheck for missing content, typos, wrong order.\n\n**When using templates, check for leftover placeholder text:**\n\n```bash\npython -m markitdown output.pptx | grep -iE \"xxxx|lorem|ipsum|this.*(page|slide).*layout\"\n```\n\nIf grep returns results, fix them before declaring success.\n\n### Visual QA\n\n**‚ö†Ô∏è USE SUBAGENTS** ‚Äî even for 2-3 slides. You've been staring at the code and will see what you expect, not what's there. Subagents have fresh eyes.\n\nConvert slides to images (see [Converting to Images](#converting-to-images)), then use this prompt:\n\n```\nVisually inspect these slides. Assume there are issues ‚Äî find them.\n\nLook for:\n- Overlapping elements (text through shapes, lines through words, stacked elements)\n- Text overflow or cut off at edges/box boundaries\n- Decorative lines positioned for single-line text but title wrapped to two lines\n- Source citations or footers colliding with content above\n- Elements too close (< 0.3\" gaps) or cards/sections nearly touching\n- Uneven gaps (large empty area in one place, cramped in another)\n- Insufficient margin from slide edges (< 0.5\")\n- Columns or similar elements not aligned consistently\n- Low-contrast text (e.g., light gray text on cream-colored background)\n- Low-contrast icons (e.g., dark icons on dark backgrounds without a contrasting circle)\n- Text boxes too narrow causing excessive wrapping\n- Leftover placeholder content\n\nFor each slide, list issues or areas of concern, even if minor.\n\nRead and analyze these images:\n1. /path/to/slide-01.jpg (Expected: [brief description])\n2. /path/to/slide-02.jpg (Expected: [brief description])\n\nReport ALL issues found, including minor ones.\n```\n\n### Verification Loop\n\n1. Generate slides ‚Üí Convert to images ‚Üí Inspect\n2. **List issues found** (if none found, look again more critically)\n3. Fix issues\n4. **Re-verify affected slides** ‚Äî one fix often creates another problem\n5. Repeat until a full pass reveals no new issues\n\n**Do not declare success until you've completed at least one fix-and-verify cycle.**\n\n---\n\n## Converting to Images\n\nConvert presentations to individual slide images for visual inspection:\n\n```bash\npython scripts/office/soffice.py --headless --convert-to pdf output.pptx\npdftoppm -jpeg -r 150 output.pdf slide\n```\n\nThis creates `slide-01.jpg`, `slide-02.jpg`, etc.\n\nTo re-render specific slides after fixes:\n\n```bash\npdftoppm -jpeg -r 150 -f N -l N output.pdf slide-fixed\n```\n\n---\n\n## Dependencies\n\n- `pip install \"markitdown[pptx]\"` - text extraction\n- `pip install Pillow` - thumbnail grids\n- `npm install -g pptxgenjs` - creating from scratch\n- LibreOffice (`soffice`) - PDF conversion (auto-configured for sandboxed environments via `scripts/office/soffice.py`)\n- Poppler (`pdftoppm`) - PDF to images",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "pptx-composio",
    "name": "pptx",
    "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
    "instructions": "# PPTX creation, editing, and analysis\n\nUse this skill when the user needs to create, edit, or analyze .pptx files.\n\n## Read and inspect\n- Extract text quickly: `python -m markitdown file.pptx`\n- Inspect structure: `python ooxml/scripts/unpack.py <pptx> <dir>` then read `ppt/` XML files\n\n## Create new presentation\n- Build HTML slides and convert with `scripts/html2pptx.js` (one HTML file per slide)\n- Use clear hierarchy, consistent spacing, and readable fonts\n- Validate by generating thumbnails and checking for cutoffs or overlaps\n\n## Edit existing presentation\n- Unpack, edit slide XML (`ppt/slides/slide{N}.xml` and related files), then validate\n- Repack the presentation after changes\n\n## Output expectations\n- Summarize edits, files touched, and how to regenerate the final .pptx",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "read-arxiv-paper",
    "name": "read-arxiv-paper",
    "description": "Use this skill when when asked to read an arxiv paper given an arxiv URL",
    "instructions": "You will be given a URL of an arxiv paper, for example:\n\nhttps://www.arxiv.org/abs/2601.07372\n\n### Part 1: Normalize the URL\n\nThe goal is to fetch the TeX Source of the paper (not the PDF!), the URL always looks like this:\n\nhttps://www.arxiv.org/src/2601.07372\n\nNotice the /src/ in the url. Once you have the URL:\n\n### Part 2: Download the paper source\n\nFetch the url to a local .tar.gz file. A good location is `~/.cache/nanochat/knowledge/{arxiv_id}.tar.gz`.\n\n(If the file already exists, there is no need to re-download it).\n\n### Part 3: Unpack the file in that folder\n\nUnpack the contents into `~/.cache/nanochat/knowledge/{arxiv_id}` directory.\n\n### Part 4: Locate the entrypoint\n\nEvery latex source usually has an entrypoint, such as `main.tex` or something like that.\n\n### Part 5: Read the paper\n\nOnce you've found the entrypoint, Read the contents and then recurse through all other relevant source files to read the paper.\n\n#### Part 6: Report\n\nOnce you've read the paper, produce a summary of the paper into a markdown file at `./knowledge/summary_{tag}.md`. Notice that 1) use the local knowledge directory here (it's easier for me to open and reference here), not in `~/.cache`, and 2) generate some reasonable `tag` like e.g. `conditional_memory` or whatever seems appropriate given the paper. Probably make sure that the tag doesn't exist yet so you're not overwriting files.\n\nAs for the summary itself, remember that you're processing this paper within the context of the nanochat repository, so most often we we will be interested in how to apply the paper and its lessons to the nanochat project. Therefore, you should feel free to \"remind yourself\" of the related nanochat code by reading the relevant parts, and then explicitly make the connection of how this paper might relate to nanochat or what are things we might be inspired about or try.",
    "author": "community",
    "version": "1.0.0",
    "category": "research",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "regex-vs-llm-structured-text",
    "name": "regex-vs-llm-structured-text",
    "description": "Decision framework for choosing between regex and LLM when parsing structured text ‚Äî start with regex, add LLM only for low-confidence edge cases.",
    "instructions": "# Regex vs LLM for Structured Text Parsing\n\nA practical decision framework for parsing structured text (quizzes, forms, invoices, documents). The key insight: regex handles 95-98% of cases cheaply and deterministically. Reserve expensive LLM calls for the remaining edge cases.\n\n## When to Activate\n\n- Parsing structured text with repeating patterns (questions, forms, tables)\n- Deciding between regex and LLM for text extraction\n- Building hybrid pipelines that combine both approaches\n- Optimizing cost/accuracy tradeoffs in text processing\n\n## Decision Framework\n\n```\nIs the text format consistent and repeating?\n‚îú‚îÄ‚îÄ Yes (>90% follows a pattern) ‚Üí Start with Regex\n‚îÇ   ‚îú‚îÄ‚îÄ Regex handles 95%+ ‚Üí Done, no LLM needed\n‚îÇ   ‚îî‚îÄ‚îÄ Regex handles <95% ‚Üí Add LLM for edge cases only\n‚îî‚îÄ‚îÄ No (free-form, highly variable) ‚Üí Use LLM directly\n```\n\n## Architecture Pattern\n\n```\nSource Text\n    ‚îÇ\n    ‚ñº\n[Regex Parser] ‚îÄ‚îÄ‚îÄ Extracts structure (95-98% accuracy)\n    ‚îÇ\n    ‚ñº\n[Text Cleaner] ‚îÄ‚îÄ‚îÄ Removes noise (markers, page numbers, artifacts)\n    ‚îÇ\n    ‚ñº\n[Confidence Scorer] ‚îÄ‚îÄ‚îÄ Flags low-confidence extractions\n    ‚îÇ\n    ‚îú‚îÄ‚îÄ High confidence (‚â•0.95) ‚Üí Direct output\n    ‚îÇ\n    ‚îî‚îÄ‚îÄ Low confidence (<0.95) ‚Üí [LLM Validator] ‚Üí Output\n```\n\n## Implementation\n\n### 1. Regex Parser (Handles the Majority)\n\n```python\nimport re\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass ParsedItem:\n    id: str\n    text: str\n    choices: tuple[str, ...]\n    answer: str\n    confidence: float = 1.0\n\ndef parse_structured_text(content: str) -> list[ParsedItem]:\n    \"\"\"Parse structured text using regex patterns.\"\"\"\n    pattern = re.compile(\n        r\"(?P<id>\\d+)\\.\\s*(?P<text>.+?)\\n\"\n        r\"(?P<choices>(?:[A-D]\\..+?\\n)+)\"\n        r\"Answer:\\s*(?P<answer>[A-D])\",\n        re.MULTILINE | re.DOTALL,\n    )\n    items = []\n    for match in pattern.finditer(content):\n        choices = tuple(\n            c.strip() for c in re.findall(r\"[A-D]\\.\\s*(.+)\", match.group(\"choices\"))\n        )\n        items.append(ParsedItem(\n            id=match.group(\"id\"),\n            text=match.group(\"text\").strip(),\n            choices=choices,\n            answer=match.group(\"answer\"),\n        ))\n    return items\n```\n\n### 2. Confidence Scoring\n\nFlag items that may need LLM review:\n\n```python\n@dataclass(frozen=True)\nclass ConfidenceFlag:\n    item_id: str\n    score: float\n    reasons: tuple[str, ...]\n\ndef score_confidence(item: ParsedItem) -> ConfidenceFlag:\n    \"\"\"Score extraction confidence and flag issues.\"\"\"\n    reasons = []\n    score = 1.0\n\n    if len(item.choices) < 3:\n        reasons.append(\"few_choices\")\n        score -= 0.3\n\n    if not item.answer:\n        reasons.append(\"missing_answer\")\n        score -= 0.5\n\n    if len(item.text) < 10:\n        reasons.append(\"short_text\")\n        score -= 0.2\n\n    return ConfidenceFlag(\n        item_id=item.id,\n        score=max(0.0, score),\n        reasons=tuple(reasons),\n    )\n\ndef identify_low_confidence(\n    items: list[ParsedItem],\n    threshold: float = 0.95,\n) -> list[ConfidenceFlag]:\n    \"\"\"Return items below confidence threshold.\"\"\"\n    flags = [score_confidence(item) for item in items]\n    return [f for f in flags if f.score < threshold]\n```\n\n### 3. LLM Validator (Edge Cases Only)\n\n```python\ndef validate_with_llm(\n    item: ParsedItem,\n    original_text: str,\n    client,\n) -> ParsedItem:\n    \"\"\"Use LLM to fix low-confidence extractions.\"\"\"\n    response = client.messages.create(\n        model=\"claude-haiku-4-5-20251001\",  # Cheapest model for validation\n        max_tokens=500,\n        messages=[{\n            \"role\": \"user\",\n            \"content\": (\n                f\"Extract the question, choices, and answer from this text.\\n\\n\"\n                f\"Text: {original_text}\\n\\n\"\n                f\"Current extraction: {item}\\n\\n\"\n                f\"Return corrected JSON if needed, or 'CORRECT' if accurate.\"\n            ),\n        }],\n    )\n    # Parse LLM response and return corrected item...\n    return corrected_item\n```\n\n### 4. Hybrid Pipeline\n\n```python\ndef process_document(\n    content: str,\n    *,\n    llm_client=None,\n    confidence_threshold: float = 0.95,\n) -> list[ParsedItem]:\n    \"\"\"Full pipeline: regex -> confidence check -> LLM for edge cases.\"\"\"\n    # Step 1: Regex extraction (handles 95-98%)\n    items = parse_structured_text(content)\n\n    # Step 2: Confidence scoring\n    low_confidence = identify_low_confidence(items, confidence_threshold)\n\n    if not low_confidence or llm_client is None:\n        return items\n\n    # Step 3: LLM validation (only for flagged items)\n    low_conf_ids = {f.item_id for f in low_confidence}\n    result = []\n    for item in items:\n        if item.id in low_conf_ids:\n            result.append(validate_with_llm(item, content, llm_client))\n        else:\n            result.append(item)\n\n    return result\n```\n\n## Real-World Metrics\n\nFrom a production quiz parsing pipeline (410 items):\n\n| Metric | Value |\n|--------|-------|\n| Regex success rate | 98.0% |\n| Low confidence items | 8 (2.0%) |\n| LLM calls needed | ~5 |\n| Cost savings vs all-LLM | ~95% |\n| Test coverage | 93% |\n\n## Best Practices\n\n- **Start with regex** ‚Äî even imperfect regex gives you a baseline to improve\n- **Use confidence scoring** to programmatically identify what needs LLM help\n- **Use the cheapest LLM** for validation (Haiku-class models are sufficient)\n- **Never mutate** parsed items ‚Äî return new instances from cleaning/validation steps\n- **TDD works well** for parsers ‚Äî write tests for known patterns first, then edge cases\n- **Log metrics** (regex success rate, LLM call count) to track pipeline health\n\n## Anti-Patterns to Avoid\n\n- Sending all text to an LLM when regex handles 95%+ of cases (expensive and slow)\n- Using regex for free-form, highly variable text (LLM is better here)\n- Skipping confidence scoring and hoping regex \"just works\"\n- Mutating parsed objects during cleaning/validation steps\n- Not testing edge cases (malformed input, missing fields, encoding issues)\n\n## When to Use\n\n- Quiz/exam question parsing\n- Form data extraction\n- Invoice/receipt processing\n- Document structure parsing (headers, sections, tables)\n- Any structured text with repeating patterns where cost matters",
    "author": "community",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "remotion-best-practices",
    "name": "remotion-best-practices",
    "description": "Best practices for Remotion - Video creation in React",
    "instructions": "## When to use\n\nUse this skills whenever you are dealing with Remotion code to obtain the domain-specific knowledge.\n\n## Captions\n\nWhen dealing with captions or subtitles, load the [./rules/subtitles.md](./rules/subtitles.md) file for more information.\n\n## Using FFmpeg\n\nFor some video operations, such as trimming videos or detecting silence, FFmpeg should be used. Load the [./rules/ffmpeg.md](./rules/ffmpeg.md) file for more information.\n\n## Audio visualization\n\nWhen needing to visualize audio (spectrum bars, waveforms, bass-reactive effects), load the [./rules/audio-visualization.md](./rules/audio-visualization.md) file for more information.\n\n## How to use\n\nRead individual rule files for detailed explanations and code examples:\n\n- [rules/3d.md](rules/3d.md) - 3D content in Remotion using Three.js and React Three Fiber\n- [rules/animations.md](rules/animations.md) - Fundamental animation skills for Remotion\n- [rules/assets.md](rules/assets.md) - Importing images, videos, audio, and fonts into Remotion\n- [rules/audio.md](rules/audio.md) - Using audio and sound in Remotion - importing, trimming, volume, speed, pitch\n- [rules/calculate-metadata.md](rules/calculate-metadata.md) - Dynamically set composition duration, dimensions, and props\n- [rules/can-decode.md](rules/can-decode.md) - Check if a video can be decoded by the browser using Mediabunny\n- [rules/charts.md](rules/charts.md) - Chart and data visualization patterns for Remotion (bar, pie, line, stock charts)\n- [rules/compositions.md](rules/compositions.md) - Defining compositions, stills, folders, default props and dynamic metadata\n- [rules/extract-frames.md](rules/extract-frames.md) - Extract frames from videos at specific timestamps using Mediabunny\n- [rules/fonts.md](rules/fonts.md) - Loading Google Fonts and local fonts in Remotion\n- [rules/get-audio-duration.md](rules/get-audio-duration.md) - Getting the duration of an audio file in seconds with Mediabunny\n- [rules/get-video-dimensions.md](rules/get-video-dimensions.md) - Getting the width and height of a video file with Mediabunny\n- [rules/get-video-duration.md](rules/get-video-duration.md) - Getting the duration of a video file in seconds with Mediabunny\n- [rules/gifs.md](rules/gifs.md) - Displaying GIFs synchronized with Remotion's timeline\n- [rules/images.md](rules/images.md) - Embedding images in Remotion using the Img component\n- [rules/light-leaks.md](rules/light-leaks.md) - Light leak overlay effects using @remotion/light-leaks\n- [rules/lottie.md](rules/lottie.md) - Embedding Lottie animations in Remotion\n- [rules/measuring-dom-nodes.md](rules/measuring-dom-nodes.md) - Measuring DOM element dimensions in Remotion\n- [rules/measuring-text.md](rules/measuring-text.md) - Measuring text dimensions, fitting text to containers, and checking overflow\n- [rules/sequencing.md](rules/sequencing.md) - Sequencing patterns for Remotion - delay, trim, limit duration of items\n- [rules/tailwind.md](rules/tailwind.md) - Using TailwindCSS in Remotion\n- [rules/text-animations.md](rules/text-animations.md) - Typography and text animation patterns for Remotion\n- [rules/timing.md](rules/timing.md) - Interpolation curves in Remotion - linear, easing, spring animations\n- [rules/transitions.md](rules/transitions.md) - Scene transition patterns for Remotion\n- [rules/transparent-videos.md](rules/transparent-videos.md) - Rendering out a video with transparency\n- [rules/trimming.md](rules/trimming.md) - Trimming patterns for Remotion - cut the beginning or end of animations\n- [rules/videos.md](rules/videos.md) - Embedding videos in Remotion - trimming, volume, speed, looping, pitch\n- [rules/parameters.md](rules/parameters.md) - Make a video parametrizable by adding a Zod schema\n- [rules/maps.md](rules/maps.md) - Add a map using Mapbox and animate it\n- [rules/voiceover.md](rules/voiceover.md) - Adding AI-generated voiceover to Remotion compositions using ElevenLabs TTS",
    "author": "community",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "seo-review",
    "name": "seo-review",
    "description": "Perform a focused SEO audit on JavaScript concept pages to maximize search visibility, featured snippet optimization, and ranking potential",
    "instructions": "# Skill: SEO Audit for Concept Pages\n\nUse this skill to perform a focused SEO audit on concept documentation pages for the 33 JavaScript Concepts project. The goal is to maximize search visibility for JavaScript developers.\n\n## When to Use\n\n- Before publishing a new concept page\n- When optimizing underperforming pages\n- Periodic content audits\n- After major content updates\n- When targeting new keywords\n\n## Goal\n\nEach concept page should rank for searches like:\n- \"what is [concept] in JavaScript\"\n- \"how does [concept] work in JavaScript\"\n- \"[concept] JavaScript explained\"\n- \"[concept] JavaScript tutorial\"\n- \"[concept] JavaScript example\"\n\n---\n\n## SEO Audit Methodology\n\nFollow these five steps for a complete SEO audit.\n\n### Step 1: Identify Target Keywords\n\nBefore auditing, identify the keyword cluster for the concept.\n\n#### Keyword Cluster Template\n\n| Type | Pattern | Example (Closures) |\n|------|---------|-------------------|\n| **Primary** | [concept] JavaScript | closures JavaScript |\n| **What is** | what is [concept] in JavaScript | what is a closure in JavaScript |\n| **How does** | how does [concept] work | how do closures work |\n| **How to** | how to use/create [concept] | how to use closures |\n| **Why** | why use [concept] | why use closures JavaScript |\n| **Examples** | [concept] examples | closure examples JavaScript |\n| **vs** | [concept] vs [related] | closures vs scope |\n| **Interview** | [concept] interview questions | closure interview questions |\n\n### Step 2: On-Page SEO Audit\n\nCheck all on-page SEO elements systematically.\n\n### Step 3: Featured Snippet Optimization\n\nVerify content is structured to win featured snippets.\n\n### Step 4: Internal Linking Audit\n\nCheck the internal link structure.\n\n### Step 5: Generate Report\n\nDocument findings using the report template.\n\n---\n\n## Keyword Clusters\n\nBuild a keyword cluster for the concept using this pattern:\n\n- **Primary**: `[concept] JavaScript`\n- **What is**: `what is [concept] in JavaScript`\n- **How does**: `how does [concept] work`\n- **How to**: `how to use [concept]`\n- **Examples**: `[concept] JavaScript example`\n- **vs**: `[concept] vs [related]`\n- **Interview**: `[concept] interview questions`\n\n---\n\n## Audit Checklist (Condensed)\n\n### Title & Meta\n- Title is 50-60 chars, keyword in first half, ends with \"in JavaScript\"\n- Meta description is 150-160 chars, starts with action verb, includes keyword\n\n### Keyword Placement\n- Keyword in title, description, first 100 words, and at least one H2\n- Avoid keyword stuffing; use variations naturally\n\n### Content Structure\n- Opening question hook + short answer\n- Code example within first 200 words\n- \"What you'll learn\" info box + clear H2 sections\n- Key takeaways and common mistakes sections\n\n### Featured Snippet Readiness\n- 40-60 word \"What is X\" definition\n- At least one question-style H2\n- Tables or steps where relevant\n\n### Internal Linking\n- 3-5 relevant internal links in body\n- Descriptive anchor text\n- Related Concepts section with 4 cards\n\n### Technical\n- No broken links\n- Images have alt text\n- Page renders correctly on mobile\n\n---\n\n## Report Template (Short)\n\n```markdown\n# SEO Audit: [Concept]\n\n## Scores\n- Title: /4\n- Meta: /4\n- Keyword placement: /5\n- Structure: /6\n- Snippet: /4\n- Internal linking: /4\n- Technical: /4\n\n## Key Issues\n- [Issue 1]\n- [Issue 2]\n\n## Priority Fixes\n1. [Fix 1]\n2. [Fix 2]\n```\n\n---\n\n## Summary\n\nWhen auditing a concept page for SEO:\n\n1. **Identify target keywords** using the keyword cluster for that concept\n2. **Check title tag** ‚Äî 50-60 chars, keyword first, hook, ends with \"JavaScript\"\n3. **Check meta description** ‚Äî 150-160 chars, action word, keyword, specific value\n4. **Verify keyword placement** ‚Äî Title, description, first 100 words, H2\n5. **Audit content structure** ‚Äî Question hook, early code, Info box, short paragraphs\n6. **Optimize for featured snippets** ‚Äî 40-60 word definitions, numbered steps, tables\n7. **Check internal linking** ‚Äî 3-5 links, good anchors, Related Concepts section\n8. **Generate report** ‚Äî Document score, issues, and prioritized fixes\n\n**Remember:** SEO isn't about gaming search engines ‚Äî it's about making content easy to find for developers who need it. Every optimization should also improve the reader experience.",
    "author": "community",
    "version": "1.0.0",
    "category": "research",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "songsee",
    "name": "songsee",
    "description": "Generate spectrograms and feature-panel visualizations from audio with the songsee CLI.",
    "instructions": "# songsee\n\nGenerate spectrograms + feature panels from audio.\n\nQuick start\n\n- Spectrogram: `songsee track.mp3`\n- Multi-panel: `songsee track.mp3 --viz spectrogram,mel,chroma,hpss,selfsim,loudness,tempogram,mfcc,flux`\n- Time slice: `songsee track.mp3 --start 12.5 --duration 8 -o slice.jpg`\n- Stdin: `cat track.mp3 | songsee - --format png -o out.png`\n\nCommon flags\n\n- `--viz` list (repeatable or comma-separated)\n- `--style` palette (classic, magma, inferno, viridis, gray)\n- `--width` / `--height` output size\n- `--window` / `--hop` FFT settings\n- `--min-freq` / `--max-freq` frequency range\n- `--start` / `--duration` time slice\n- `--format` jpg|png\n\nNotes\n\n- WAV/MP3 decode native; other formats use ffmpeg if available.\n- Multiple `--viz` renders a grid.",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "summarize",
    "name": "summarize",
    "description": "Summarize or extract text/transcripts from URLs, podcasts, and local files (great fallback for ‚Äútranscribe this YouTube/video‚Äù).",
    "instructions": "# Summarize\n\nFast CLI to summarize URLs, local files, and YouTube links.\n\n## When to use (trigger phrases)\n\nUse this skill immediately when the user asks any of:\n\n- ‚Äúuse summarize.sh‚Äù\n- ‚Äúwhat‚Äôs this link/video about?‚Äù\n- ‚Äúsummarize this URL/article‚Äù\n- ‚Äútranscribe this YouTube/video‚Äù (best-effort transcript extraction; no `yt-dlp` needed)\n\n## Quick start\n\n```bash\nsummarize \"https://example.com\" --model google/gemini-3-flash-preview\nsummarize \"/path/to/file.pdf\" --model google/gemini-3-flash-preview\nsummarize \"https://youtu.be/dQw4w9WgXcQ\" --youtube auto\n```\n\n## YouTube: summary vs transcript\n\nBest-effort transcript (URLs only):\n\n```bash\nsummarize \"https://youtu.be/dQw4w9WgXcQ\" --youtube auto --extract-only\n```\n\nIf the user asked for a transcript but it‚Äôs huge, return a tight summary first, then ask which section/time range to expand.\n\n## Model + keys\n\nSet the API key for your chosen provider:\n\n- OpenAI: `OPENAI_API_KEY`\n- Anthropic: `ANTHROPIC_API_KEY`\n- xAI: `XAI_API_KEY`\n- Google: `GEMINI_API_KEY` (aliases: `GOOGLE_GENERATIVE_AI_API_KEY`, `GOOGLE_API_KEY`)\n\nDefault model is `google/gemini-3-flash-preview` if none is set.\n\n## Useful flags\n\n- `--length short|medium|long|xl|xxl|<chars>`\n- `--max-output-tokens <count>`\n- `--extract-only` (URLs only)\n- `--json` (machine readable)\n- `--firecrawl auto|off|always` (fallback extraction)\n- `--youtube auto` (Apify fallback if `APIFY_API_TOKEN` set)\n\n## Config\n\nOptional config file: `~/.summarize/config.json`\n\n```json\n{ \"model\": \"openai/gpt-5.2\" }\n```\n\nOptional services:\n\n- `FIRECRAWL_API_KEY` for blocked sites\n- `APIFY_API_TOKEN` for YouTube fallback",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "technical-writer",
    "name": "technical-writer",
    "description": "|",
    "instructions": "# Technical Writer\n\nYou are an expert technical writer who creates clear, user-friendly documentation for technical products.\n\n## When to Apply\n\nUse this skill when:\n- Writing API documentation\n- Creating README files and setup guides\n- Developing user manuals and tutorials\n- Documenting architecture and design\n- Writing changelog and release notes\n- Creating onboarding guides\n- Explaining complex technical concepts\n\n## Writing Principles\n\n### 1. **User-Centered**\n- Lead with the user's goal, not the feature\n- Answer \"why should I care?\" before \"how does it work?\"\n- Anticipate user questions and pain points\n\n### 2. **Clarity First**\n- Use active voice and present tense\n- Keep sentences under 25 words\n- One main idea per paragraph\n- Define technical terms on first use\n\n### 3. **Show, Don't Just Tell**\n- Include practical examples for every concept\n- Provide complete, runnable code samples\n- Show expected output\n- Include common error cases\n\n### 4. **Progressive Disclosure**\n-Structure from simple to complex\n- Quick start before deep dives\n- Link to advanced topics\n- Don't overwhelm beginners\n\n### 5. **Scannable Content**\n- Use descriptive headings\n- Bulleted lists for 3+ items\n- Code blocks with syntax highlighting\n- Visual hierarchy with formatting\n\n## Documentation Structure\n\n### For Project README\n```markdown\n# Project Name\n[One-line description]\n\n## Features\n- [Key features as bullets]\n\n## Installation\n[Minimal steps to install]\n\n## Quick Start\n[Simplest possible example]\n\n## Usage\n[Common use cases with examples]\n\n## API Reference\n[If applicable]\n\n## Configuration\n[Optional settings]\n\n## Troubleshooting\n[Common issues and solutions]\n\n## Contributing\n[How to contribute]\n\n## License\n```\n\n### For API Documentation\n```markdown\n## Function/Endpoint Name\n\n[Brief description of what it does]\n\n### Parameters\n\n| Name | Type | Required | Description |\n|------|------|----------|-------------|\n| param1 | string | Yes | What it's for |\n\n### Returns\n\n[What it returns and in what format]\n\n### Example\n\n```language\n[Complete working example]\n```\n\n### Errors\n\n| Code | Description | Solution |\n|------|-------------|----------|\n```\n\n### For Tutorials\n```markdown\n# [What You'll Build]\n\n[Brief description and screenshot/demo]\n\n## Prerequisites\n- [Required knowledge]\n- [Required software]\n\n## Step 1: [First Action]\n[Clear instructions with code]\n\n## Step 2: [Next Action]\n[Continue step by step]\n\n## Next Steps\n[Where to go from here]\n```\n\n## Style Guide\n\n### Voice & Tone\n- **Use \"you\"** for direct address\n- **Use \"we\"** when referring to shared actions\n- **Avoid \"I\"** except in opinionated guides\n- **Be conversational but professional**\n\n### Formatting\n- **Bold** for UI elements, buttons, menu items\n- `code formatting` for commands, variables, filenames\n- *Italic* for emphasis (use sparingly)\n- UPPERCASE for placeholders (API_KEY, USERNAME)\n\n### Code Examples\n```python\n# Always include comments explaining non-obvious code\n# Show complete, working examples\n# Include expected output\n\ndef example_function(param: str) -> str:\n    \"\"\"\n    Brief description of what this does.\n    \n    Args:\n        param: What this parameter is for\n        \n    Returns:\n        What gets returned\n    \"\"\"\n    return f\"Result: {param}\"\n\n# Example usage\nresult = example_function(\"test\")\nprint(result)\n# Output: Result: test\n```\n\n## Common Patterns\n\n### Installation Instructions\n```markdown\n## Installation\n\n### Using pip\n```bash\npip install package-name\n```\n\n### Using npm\n```bash\nnpm install package-name\n```\n\n### From source\n```bash\ngit clone https://github.com/user/repo.git\ncd repo\npip install -e .\n```\n```\n\n### Troubleshooting Section\n```markdown\n## Troubleshooting\n\n### Error: \"Module not found\"\n**Cause:** Package not installed or wrong Python environment\n\n**Solution:**\n```bash\npip install package-name\n```\n\n### Error: \"Permission denied\"\n**Cause:** Insufficient file permissions\n\n**Solution:**\n```bash\nsudo command\n# or\nchmod +x script.sh\n```\n```\n\n## Example Output\n\n**User Request:** \"Write a README for a CLI tool that sorts files by size\"\n\n**Response:**\n\n```markdown\n# filesort\n\nSort and organize files by size from the command line.\n\n## Features\n\n- Sort files in any directory by size\n- Filter by file extension\n- Export results to CSV\n- Human-readable size formatting\n\n## Installation\n\n```bash\npip install filesort\n```\n\n## Quick Start\n\nSort files in current directory:\n```bash\nfilesort .\n```\n\nOutput:\n```\n1.2 GB    video.mp4\n856 MB    dataset.zip\n45 MB     photo.jpg\n2.1 KB    README.md\n```\n\n## Usage\n\n```bash\nfilesort [OPTIONS] DIRECTORY\n```\n\n### Options\n\n| Option | Description |\n|--------|-------------|\n| `-r, --reverse` | Show largest files first (default: smallest first) |\n| `-n, --number NUM` | Show only top N files |\n| `-e, --extension EXT` | Filter by file extension |\n| `-o, --output FILE` | Export to CSV file |\n| `--recursive` | Include subdirectories |\n\n### Examples\n\n**Find your 10 largest files:**\n```bash\nfilesort . --reverse --number 10\n```\n\n**Find large video files:**\n```bash\nfilesort ~/Videos --extension mp4 --reverse\n```\n\n**Export file list to CSV:**\n```bash\nfilesort . --output files.csv\n```\n\n**Search recursively:**\n```bash\nfilesort ~/Documents --recursive --reverse --number 20\n```\n\n## Configuration\n\nCreate `~/.filesort.yaml` for default options:\n\n```yaml\nreverse: true\nnumber: 50\nignore:\n  - \"*.tmp\"\n  - \"__pycache__\"\n```\n\n## Troubleshooting\n\n### \"Permission denied\" errors\nSome directories require elevated permissions:\n```bash\nsudo filesort /var/log\n```\n\n### No files shown\nCheck if you're filtering too aggressively:\n```bash\n# This might not match anything\nfilesort . --extension xyz\n\n# Try without filters\nfilesort .\n```\n\n## Contributing\n\nContributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## License\n\nMIT\n```\n\n---\n\n**Why this works:**\n- Starts with clear value proposition\n- Quick start gets users running immediately\n- Examples for every feature\n- Troubleshooting for common issues\n- Scannable structure with tables\n- Progressive complexity (basic ‚Üí advanced)",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "video-frames",
    "name": "video-frames",
    "description": "Extract frames or short clips from videos using ffmpeg.",
    "instructions": "# Video Frames (ffmpeg)\n\nExtract a single frame from a video, or create quick thumbnails for inspection.\n\n## Quick start\n\nFirst frame:\n\n```bash\n{baseDir}/scripts/frame.sh /path/to/video.mp4 --out /tmp/frame.jpg\n```\n\nAt a timestamp:\n\n```bash\n{baseDir}/scripts/frame.sh /path/to/video.mp4 --time 00:00:10 --out /tmp/frame-10s.jpg\n```\n\n## Notes\n\n- Prefer `--time` for ‚Äúwhat is happening around here?‚Äù.\n- Use a `.jpg` for quick share; use `.png` for crisp UI frames.",
    "author": "openclaw",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "video-report",
    "name": "video-report",
    "description": "Generate a report about a video",
    "instructions": "When a user reports a video not working, we should download the URL and put it as the `src` in `packages/example/src/NewVideo.tsx`.\n\nThen, in `packages/example`, we should run `bunx remotion render NewVideo --log=verbose`.",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "web-fetch",
    "name": "web-fetch",
    "description": "Fetch and extract readable content from web pages. Use for lightweight page access without browser automation.",
    "instructions": "# Web Fetch\n\nFetch and extract readable content from web pages using curl and basic text processing.\n\n## Usage\n\n**Important**: Scripts are located relative to this skill's base directory.\n\nWhen you see this skill in `<available_skills>`, note the `<base_dir>` path.\n\n```bash\n# General pattern:\nbash \"<base_dir>/scripts/fetch.sh\" <url> [output_file]\n\n# Example (replace <base_dir> with actual path from skill listing):\nbash \"~/chatgpt-on-wechat/skills/web-fetch/scripts/fetch.sh\" \"https://example.com\"\n```\n\n**Parameters:**\n- `url`: The HTTP/HTTPS URL to fetch (required)\n- `output_file`: Optional file to save the output (default: stdout)\n\n**Returns:**\n- Extracted page content with title and text\n\n## Examples\n\n### Fetch a web page\n```bash\nbash \"<base_dir>/scripts/fetch.sh\" \"https://example.com\"\n```\n\n### Save to file\n```bash\nbash \"<base_dir>/scripts/fetch.sh\" \"https://example.com\" output.txt\ncat output.txt\n```\n\n## Notes\n\n- Uses curl for HTTP requests (timeout: 10s)\n- Extracts title and basic text content\n- Removes HTML tags and scripts\n- Works with any standard web page\n- No external dependencies beyond curl",
    "author": "community",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "write-tbp",
    "name": "write-tbp",
    "description": "Writing technical blog posts about tldraw features and implementation details. Use when creating blog content about how tldraw solves interesting problems.",
    "instructions": "# Write technical blog post\n\nThis skill covers how to write technical blog posts about tldraw's implementation details.\n\n## Process\n\n### 1. Create the workspace\n\nCreate an assets folder for this topic:\n\n```\n.claude/skills/write-tbp/assets/<topic>/\n‚îú‚îÄ‚îÄ research.md   # Gathered context and notes\n‚îî‚îÄ‚îÄ draft.md      # The blog post draft\n```\n\nUse a short, kebab-case name for the topic (e.g., `scribbles`, `arrow-routing`, `dash-patterns`).\n\n### 2. Research the topic\n\nUse an Explore subagent to gather all relevant information:\n\n```\nTask (subagent_type: Explore, thoroughness: very thorough)\n\nFind all code, documentation, and context related to [TOPIC] in the tldraw codebase.\n\nLook for:\n- Implementation files in packages/editor and packages/tldraw\n- Type definitions in packages/tlschema\n- Related examples in apps/examples\n- Any existing documentation in apps/docs/content\n- Tests that reveal behavior\n- Comments explaining why things work the way they do\n\nFor each relevant file, note:\n- What it does\n- Key functions/classes\n- Interesting implementation details\n- Any \"why\" comments or non-obvious decisions\n\nOutput a comprehensive summary of how [TOPIC] works. This document will be read by another agent. No need to over-optimize for human readability.\n```\n\nSave the research output to `assets/<topic>/research.md`.\n\n### 3. Identify the interesting angle\n\nBefore writing, answer these questions from the research:\n\n- **What problem does this solve?** Not \"what does it do\" but \"what would go wrong without it?\"\n- **What's surprising or unintuitive?** The obvious approach that doesn't work, or the hidden complexity.\n- **What's the key insight?** The \"aha\" that makes the solution work.\n- **What did we try first?** Any journey or iteration visible in the code or comments.\n\nIf you can't find an interesting angle, the topic may not be suitable for a technical blog post.\n\n### 4. Write the draft\n\nCreate `assets/<topic>/draft.md` following the blog-guide structure:\n\n1. **Frame the problem** ‚Äî Hook the reader with context and tension\n2. **Show the insight** ‚Äî The key idea that makes it work\n3. **Walk through the implementation** ‚Äî Code and explanation, building complexity\n4. **Wrap up** ‚Äî Where it lives, tradeoffs, links to files\n\nTarget 800-1500 words.\n\n### 5. Self-evaluate\n\nCheck the draft against the blog-guide checklist:\n\n- [ ] **Opening** ‚Äî Does it frame a problem before diving into solution?\n- [ ] **Insight** ‚Äî Is there a clear \"aha\" moment or key idea?\n- [ ] **Specificity** ‚Äî Is this grounded in tldraw's actual implementation?\n- [ ] **Code** ‚Äî Do examples build understanding, not just show syntax?\n- [ ] **Tone** ‚Äî Warm and personal, but not rambling?\n- [ ] **Links** ‚Äî Points to actual code in the repo?\n- [ ] **Length** ‚Äî Appropriate depth for the topic?\n\nRevise the draft to address any gaps.\n\n### 6. Output\n\nPresent the final draft to the user for review. The draft remains in `assets/<topic>/draft.md` until the user is satisfied, at which point they can move it to the appropriate location.\n\n## References\n\n- **Style guide**: See `../shared/blog-guide.md` for voice, tone, and structure.\n- **Writing guide**: See `../shared/writing-guide.md` for general writing conventions.",
    "author": "community",
    "version": "1.0.0",
    "category": "writing",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "xlsx",
    "name": "xlsx",
    "description": "Use this skill any time a spreadsheet file is the primary input or output. This means any task where the user wants to: open, read, edit, or fix an existing .xlsx, .xlsm, .csv, or .tsv file (e.g., adding columns, computing formulas, formatting, charting, cleaning messy data); create a new spreadsheet from scratch or from other data sources; or convert between tabular file formats. Trigger especially when the user references a spreadsheet file by name or path ‚Äî even casually (like \\\"the xlsx in my downloads\\\") ‚Äî and wants something done to it or produced from it. Also trigger for cleaning or restructuring messy tabular data files (malformed rows, misplaced headers, junk data) into proper spreadsheets. The deliverable must be a spreadsheet file. Do NOT trigger when the primary deliverable is a Word document, HTML report, standalone Python script, database pipeline, or Google Sheets API integration, even if tabular data is involved.",
    "instructions": "# Requirements for Outputs\n\n## All Excel files\n\n### Professional Font\n- Use a consistent, professional font (e.g., Arial, Times New Roman) for all deliverables unless otherwise instructed by the user\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `scripts/recalc.py` script. The script automatically configures LibreOffice on first run, including in sandboxed environments where Unix sockets are restricted (handled by `scripts/office/soffice.py`)\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### ‚ùå WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### ‚úÖ CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the scripts/recalc.py script\n   ```bash\n   python scripts/recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns JSON with error details\n   - If `status` is `errors_found`, check `error_summary` for specific error types and locations\n   - Fix the identified errors and recalculate again\n   - Common errors to fix:\n     - `#REF!`: Invalid cell references\n     - `#DIV/0!`: Division by zero\n     - `#VALUE!`: Wrong data type in formula\n     - `#NAME?`: Unrecognized formula name\n\n### Creating new Excel files\n\n```python\n# Using openpyxl for formulas and formatting\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n### Editing existing Excel files\n\n```python\n# Using openpyxl to preserve formulas and formatting\nfrom openpyxl import load_workbook\n\n# Load existing file\nwb = load_workbook('existing.xlsx')\nsheet = wb.active  # or wb['SheetName'] for specific sheet\n\n# Working with multiple sheets\nfor sheet_name in wb.sheetnames:\n    sheet = wb[sheet_name]\n    print(f\"Sheet: {sheet_name}\")\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)  # Insert row at position 2\nsheet.delete_cols(3)  # Delete column 3\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Recalculating formulas\n\nExcel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `scripts/recalc.py` script to recalculate formulas:\n\n```bash\npython scripts/recalc.py <excel_file> [timeout_seconds]\n```\n\nExample:\n```bash\npython scripts/recalc.py output.xlsx 30\n```\n\nThe script:\n- Automatically sets up LibreOffice macro on first run\n- Recalculates all formulas in all sheets\n- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)\n- Returns JSON with detailed error locations and counts\n- Works on both Linux and macOS\n\n## Formula Verification Checklist\n\nQuick checks to ensure formulas work correctly:\n\n### Essential Verification\n- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model\n- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)\n- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)\n\n### Common Pitfalls\n- [ ] **NaN handling**: Check for null values with `pd.notna()`\n- [ ] **Far-right columns**: FY data often in columns 50+ \n- [ ] **Multiple matches**: Search all occurrences, not just first\n- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)\n- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)\n- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets\n\n### Formula Testing Strategy\n- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly\n- [ ] **Verify dependencies**: Check all cells referenced in formulas exist\n- [ ] **Test edge cases**: Include zero, negative, and very large values\n\n### Interpreting scripts/recalc.py Output\nThe script returns JSON with error details:\n```json\n{\n  \"status\": \"success\",           // or \"errors_found\"\n  \"total_errors\": 0,              // Total error count\n  \"total_formulas\": 42,           // Number of formulas in file\n  \"error_summary\": {              // Only present if errors found\n    \"#REF!\": {\n      \"count\": 2,\n      \"locations\": [\"Sheet1!B5\", \"Sheet1!C10\"]\n    }\n  }\n}\n```\n\n## Best Practices\n\n### Library Selection\n- **pandas**: Best for data analysis, bulk operations, and simple data export\n- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features\n\n### Working with openpyxl\n- Cell indices are 1-based (row=1, column=1 refers to cell A1)\n- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`\n- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost\n- For large files: Use `read_only=True` for reading or `write_only=True` for writing\n- Formulas are preserved but not evaluated - use scripts/recalc.py to update values\n\n### Working with pandas\n- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`\n- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`\n- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`\n\n## Code Style Guidelines\n**IMPORTANT**: When generating Python code for Excel operations:\n- Write minimal, concise Python code without unnecessary comments\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n**For Excel files themselves**:\n- Add comments to cells with complex formulas or important assumptions\n- Document data sources for hardcoded values\n- Include notes for key calculations and model sections",
    "author": "community",
    "version": "1.0.0",
    "category": "productivity",
    "requires": [],
    "examples": []
  },
  {
    "skillId": "youtube-downloader",
    "name": "youtube-downloader",
    "description": "Download YouTube videos with customizable quality and format options. Use this skill when the user asks to download, save, or grab YouTube videos. Supports various quality settings (best, 1080p, 720p, 480p, 360p), multiple formats (mp4, webm, mkv), and audio-only downloads as MP3.",
    "instructions": "# YouTube Video Downloader\n\nDownload YouTube videos with full control over quality and format settings.\n\n## Quick Start\n\nThe simplest way to download a video:\n\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=VIDEO_ID\"\n```\n\nThis downloads the video in best available quality as MP4 to `/mnt/user-data/outputs/`.\n\n## Options\n\n### Quality Settings\n\nUse `-q` or `--quality` to specify video quality:\n\n- `best` (default): Highest quality available\n- `1080p`: Full HD\n- `720p`: HD\n- `480p`: Standard definition\n- `360p`: Lower quality\n- `worst`: Lowest quality available\n\nExample:\n```bash\npython scripts/download_video.py \"URL\" -q 720p\n```\n\n### Format Options\n\nUse `-f` or `--format` to specify output format (video downloads only):\n\n- `mp4` (default): Most compatible\n- `webm`: Modern format\n- `mkv`: Matroska container\n\nExample:\n```bash\npython scripts/download_video.py \"URL\" -f webm\n```\n\n### Audio Only\n\nUse `-a` or `--audio-only` to download only audio as MP3:\n\n```bash\npython scripts/download_video.py \"URL\" -a\n```\n\n### Custom Output Directory\n\nUse `-o` or `--output` to specify a different output directory:\n\n```bash\npython scripts/download_video.py \"URL\" -o /path/to/directory\n```\n\n## Complete Examples\n\n1. Download video in 1080p as MP4:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -q 1080p\n```\n\n2. Download audio only as MP3:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -a\n```\n\n3. Download in 720p as WebM to custom directory:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -q 720p -f webm -o /custom/path\n```\n\n## How It Works\n\nThe skill uses `yt-dlp`, a robust YouTube downloader that:\n- Automatically installs itself if not present\n- Fetches video information before downloading\n- Selects the best available streams matching your criteria\n- Merges video and audio streams when needed\n- Supports a wide range of YouTube video formats\n\n## Important Notes\n\n- Downloads are saved to `/mnt/user-data/outputs/` by default\n- Video filename is automatically generated from the video title\n- The script handles installation of yt-dlp automatically\n- Only single videos are downloaded (playlists are skipped by default)\n- Higher quality videos may take longer to download and use more disk space",
    "author": "community",
    "version": "1.0.0",
    "category": "development",
    "requires": [],
    "examples": []
  }
]